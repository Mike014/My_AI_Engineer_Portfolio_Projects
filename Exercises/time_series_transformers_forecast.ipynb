{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Time Series Forecasting with Transformers**\n",
        "\n",
        "**Objective**: Create a **Transformers-based model** in **Keras** to **predict future values** ​​of a time series.\n",
        "- **Dataset**: We will use daily temperature data from a city.\n",
        "- **Applied Skills**:\n",
        "\n",
        "   - Time Series Preprocessing\n",
        "   - Using Tensors and Operations with TensorFlow\n",
        "   - Implementing a Transformer Encoder\n",
        "   - Training and Evaluation of the Model\n",
        "   - Visualizing the Forecasts"
      ],
      "metadata": {
        "id": "_Ijy_KXtMoY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout, LayerNormalization, Input, BatchNormalization\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "51oVz564NPXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps**\n",
        "1. **Loading and Preprocessing Data**\n",
        "- We import a **time series dataset** (e.g. daily temperature)\n",
        "- We **normalize the data** and create an input sequence for the model."
      ],
      "metadata": {
        "id": "LW4QANL-Nb1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define the number of timesteps (days in a year)\n",
        "timesteps = 365\n",
        "\n",
        "# Create a linear trend component (increasing from 10 to 30)\n",
        "trend = np.linspace(10, 30, timesteps)\n",
        "\n",
        "# Create a seasonal component using a sine wave\n",
        "seasonal = 5 * np.sin(np.linspace(0, 2 * np.pi, timesteps))\n",
        "\n",
        "# Generate random noise with mean 0 and standard deviation 2\n",
        "noise = np.random.normal(0, 2, timesteps)\n",
        "\n",
        "# Combine trend, seasonality, and noise to create the time series data\n",
        "data = trend + seasonal + noise"
      ],
      "metadata": {
        "id": "zpLgvmT9NrxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Creiamo i dati di input per il modello\n",
        "def create_sequences(data, window_size):\n",
        "    \"\"\"\n",
        "    Generates input sequences and corresponding target values for a time series.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): The time series data.\n",
        "        window_size (int): The size of the sliding window used to create sequences.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the input sequences (X) and target values (y).\n",
        "    \"\"\"\n",
        "    X, y = [], [] # Initialize empty lists to store input sequences (X) and target values (y)\n",
        "    for i in range(len(data) - window_size): # Iterate through the data, leaving space for the window\n",
        "        X.append(data[i:i+window_size]) # Extract a window of data and add it to X\n",
        "        y.append(data[i+window_size]) # Add the next value\n",
        "    return np.array(X), np.array(y)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VqomMM8zP9ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 60  # Define the size of the sliding window (60 data points)\n",
        "X, y = create_sequences(data, window_size)  # Create input sequences (X) and targets (y) using the function\n",
        "X = X[..., np.newaxis]  # Add a new axis to X to make it compatible with the model (shape: [samples, timesteps, features])"
      ],
      "metadata": {
        "id": "-ulvhvpWQMfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "split = int(0.8 * len(X))  # Calculate the split index (80% of the data for training)\n",
        "X_train, y_train = X[:split], y[:split]  # Assign data before the split index to training sets\n",
        "X_test, y_test = X[split:], y[split:]  # Assign data after the split index to testing sets\n",
        "\n",
        "# Normalize the data\n",
        "mean = np.mean(X_train)  # Calculate the mean of the training data\n",
        "std = np.std(X_train)  # Calculate the standard deviation of the training data\n",
        "X_train = (X_train - mean) / std  # Normalize the training data using Z-score normalization\n",
        "X_test = (X_test - mean) / std  # Normalize the testing data using the same mean and std from training\n",
        "\n",
        "y_mean = np.mean(y_train)  # Calculate the mean of the training target values\n",
        "y_std = np.std(y_train)  # Calculate the standard deviation of the training target values\n",
        "y_train = (y_train - y_mean) / y_std  # Normalize the training target values\n",
        "y_test = (y_test - y_mean) / y_std  # Normalize the testing target values"
      ],
      "metadata": {
        "id": "25JcfA7tQSQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model Construction\n",
        "\n",
        "This section implements a Transformer Encoder using TensorFlow and Keras. It defines the core components of a Transformer Encoder layer: Multi-Head Attention, Layer Normalization, and a Feed-Forward Network.\n",
        "\n",
        "### Layers and Architecture\n",
        "\n",
        "The `TransformerEncoderLayer` is built using the following layers:\n",
        "\n",
        "#### Multi-Head Attention Layer (`self.attn`)\n",
        "\n",
        "- **Purpose**: This layer is the heart of the Transformer. It allows the model to attend to different parts of the input sequence and learn relationships between them.\n",
        "- **Functionality**: It uses multiple \"heads\" (specified by `num_heads`) to focus on different aspects of the data, improving the model's ability to capture complex patterns.\n",
        "- **Implementation**: In this implementation, it's using `tf.keras.layers.MultiHeadAttention`.\n",
        "\n",
        "#### Layer Normalization Layers (`self.norm1`, `self.norm2`)\n",
        "\n",
        "- **Purpose**: Layer Normalization is applied after the Multi-Head Attention and the Feed-Forward Network.\n",
        "- **Functionality**: It normalizes the activations within each layer, stabilizing and accelerating the training process. It normalizes the inputs across the features, as opposed to Batch Normalization which normalizes across the batch.\n",
        "- **Implementation**: Keras' `LayerNormalization` is used here with a small epsilon value for numerical stability.\n",
        "\n",
        "#### Feed-Forward Network (`self.ffn`)\n",
        "\n",
        "- **Purpose**: This is a traditional feed-forward neural network consisting of two dense layers with a ReLU activation in between.\n",
        "- **Functionality**: It processes the output of the Multi-Head Attention layer.\n",
        "- **Implementation**: L2 regularization is applied to the dense layers to prevent overfitting (`kernel_regularizer=tf.keras.regularizers.l2(1.00)`).\n",
        "\n",
        "#### Dropout Layers (`self.dropout1`, `self.dropout2`)\n",
        "\n",
        "- **Purpose**: Dropout is a regularization technique used to prevent overfitting.\n",
        "- **Functionality**: It randomly ignores a fraction of neurons during training, forcing the network to learn more robust features.\n",
        "- **Implementation**: Dropout is applied after the Multi-Head Attention and the Feed-Forward Network.\n",
        "\n",
        "### Data Flow\n",
        "\n",
        "1. The input data (`inputs`) is first passed through the Multi-Head Attention layer (`self.attn`).\n",
        "2. Dropout is applied to the attention output (`self.dropout1`).\n",
        "3. The attention output is added to the original input, and the result is normalized using Layer Normalization (`self.norm1`).\n",
        "4. This normalized output is then fed into the Feed-Forward Network (`self.ffn`).\n",
        "5. Dropout is applied to the output of the Feed-Forward Network (`self.dropout2`).\n",
        "6. The output of the Feed-Forward Network is added to the output of step 3, and the result is normalized using Layer Normalization (`self.norm2`).\n",
        "7. This final normalized output is returned by the `call` method.\n",
        "\n"
      ],
      "metadata": {
        "id": "XS2q5XTVRrpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of the Transformer Encoder\n",
        "class TransformerEncoderLayer(Layer):  # Define a custom layer class called 'TransformerEncoderLayer', inheriting from 'Layer'\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.3):  # Initialize the layer with parameters\n",
        "        super(TransformerEncoderLayer, self).__init__()  # Call the constructor of the parent class (Layer)\n",
        "        self.attn = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)  # Create a Multi-Head Attention layer\n",
        "        self.norm1 = LayerNormalization(epsilon=1e-6)  # Create a Layer Normalization layer (norm1)\n",
        "        self.norm2 = LayerNormalization(epsilon=1e-6)  # Create another Layer Normalization layer (norm2)\n",
        "        self.ffn = tf.keras.Sequential([  # Create a feed-forward network (ffn) as a sequential model\n",
        "            Dense(ff_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1.00)),  # Dense layer with ReLU and L2 regularization\n",
        "            Dropout(dropout),  # Dropout layer\n",
        "            Dense(embed_dim, kernel_regularizer=tf.keras.regularizers.l2(1.00))  # Another dense layer with L2 regularization\n",
        "        ])\n",
        "        self.dropout1 = Dropout(dropout)  # Create a Dropout layer (dropout1)\n",
        "        self.dropout2 = Dropout(dropout)  # Create another Dropout layer (dropout2)\n",
        "\n",
        "    def call(self, inputs, training=False):  # Define the forward pass of the layer\n",
        "        attn_output = self.attn(inputs, inputs)  # Apply Multi-Head Attention to the inputs\n",
        "        attn_output = self.dropout1(attn_output, training=training)  # Apply dropout1 to the attention output\n",
        "        out1 = self.norm1(inputs + attn_output)  # Add inputs and attention output, then normalize with norm1\n",
        "        ffn_output = self.ffn(out1, training=training)  # Pass the output through the feed-forward network\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)  # Apply dropout2 to the ffn output\n",
        "        return self.norm2(out1 + ffn_output)  # Add out1 and ffn output, then normalize with norm2 and return"
      ],
      "metadata": {
        "id": "B4kY3YLfTa5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model Construction\n",
        "\n",
        "This section implements a Transformer-based model for time series forecasting using TensorFlow and Keras. It combines a Dense layer, Batch Normalization, Dropout, two Transformer Encoder layers, Global Average Pooling, and a final Dense layer for prediction.\n",
        "\n",
        "### Layers and Architecture\n",
        "\n",
        "The `create_transformer_model` function constructs a model with the following layers:\n",
        "\n",
        "#### Input Layer\n",
        "\n",
        "- **Purpose**: Receives the time series data with the specified input shape.\n",
        "- **Functionality**: Acts as the entry point for the data into the model.\n",
        "- **Implementation**: `Input(shape=input_shape)`\n",
        "\n",
        "#### Dense Layer\n",
        "\n",
        "- **Purpose**: Applies a linear transformation to the input data.\n",
        "- **Functionality**: Extracts features from the input sequence.\n",
        "- **Implementation**: `Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.05))`\n",
        "  - Uses 128 neurons.\n",
        "  - ReLU activation function introduces non-linearity.\n",
        "  - L2 regularization helps prevent overfitting.\n",
        "\n",
        "#### Batch Normalization Layer\n",
        "\n",
        "- **Purpose**: Normalizes the activations of the previous layer.\n",
        "- **Functionality**: Improves training stability and speed by reducing internal covariate shift.\n",
        "- **Implementation**: `BatchNormalization()`\n",
        "\n",
        "#### Dropout Layer\n",
        "\n",
        "- **Purpose**: Randomly sets a fraction of input units to 0 during training.\n",
        "- **Functionality**: Helps prevent overfitting by reducing dependence on individual neurons.\n",
        "- **Implementation**: `Dropout(0.3)` (30% dropout rate)\n",
        "\n",
        "#### Transformer Encoder Layers (x2)\n",
        "\n",
        "- **Purpose**: The core of the model, responsible for capturing temporal dependencies.\n",
        "- **Functionality**: Uses Multi-Head Attention to learn relationships between different parts of the input sequence. Includes Layer Normalization and a Feed-Forward Network within each encoder layer.\n",
        "- **Implementation**: `TransformerEncoderLayer(embed_dim=128, num_heads=2, ff_dim=256, dropout=0.3)`\n",
        "  - `embed_dim`: Dimensionality of the embedding space (128).\n",
        "  - `num_heads`: Number of attention heads (2).\n",
        "  - `ff_dim`: Dimensionality of the feed-forward network (256).\n",
        "  - `dropout`: Dropout rate within the encoder layer (0.3).\n",
        "\n",
        "#### Global Average Pooling 1D Layer\n",
        "\n",
        "- **Purpose**: Averages the output of the Transformer Encoder layers across the time dimension.\n",
        "- **Functionality**: Reduces the dimensionality of the data while preserving important information.\n",
        "- **Implementation**: `tf.keras.layers.GlobalAveragePooling1D()`\n",
        "\n",
        "#### Output Layer\n",
        "\n",
        "- **Purpose**: Produces the final prediction.\n",
        "- **Functionality**: Maps the processed features to a single output value.\n",
        "- **Implementation**: `Dense(1)` (single neuron for regression)\n"
      ],
      "metadata": {
        "id": "AEKySDf7FwOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transformer_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.05))(inputs)\n",
        "    x = BatchNormalization()(x)  # BatchNormalization mantiene la stabilità\n",
        "    x = Dropout(0.3)(x)  # Dropout ridotto\n",
        "    x = TransformerEncoderLayer(embed_dim=128, num_heads=2, ff_dim=256, dropout=0.3)(x)\n",
        "    x = TransformerEncoderLayer(embed_dim=128, num_heads=2, ff_dim=256, dropout=0.3)(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = Dense(1)(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = create_transformer_model((window_size, 1))"
      ],
      "metadata": {
        "id": "fjENf_N9VtFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate\n",
        "\n",
        "The learning rate is a crucial hyperparameter that controls the step size during the optimization process. It determines how much the model's weights are adjusted based on the calculated error.\n",
        "\n",
        "- A smaller learning rate means the model's weights are updated more slowly, leading to more stable training but potentially requiring more time to converge.\n",
        "- A larger learning rate can lead to faster convergence, but it may also cause the model to overshoot the optimal solution and oscillate or diverge.\n",
        "\n",
        "## Learning Rate Scheduler (`lr_scheduler`)\n",
        "\n",
        "### ReduceLROnPlateau\n",
        "\n",
        "This learning rate scheduler automatically reduces the learning rate when a metric (in this case, `val_loss`) has stopped improving.\n",
        "\n",
        "- **monitor='val_loss'**: It monitors the validation loss to determine if the model is improving.\n",
        "- **factor=0.5**: When the validation loss plateaus, the learning rate is reduced by a factor of 0.5 (halved).\n",
        "- **patience=3**: The scheduler waits for 3 epochs (patience) without improvement before reducing the learning rate.\n",
        "- **min_lr=1e-6**: This sets a lower bound for the learning rate, preventing it from getting too small and potentially hindering training.\n",
        "\n",
        "## Optimizer (`AdamW`)\n",
        "\n",
        "### AdamW (Adam with Weight Decay)\n",
        "\n",
        "AdamW is a variant of the popular Adam optimizer, often preferred for training deep learning models, especially Transformers. It combines the benefits of Adam (adaptive learning rates) with weight decay, a regularization technique that helps prevent overfitting.\n",
        "\n",
        "- **learning_rate=initial_learning_rate**: Sets the initial learning rate for the AdamW optimizer.\n",
        "- **clipnorm=1.0**: Clips the gradients to a maximum norm of 1.0. This helps prevent exploding gradients, which can destabilize training.\n",
        "\n",
        "## `model.compile()`\n",
        "\n",
        "This function configures the model for training.\n",
        "\n",
        "- **optimizer**: Specifies the optimization algorithm to use (AdamW in this case).\n",
        "- **loss**: Defines the loss function to minimize during training (Mean Squared Error - 'mse' here).\n",
        "\n",
        "## `model.summary()`\n",
        "\n",
        "Prints a summary of the model's architecture, including the layers, output shapes, and the number of trainable parameters. This is useful for understanding the structure of your model."
      ],
      "metadata": {
        "id": "QeNf6Y0RGUTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **MSE (Mean Squared Error) Loss Function**:\n",
        "MSE is a loss function that **calculates the mean squared difference** between the **predicted and actual values**, penalizing larger errors more.\n"
      ],
      "metadata": {
        "id": "oGk_hHkAWLXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Rate and Optimizer Configuration\n",
        "\n",
        "initial_learning_rate = 3e-4  # Set the initial learning rate to 0.0003\n",
        "\n",
        "# lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "#    initial_learning_rate, decay_steps=80, end_learning_rate=final_learning_rate\n",
        "# )\n",
        "# This is an example of a learning rate scheduler that gradually decreases\n",
        "# the learning rate over time. It's commented out here, but you can use it\n",
        "# instead of ReduceLROnPlateau if desired.\n",
        "\n",
        "# Learning Rate Scheduler using ReduceLROnPlateau\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor the validation loss for learning rate adjustments\n",
        "    factor=0.5,        # Reduce the learning rate by a factor of 0.5 (halve it)\n",
        "    patience=3,        # Number of epochs with no improvement after which to reduce LR\n",
        "    min_lr=1e-6       # Minimum learning rate (to prevent it from going to zero)\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=initial_learning_rate, clipnorm=1.0),\n",
        "    loss='mse'  # Use Mean Squared Error as the loss function\n",
        ")\n",
        "\n",
        "# Print a summary of the model's architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "yEWhzsnqaUIz",
        "outputId": "4b0967cb-d6f6-450d-ed04-adb142be82b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_153\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_153\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_151 (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m1\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_302 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_40               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_427 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_layer_97         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m198,400\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoderLayer\u001b[0m)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_layer_98         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m198,400\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoderLayer\u001b[0m)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_54          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_307 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_302 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_40               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_427 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_layer_97         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">198,400</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderLayer</span>)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_layer_98         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">198,400</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderLayer</span>)            │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_54          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_307 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m397,697\u001b[0m (1.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">397,697</span> (1.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m397,441\u001b[0m (1.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">397,441</span> (1.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model: \"functional_150\"\n",
        "\n",
        "| Layer (type)                     | Output Shape       | Param #    |\n",
        "|----------------------------------|--------------------|------------|\n",
        "| input_layer_148 (InputLayer)     | (None, 60, 1)      | 0          |\n",
        "| dense_296 (Dense)                | (None, 60, 128)    | 256        |\n",
        "| batch_normalization_39           | (None, 60, 128)    | 512        |\n",
        "| (BatchNormalization)             |                    |            |\n",
        "| dropout_418 (Dropout)            | (None, 60, 128)    | 0          |\n",
        "| transformer_encoder_layer_95     | (None, 60, 128)    | 198,400    |\n",
        "| (TransformerEncoderLayer)        |                    |            |\n",
        "| transformer_encoder_layer_96     | (None, 60, 128)    | 198,400    |\n",
        "| (TransformerEncoderLayer)        |                    |            |\n",
        "| global_average_pooling1d_53      | (None, 128)        | 0          |\n",
        "| (GlobalAveragePooling1D)         |                    |            |\n",
        "| dense_301 (Dense)                | (None, 1)          | 129        |\n",
        "\n",
        "**Total params**: 397,697 (1.52 MB)  \n",
        "**Trainable params**: 397,441 (1.52 MB)  \n",
        "**Non-trainable params**: 256 (1.00 KB)  \n",
        "\n",
        "### Explanation of the Table Structure\n",
        "\n",
        "- **Layer (type)**: The name and type of the layer.\n",
        "- **Output Shape**: The shape of the output produced by the layer.\n",
        "- **Param #**: The number of trainable parameters in the layer.\n",
        "\n",
        "### Layer Details\n",
        "\n",
        "1. **Input Layer**:\n",
        "   - **Layer (type)**: `input_layer_148 (InputLayer)`\n",
        "   - **Output Shape**: `(None, 60, 1)`\n",
        "   - **Param #**: `0`\n",
        "   - **Description**: Receives input data with the specified shape `(60, 1)`.\n",
        "\n",
        "2. **Dense Layer**:\n",
        "   - **Layer (type)**: `dense_296 (Dense)`\n",
        "   - **Output Shape**: `(None, 60, 128)`\n",
        "   - **Param #**: `256`\n",
        "   - **Description**: Applies a linear transformation with 128 neurons and ReLU activation.\n",
        "\n",
        "3. **Batch Normalization Layer**:\n",
        "   - **Layer (type)**: `batch_normalization_39 (BatchNormalization)`\n",
        "   - **Output Shape**: `(None, 60, 128)`\n",
        "   - **Param #**: `512`\n",
        "   - **Description**: Normalizes activations to improve training stability and speed.\n",
        "\n",
        "4. **Dropout Layer**:\n",
        "   - **Layer (type)**: `dropout_418 (Dropout)`\n",
        "   - **Output Shape**: `(None, 60, 128)`\n",
        "   - **Param #**: `0`\n",
        "   - **Description**: Applies dropout to prevent overfitting by randomly deactivating 30% of the units during training.\n",
        "\n",
        "5. **Transformer Encoder Layers**:\n",
        "   - **Layer (type)**: `transformer_encoder_layer_95 (TransformerEncoderLayer)`\n",
        "   - **Output Shape**: `(None, 60, 128)`\n",
        "   - **Param #**: `198,400`\n",
        "   - **Description**: Captures temporal dependencies using multi-head attention and a feed-forward network.\n",
        "   - **Layer (type)**: `transformer_encoder_layer_96 (TransformerEncoderLayer)`\n",
        "   - **Output Shape**: `(None, 60, 128)`\n",
        "   - **Param #**: `198,400`\n",
        "   - **Description**: A second Transformer Encoder layer to further capture temporal dependencies.\n",
        "\n",
        "6. **Global Average Pooling 1D Layer**:\n",
        "   - **Layer (type)**: `global_average_pooling1d_53 (GlobalAveragePooling1D)`\n",
        "   - **Output Shape**: `(None, 128)`\n",
        "   - **Param #**: `0`\n",
        "   - **Description**: Reduces data dimensionality by averaging along the time dimension.\n",
        "\n",
        "7. **Output Layer**:\n",
        "   - **Layer (type)**: `dense_301 (Dense)`\n",
        "   - **Output Shape**: `(None, 1)`\n",
        "   - **Param #**: `129`\n",
        "   - **Description**: Produces the final prediction with a single neuron for regression.\n",
        "\n",
        "### Total Parameters\n",
        "\n",
        "- **Total params**: `397,697` (1.52 MB)\n",
        "  - The total number of parameters in the model, including trainable and non-trainable parameters.\n",
        "- **Trainable params**: `397,441` (1.52 MB)\n",
        "  - The number of parameters that will be updated during training.\n",
        "- **Non-trainable params**: `256` (1.00 KB)\n",
        "  - The number of parameters that will not be updated during training (e.g., normalization parameters).\n",
        "\n",
        "This table provides a detailed overview of the model structure, showing how data flows through the various layers and the number of parameters involved in each layer."
      ],
      "metadata": {
        "id": "kjELoL_AW2hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We implement Early Stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "cEteeRP_bRmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " This technique is used to **prevent overfitting** and improve the model's ability to generalize to new, unseen data.\n",
        "\n",
        "- **Monitoring a metric**: Watching a metric like validation loss (*val_loss*) to assess **model performance on unseen data**.\n",
        "- **Waiting for improvement**: **Allowing a certain number of epochs** (*patience*) for the metric to improve **before stopping**.\n",
        "- **Restoring best weights**: **Reverting to the model weights** that achieved the **best performance** on the monitored metric."
      ],
      "metadata": {
        "id": "KQGMQ3JwbeJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping, lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLA0U455WX7y",
        "outputId": "0f68181f-76fa-4f18-c089-e89fde4826cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`.fit()` Arguments:**\n",
        "\n",
        "* **`X_train`:** Training data (input features).\n",
        "* **`y_train`:** Target values for training data.\n",
        "* **`epochs`:** Number of training iterations over the entire dataset (default: 1).\n",
        "* **`batch_size`:** Number of samples processed before updating model weights (default: 32).\n",
        "* **`validation_data`:** Data used to evaluate the model during training.\n",
        "* **`verbose`:** Controls the amount of training output (0: silent, 1: progress bar, 2: one line per epoch)."
      ],
      "metadata": {
        "id": "_j3Wifq1Xi1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecasting and evaluation\n",
        "preds = model.predict(X_test) * y_std + y_mean # Denormalize the forecasts\n",
        "y_test = y_test * y_std + y_mean # Denormalize the actual values\n",
        "\n",
        "plt.plot(y_test, label='Actual Values')\n",
        "plt.plot(preds, label='Forecast', linestyle='dashed')\n",
        "plt.legend()\n",
        "plt.title(\"Temperature Forecast with Transformer\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "ZLNSbU8mCADE",
        "outputId": "8a80779c-5ccf-4b0f-e640-93ddae8b84ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgVpJREFUeJzt3Xd8U9X7B/BPkjbpTuluoYsyyh5llT0KFRGZgvxQQUFQC8hwoSLiwoUiKji+CDhRVFRAQGQUZO9NaaGlpZOWNt0rub8/bpI2dCUdSQuf9+uVV9ubm5vT2zT3yTnPeY5EEAQBRERERGYitXQDiIiI6N7C4IOIiIjMisEHERERmRWDDyIiIjIrBh9ERERkVgw+iIiIyKwYfBAREZFZMfggIiIis2LwQURERGbF4IOICMD06dMREBBg9L4ODg4N26BG5oMPPkDLli0hk8nQtWtXSzeHmjgGH/cIiURi1G3fvn2WbqrFrF69GuvXr7d0Myo1ePDgKv9mV65csXTzGlR+fj5ef/11s782G+J5169fb9T/obFBkLn8888/eOGFF9CvXz+sW7cO77zzjqWbRE2claUbQObx3XffGfz87bffYteuXRW2t2vXzpzNalRWr14NNzc3TJ8+3dJNqVSLFi2wfPnyCtt9fHws0Brzyc/Px7JlywCIQVhD+frrr6HRaBr0eQcOHFjhf27mzJno1asXZs2apd/W2HpV9uzZA6lUirVr10Iul1u6OXQXYPBxj3jkkUcMfj5y5Ah27dpVYfvdQhAEFBYWwtbW9q5ph1KpbJC/V2M5V5ZmbW3d4M/RsmVLtGzZ0mDbU089hZYtW1b7ty0tLYVGo7HYhT8tLQ22trb19vyN5TWXn58POzs7i7bhXsVhF9LTaDRYuXIlOnToABsbG3h6emL27NnIzMw02C8gIAAPPPAA9u3bhx49esDW1hadOnXSd0///vvv6NSpE2xsbBASEoLTp08bPF43Xn79+nWEh4fD3t4ePj4+eOONN3DnIsumtmnnzp36Nn355ZcAgHXr1mHo0KHw8PCAQqFA+/btsWbNmgqPv3jxIiIjI/Vd37pPu6+//jokEkmF86XrQo+LizOqHVlZWZg/fz58fX2hUCjQqlUrvPfeewaftuuitLQUb775JoKCgqBQKBAQEICXX34ZRUVFRp8rY9uo0WjwySef6P/O7u7uuO+++3DixAn9PsacdwA4ceIEwsPD4ebmBltbWwQGBuKJJ54AAMTFxcHd3R0AsGzZMv3f5vXXX6/0HGRlZUEmk2HVqlX6benp6ZBKpXB1dTV4fT399NPw8vLS/1w+58PY501MTMTYsWPh4OAAd3d3PPfcc1Cr1ZW2zVhxcXGQSCT48MMPsXLlSv3f89KlSyguLsZrr72GkJAQKJVK2NvbY8CAAdi7d2+Vx/jqq6/0x+jZsyeOHz9usG9KSgoef/xxtGjRAgqFAt7e3hgzZoz+dS2RSLBu3Trk5eXpz4NueLKur7l9+/ZBIpHgl19+wbJly9C8eXM4Ojpi4sSJUKlUKCoqwvz58+Hh4QEHBwc8/vjjFY4NAN9//z1CQkJga2sLFxcXPPzww0hISDDYZ/DgwejYsSNOnjyJgQMHws7ODi+//HKd/lZUe+z5IL3Zs2dj/fr1ePzxxzFv3jzExsbis88+w+nTp3Hw4EGDT4YxMTH4v//7P8yePRuPPPIIPvzwQ4wePRpffPEFXn75ZTzzzDMAgOXLl2PSpEmIioqCVFoW66rVatx3333o06cP3n//fezYsQNLly5FaWkp3njjjVq1KSoqClOmTMHs2bPx5JNPom3btgCANWvWoEOHDnjwwQdhZWWFLVu24JlnnoFGo0FERAQAYOXKlZg7dy4cHBzwyiuvAAA8PT1rdR4ra0d+fj4GDRqExMREzJ49G35+fjh06BAWL16M5ORkrFy5ssbjqtVqpKenG2yzsbHRd9HPnDkTGzZswMSJE7Fo0SIcPXoUy5cvx+XLl7F58+Z6beOMGTOwfv16jBw5EjNnzkRpaSkOHDiAI0eOoEePHkaf97S0NIwYMQLu7u546aWX4OzsjLi4OPz+++8AAHd3d6xZswZPP/00xo0bh/HjxwMAOnfuXOk5cnZ2RseOHbF//37MmzcPAPDff/9BIpHg9u3buHTpEjp06AAAOHDgAAYMGFDpcYx5XrVajfDwcPTu3Rsffvgh/v33X6xYsQJBQUF4+umna/hr1mzdunUoLCzErFmzoFAo4OLiguzsbPzvf//DlClT8OSTTyInJwdr165FeHg4jh07ViER9Mcff0ROTg5mz54NiUSC999/H+PHj8f169f1/zsTJkzAxYsXMXfuXAQEBCAtLQ27du1CfHw8AgIC8N133+Grr77CsWPH8L///Q8A0LdvXwB1f83pLF++HLa2tnjppZcQExODTz/9FNbW1pBKpcjMzMTrr7+OI0eOYP369QgMDMRrr72mf+zbb7+NJUuWYNKkSZg5cyZu3bqFTz/9FAMHDsTp06fh7Oys3zcjIwMjR47Eww8/jEceeaTW/+NUDwS6J0VERAjl//wHDhwQAAg//PCDwX47duyosN3f318AIBw6dEi/befOnQIAwdbWVrhx44Z++5dffikAEPbu3avfNm3aNAGAMHfuXP02jUYjjBo1SpDL5cKtW7dq3aYdO3ZU+F3z8/MrbAsPDxdatmxpsK1Dhw7CoEGDKuy7dOlSobJ/lXXr1gkAhNjY2Brb8eabbwr29vbC1atXDba/9NJLgkwmE+Lj4yscv7xBgwYJACrcpk2bJgiCIJw5c0YAIMycOdPgcc8995wAQNizZ0+9tXHPnj0CAGHevHkV2qnRaPTfG3PeN2/eLAAQjh8/XuXvfuvWLQGAsHTp0ir3KS8iIkLw9PTU/7xw4UJh4MCBgoeHh7BmzRpBEAQhIyNDkEgkwieffKLfb9q0aYK/v79Rz6t7Db/xxhsG27t16yaEhIQY1U4de3t7/d9REAQhNjZWACA4OTkJaWlpBvuWlpYKRUVFBtsyMzMFT09P4YknnqhwDFdXV+H27dv67X/++acAQNiyZYv+sQCEDz74oNo2Tps2TbC3tzfYVh+vub179woAhI4dOwrFxcX67VOmTBEkEokwcuRIg/1DQ0MN/kZxcXGCTCYT3n77bYP9zp8/L1hZWRls1/0PffHFF9X+rmQeHHYhAMCmTZugVCoxfPhwpKen628hISFwcHCo0K3bvn17hIaG6n/u3bs3AGDo0KHw8/OrsP369esVnnPOnDn67yUSCebMmYPi4mL8+++/tWpTYGAgwsPDKzxP+XFllUqF9PR0DBo0CNevX4dKpTL6HBmrsnZs2rQJAwYMQLNmzQx+l7CwMKjVauzfv7/G4wYEBGDXrl0GtxdeeAEA8PfffwMAFi5caPCYRYsWAQC2bdtWb2387bffIJFIsHTp0gptLD88Zcx5130q3bp1K0pKSmo8B8YYMGAAUlNTERUVBUDs4Rg4cCAGDBiAAwcOABB7QwRBqLLnw1hPPfVUheeu7LVeGxMmTNAP/ejIZDJ93oVGo8Ht27dRWlqKHj164NSpUxWOMXnyZDRr1sygfUDZ/6Muj2Pfvn0VhjJrUh+vOZ3HHnvMoBezd+/eEARBP/xWfntCQgJKS0sBiEO8Go0GkyZNMnjNenl5oXXr1hXeIxQKBR5//HGTfk9qGBx2IQBAdHQ0VCoVPDw8Kr0/LS3N4OfyAQYgJkMCgK+vb6Xb73xjk0qlFRLv2rRpAwD6sWZT2xQYGFjpfgcPHsTSpUtx+PBh5OfnG9ynUqn0bawvlbUjOjoa586dq3Ax0bnzd6mMvb09wsLCKr3vxo0bkEqlaNWqlcF2Ly8vODs748aNG/XWxmvXrsHHxwcuLi7VtteY8z5o0CBMmDABy5Ytw8cff4zBgwdj7Nix+L//+z8oFIpqj18V3QX2wIEDaNGiBU6fPo233noL7u7u+PDDD/X3OTk5oUuXLrV6DgD6XJfymjVrZvJFvCpVvZ43bNiAFStW4MqVKwYBW2X73/l/qgtEdG1UKBR47733sGjRInh6eqJPnz544IEH8Nhjjxnkw1SmPl5zVbWzuvcTjUYDlUoFV1dXREdHQxAEtG7dutLj3plE3Lx5c87WaSQYfBAA8VOUh4cHfvjhh0rvr+wTWGWq2i7ckUjaEG2qLHP+2rVrGDZsGIKDg/HRRx/B19cXcrkcf//9Nz7++GOjkj0rSzYFUGViYWXt0Gg0GD58uL6n4k66wKuuqmrrnRq6jcaed4lEgl9//RVHjhzBli1bsHPnTjzxxBNYsWIFjhw5Uqsppz4+PggMDMT+/fsREBAAQRAQGhoKd3d3PPvss7hx4wYOHDiAvn37GuQhmaqq13p9qexv9P3332P69OkYO3Ysnn/+eXh4eEAmk2H58uW4du2a0W0s//84f/58jB49Gn/88Qd27tyJJUuWYPny5dizZw+6detWYzvr8pqrqZ01tV+j0UAikWD79u2V7nvn68fSs2uoDIMPAgAEBQXh33//Rb9+/czyD6rRaHD9+nWDC9rVq1cBQD/joD7atGXLFhQVFeGvv/4y+HR1Z3csUPWbqO7TYlZWlkHy2p2f7KoTFBSE3NzcKnsu6srf3x8ajQbR0dEGtVpSU1ORlZUFf3//emtjUFAQdu7cidu3b1fZ+2HKeQeAPn36oE+fPnj77bfx448/YurUqdi4cSNmzpxp9MWtvAEDBmD//v0IDAxE165d4ejoiC5dukCpVGLHjh04deqUvoZHVWrzvA3t119/RcuWLfH7778btK+yITBTBAUFYdGiRVi0aBGio6PRtWtXrFixAt9//32Vj6mP11xdBQUFQRAEBAYG1lsAT+bBnA8CAEyaNAlqtRpvvvlmhftKS0uRlZVV78/52Wef6b8XBAGfffYZrK2tMWzYsHprk+7TUPlPeiqVCuvWrauwr729faXHDAoKAgCDvIy8vDxs2LChxufXmTRpEg4fPoydO3dWuC8rK0s/hl1b999/PwBUmDXz0UcfAQBGjRpVb22cMGECBEGo9OKtO8/GnvfMzMwKvWK6GRu6KZW6OgymvAYHDBiAuLg4/Pzzz/phGKlUir59++Kjjz5CSUlJjfketXnehlbZeT169CgOHz5cq+Pl5+ejsLDQYFtQUBAcHR0rndJaXn285upq/PjxkMlkWLZsWYXXkSAIyMjIaPA2UO2w54MAAIMGDcLs2bOxfPlynDlzBiNGjIC1tTWio6OxadMmfPLJJ5g4cWK9PZ+NjQ127NiBadOmoXfv3ti+fTu2bduGl19+WT+cUh9tGjFiBORyOUaPHo3Zs2cjNzcXX3/9NTw8PJCcnGywb0hICNasWYO33noLrVq1goeHB4YOHYoRI0bAz88PM2bMwPPPPw+ZTIZvvvkG7u7uiI+PN+r3ff755/HXX3/hgQcewPTp0xESEoK8vDycP38ev/76K+Li4uDm5la7kwmgS5cumDZtGr766itkZWVh0KBBOHbsGDZs2ICxY8diyJAh9dbGIUOG4NFHH8WqVasQHR2N++67DxqNBgcOHMCQIUMwZ84co8/7hg0bsHr1aowbNw5BQUHIycnB119/DScnJ/3FzdbWFu3bt8fPP/+MNm3awMXFBR07dkTHjh2r/F10gUVUVJRBKfCBAwdi+/bt+poX1anN8za0Bx54AL///jvGjRuHUaNGITY2Fl988QXat2+P3Nxck4939epVDBs2DJMmTUL79u1hZWWFzZs3IzU1FQ8//HC1j62P11xdBQUF4a233sLixYsRFxeHsWPHwtHREbGxsdi8eTNmzZqF5557rsHbQbVg9vk11CjcOdVW56uvvhJCQkIEW1tbwdHRUejUqZPwwgsvCElJSfp9/P39hVGjRlV4LAAhIiLCYJtuyl/5qXy6aXvXrl0TRowYIdjZ2Qmenp7C0qVLBbVaXa9tEgRB+Ouvv4TOnTsLNjY2QkBAgPDee+8J33zzTYVpsikpKcKoUaMER0dHAYDBtNuTJ08KvXv3FuRyueDn5yd89NFHVU61raodOTk5wuLFi4VWrVoJcrlccHNzE/r27St8+OGHBtMMKzNo0CChQ4cO1e5TUlIiLFu2TAgMDBSsra0FX19fYfHixUJhYaHBfvXRxtLSUuGDDz4QgoODBblcLri7uwsjR44UTp48qd/HmPN+6tQpYcqUKYKfn5+gUCgEDw8P4YEHHhBOnDhh0K5Dhw4JISEhglwuN3rarYeHhwBASE1N1W/777//BADCgAEDKux/51Tb6p63sqmnglD1tOzqVDXVtrLprxqNRnjnnXcEf39/QaFQCN26dRO2bt1aoe3VHaP875Geni5EREQIwcHBgr29vaBUKoXevXsLv/zyi8Fjqvp96/qa00213bRpk8F23f/WnVOwdedXNx1f57fffhP69+8v2NvbC/b29kJwcLAQEREhREVF6fcx5n+IzEciCLXIBCSqg+nTp+PXX3+t1Sc1IiJq+pjzQURERGbF4IOIiIjMisEHERERmRVzPoiIiMis2PNBREREZsXgg4iIiMyq0RUZ02g0SEpKgqOjY6Msb0xEREQVCYKAnJwc+Pj41LhuUqMLPpKSkiqsZEhERERNQ0JCAlq0aFHtPo0u+HB0dAQgNt7JycnCrSEiIiJjZGdnw9fXV38dr06jCz50Qy1OTk4MPoiIiJoYY1ImmHBKREREZsXgg4iIiMyKwQcRERGZVaPL+TCGIAgoLS2FWq22dFOoiZDJZLCysuL0bSKiRqDJBR/FxcVITk5Gfn6+pZtCTYydnR28vb0hl8st3RQiontakwo+NBoNYmNjIZPJ4OPjA7lczk+yVCNBEFBcXIxbt24hNjYWrVu3rrEADhERNZwmFXwUFxdDo9HA19cXdnZ2lm4ONSG2trawtrbGjRs3UFxcDBsbG0s3iYjontUkP/7xUyvVBl83RESNA9+NiYiIyKwYfBAREZFZMfggAGI53D/++KNBn2Pw4MGYP39+gz4HERE1fgw+zOzw4cOQyWQYNWqUyY8NCAjAypUr679RNRg9ejTuu+++Su87cOAAJBIJzp07Z+ZWERFRU8Xgw8zWrl2LuXPnYv/+/UhKSrJ0c4wyY8YM7Nq1Czdv3qxw37p169CjRw907tzZAi0jIro7XU7OxreH46DRCJZuSoNo8sGHIAjILy61yE0QTHtR5Obm4ueff8bTTz+NUaNGYf369RX22bJlC3r27AkbGxu4ublh3LhxAMQhixs3bmDBggWQSCT6+iavv/46unbtanCMlStXIiAgQP/z8ePHMXz4cLi5uUGpVGLQoEE4deqU0e1+4IEH4O7uXqG9ubm52LRpE2bMmIGMjAxMmTIFzZs3h52dHTp16oSffvqp2uNWNtTj7Oxs8DwJCQmYNGkSnJ2d4eLigjFjxiAuLk5//759+9CrVy/Y29vD2dkZ/fr1w40bN4z+3YiIGhtBEBDx4ym89udF/HMp1dLNaRBNqs5HZQpK1Gj/2k6LPPelN8JhJzf+FP7yyy8IDg5G27Zt8cgjj2D+/PlYvHixPpDYtm0bxo0bh1deeQXffvstiouL8ffffwMAfv/9d3Tp0gWzZs3Ck08+aVI7c3JyMG3aNHz66acQBAErVqzA/fffj+joaDg6Otb4eCsrKzz22GNYv349XnnlFX17N23aBLVajSlTpiA3NxchISF48cUX4eTkhG3btuHRRx9FUFAQevXqZVJ7dUpKShAeHo7Q0FAcOHAAVlZWeOutt3Dffffh3LlzkEqlGDt2LJ588kn89NNPKC4uxrFjx1h4joiatCspObh+Kw8AcCz2Nu7r6GXhFtW/Jh98NCVr167FI488AgC47777oFKpEBkZicGDBwMA3n77bTz88MNYtmyZ/jFdunQBALi4uEAmk8HR0RFeXqa9EIcOHWrw81dffQVnZ2dERkbigQceMOoYTzzxBD744AOD9q5btw4TJkyAUqmEUqnEc889p99/7ty52LlzJ3755ZdaBx8///wzNBoN/ve//+kDinXr1sHZ2Rn79u1Djx49oFKp8MADDyAoKAgA0K5du1o9FxFRY/H3+WT99yfjMy3YkobT5IMPW2sZLr0RbrHnNlZUVBSOHTuGzZs3AxB7EyZPnoy1a9fqL+ZnzpwxuVfDGKmpqXj11Vexb98+pKWlQa1WIz8/H/Hx8UYfIzg4GH379sU333yDwYMHIyYmBgcOHMAbb7wBAFCr1XjnnXfwyy+/IDExEcXFxSgqKqpTJdqzZ88iJiamQu9MYWEhrl27hhEjRmD69OkIDw/H8OHDERYWhkmTJsHb27vWz0lEZEmCIGBbueDjYqIKhSVq2JhwvWkKmnzwIZFITBr6sJS1a9eitLQUPj4++m2CIEChUOCzzz6DUqmEra2tyceVSqUVck9KSkoMfp42bRoyMjLwySefwN/fHwqFAqGhoSguLjbpuWbMmIG5c+fi888/x7p16xAUFIRBgwYBAD744AN88sknWLlyJTp16gR7e3vMnz+/2ueQSCTVtl03lPPDDz9UeKy7uzsAsSdk3rx52LFjB37++We8+uqr2LVrF/r06WPS70ZE1BhEp+Xi+q08yGVS2CtkyMwvwbmbKvQKdLF00+pVk084bQpKS0vx7bffYsWKFThz5oz+dvbsWfj4+OgTMzt37ozdu3dXeRy5XA61Wm2wzd3dHSkpKQYX8TNnzhjsc/DgQcybNw/3338/OnToAIVCgfT0dJN/j0mTJkEqleLHH3/Et99+iyeeeEI/HHLw4EGMGTMGjzzyCLp06YKWLVvi6tWr1R7P3d0dycllEX50dLTBasXdu3dHdHQ0PDw80KpVK4ObUqnU79etWzcsXrwYhw4dQseOHfHjjz+a/LsRETUG286J74kD27ihd6ArAODkjbtv6MXk4CMnJwfz58+Hv78/bG1t0bdvXxw/flx/vyAIeO211+Dt7Q1bW1uEhYUhOjq6Xhvd1GzduhWZmZmYMWMGOnbsaHCbMGEC1q5dCwBYunQpfvrpJyxduhSXL1/G+fPn8d577+mPExAQgP379yMxMVEfPAwePBi3bt3C+++/j2vXruHzzz/H9u3bDZ6/devW+O6773D58mUcPXoUU6dOrVUvi4ODAyZPnozFixcjOTkZ06dPN3iOXbt24dChQ7h8+TJmz56N1NTqs7SHDh2Kzz77DKdPn8aJEyfw1FNPwdraWn//1KlT4ebmhjFjxuDAgQOIjY3Fvn37MG/ePNy8eROxsbFYvHgxDh8+jBs3buCff/5BdHQ08z6IqMnafkEMPkZ29EaPgGYAgJM3bluySQ3C5OBj5syZ2LVrF7777jucP38eI0aMQFhYGBITEwEA77//PlatWoUvvvgCR48ehb29PcLDw1FYWFjvjW8q1q5di7CwMINP6zoTJkzAiRMncO7cOQwePBibNm3CX3/9ha5du2Lo0KE4duyYft833ngDcXFxCAoK0g87tGvXDqtXr8bnn3+OLl264NixYwaJn7rnz8zMRPfu3fHoo49i3rx58PDwqNXvMmPGDGRmZiI8PNxgCOnVV19F9+7dER4ejsGDB8PLywtjx46t9lgrVqyAr68vBgwYgP/7v//Dc889Z5AjYmdnh/3798PPzw/jx49Hu3btMGPGDBQWFsLJyQl2dna4cuUKJkyYgDZt2mDWrFmIiIjA7Nmza/W7ERFZUkxaDq6m5sJaJkFYe09099cFH5kml3Zo7CSCCb9RQUEBHB0d8eeffxpU6AwJCcHIkSPx5ptvwsfHB4sWLdJfAFUqFTw9PbF+/Xo8/PDDNT5HdnY2lEolVCoVnJycDO4rLCxEbGwsAgMDuSQ6mYyvHyJqzFbtjsZHu65iSFt3rHu8F4pK1ej0+j8oLtVgz6JBaOnuYOkmVqu66/edTOr5KC0thVqtrvDGbWtri//++w+xsbFISUlBWFiY/j6lUonevXvj8OHDlR6zqKgI2dnZBjciIqJ7jW6K7chO4ow9hZUMnZuLPeZ3W96HScGHo6MjQkND8eabbyIpKQlqtRrff/89Dh8+jOTkZKSkpAAAPD09DR7n6empv+9Oy5cv19eJUCqV8PX1reWvQkRE1DRdv5WLKyk5sJJKMKJ92TU0RDv0cuouq/dhcs7Hd999B0EQ0Lx5cygUCqxatQpTpkyBVFq7iTOLFy+GSqXS3xISEmp1HCIioqZq+wXxA3rfVm5wtpPrt+uCjxNx93jwERQUhMjISOTm5iIhIQHHjh1DSUkJWrZsqa+8eecsh9TU1CqrcioUCjg5ORnciIiI7iW6IZf77yilrks6jU7LhSq/pMLjamPjsXjcyMirl2PVVq3rfNjb28Pb2xuZmZnYuXMnxowZg8DAQHh5eRnUqsjOzsbRo0cRGhpaLw0mIiK6m9zIyMPFpGzIpBKM6GAYfLg5KBDgKs4CPJVQ996P9Qdj8dLv5/HwV0dwO8+0QpP1yeTSoDt37oQgCGjbti1iYmLw/PPPIzg4GI8//jgkEgnmz5+Pt956C61bt0ZgYCCWLFkCHx+fGqddEhER3Yv+Pi8OuYS2dIWLvbzC/d39myEuIx+nbmRiSNvalUkAgA2H4vD6lksAgHHdmqOZnXUNj2g4JgcfKpUKixcvxs2bN+Hi4oIJEybg7bff1heHeuGFF5CXl4dZs2YhKysL/fv3x44dOzi1kYjoHrc3Kg2JmQWY2tuPq0+XUzbLpfL0hBD/Zvj9VGKd8j6+PRyHpX9dBAA8PTgIz4e3tejfwOTgY9KkSZg0aVKV90skErzxxhv6BceIiIgKS9R45vtTKChRQy6TYlJPzmwEgITb+TifqIJUAoR3qDz46OEvrutyJiELpWoNrGSmZUx8dzgOr/0pBh6zB7XECxYOPACu7UJERGZw+HoGCkrEtane3HYJqdn3btXr8nTl1HsHusLNQVHpPq09HOCosEJBiRpXUnJMOv73R25giS7wGNgSL90XbPHAA2DwQUREZrDvSpr++5zCUiz548JdVzK8NrZp8z3ur2LIBQCkUgm6lSu1bqwfjt7Aq39cAADMGtgSL41sHIEHwODDbKZPnw6JRFLhFhMTY+mm1cr69evh7Oxs6WYQURMgCAL2Rt0CADw3og2spBL8cykV284n1/DIu9vNzHycTciCRAKEd6w6+ACAED/Tgo8fj8bjlc1i4DGzfyAWN6LAA2DwYVb33XcfkpOTDW6BgYEmH6e42HLTo4iITHXtVh7ib+dDLpPi8X6BeGZIKwDA0j8vWnS6p6Xt0BYW6xngAg/H6idlhJjQ8/HbyZt4efN5AMCM/oF4ZVS7RhV4AHdT8FGcV/WtpNCEfQuM27cWFAoFvLy8DG4ymQyRkZHo1asXFAoFvL298dJLL6G0tFT/uMGDB2POnDmYP38+3NzcEB4eDgC4cOECRo4cCQcHB3h6euLRRx9Fenq6/nEajQbvv/8+WrVqBYVCAT8/P7z99tv6+1988UW0adMGdnZ2aNmyJZYsWYKSkrIiNmfPnsWQIUPg6OgIJycnhISE4MSJE9i3bx8ef/xxqFQqfQ/O66+/XqtzQkR3v31R4pBL75YusFdYYc6QVmjj6YCMvGK8seWihVtnOVUVFqtMVz9nSCVAYlYBklUFVe6XlFWAJX+KPR5P9AvEq40w8ABqMdul0XrHp+r7Wo8Apm4q+/mDVkBJfuX7+vcHHt9W9vPKTkB+RsX9XlfVrp13SExMxP3334/p06fj22+/xZUrV/Dkk0/CxsbG4IK+YcMGPP300zh48CAAICsrC0OHDsXMmTPx8ccfo6CgAC+++CImTZqEPXv2ABBL13/99df4+OOP0b9/fyQnJ+PKlSv6Yzo6OmL9+vXw8fHB+fPn8eSTT8LR0REvvPACAGDq1Kno1q0b1qxZA5lMhjNnzsDa2hp9+/bFypUr8dprryEqKgoA4ODQuFdbJCLL2asNPnQ1KuRWUrw/sQvGrz6IP84k4cGuPhga7FndIe46yaoCnIrPAlC2kFx1HBRWCPZywqXkbJy6kYVRnW0r3e+NLZeQX6xGiH+zRht4AHdT8NEEbN261eAiPXLkSLRp0wa+vr747LPPIJFIEBwcjKSkJLz44ot47bXX9GvmtG7dGu+//77+sW+99Ra6deuGd955R7/tm2++ga+vL65evQpvb2988skn+OyzzzBt2jQAYmn8/v376/d/9dVX9d8HBATgueeew8aNG/XBR3x8vL6InK4NOkqlEhKJpMqy+UREAJBbVIpjsbcBAEOCywpkdfV1xoz+gfj6QCxe/v0C/lnoAicbyxW9Mrd92hyY7n7O8HQyrg5WiH8zXErOxskbmRjVuWLAsvdKGnZcTIFMKsHb4zpCKm2cgQdwNwUfLydVfZ9EZvjz89UkeUruGImaf772bbrDkCFDsGbNGv3P9vb2iIiIQGhoqEF02q9fP+Tm5uLmzZvw8/MDAISEhBgc6+zZs9i7d2+lPQ7Xrl1DVlYWioqKMGzYsCrb8/PPP2PVqlW4du0acnNzUVpaarC2zsKFCzFz5kx89913CAsLw0MPPYSgoKBa//5EdO85GJOOErWAAFc7BLrZG9y3cHhb/HMpFTcy8vHu9it4Z1wnC7XS/I5cF3vU+7dyM/oxIf7N8N2RGzhZyQq3BcVqvPaXONwyo38ggr0a9zppd0/Oh9y+6pu1jQn72hq3by3Y29ujVatW+pu3d81dbeUfW15ubi5Gjx6NM2fOGNyio6MxcOBA2NpW3iWnc/jwYUydOhX3338/tm7ditOnT+OVV14xSGZ9/fXXcfHiRYwaNQp79uxB+/btsXnzZtN+aSK6p+nyPQZXUhbcVi7Du+M7AxBnZxy+VskQ911IEAT979onyNXox+mSTi8mqlBQrDa477O90Ui4XQAfpQ2eHda6soc3KndP8NFEtWvXDocPHzaY737w4EE4OjqiRYsWVT6ue/fuuHjxIgICAgwCmlatWsHe3h6tW7eGra2twSJ/5R06dAj+/v545ZVX0KNHD7Ru3Ro3btyosF+bNm2wYMEC/PPPPxg/fjzWrVsHAJDL5VCr1RX2JyLSEQQBe6+Iwwvlh1zKCw1yxf/1Fnt4X/r9XIWL6t0oNj0PaTlFkMuk6K6dQmuMFs1s4eGoQKlGwLmbWfrtMWk5+Gr/dQDA0gc7wF7R+Ac1GHxY2DPPPIOEhATMnTsXV65cwZ9//omlS5di4cKF+nyPykREROD27duYMmUKjh8/jmvXrmHnzp14/PHHoVarYWNjgxdffBEvvPACvv32W1y7dg1HjhzB2rVrAYj5G/Hx8di4cSOuXbuGVatWGfRqFBQUYM6cOdi3bx9u3LiBgwcP4vjx42jXrh0AMUckNzcXu3fvRnp6OvLzq0jgJaJ71uXkHKRkF8LGWoregS5V7rd4ZDC8lTa4kZGPz/c2zdpHpjisHXLp5ucMG2tZDXuXkUgkZVNutUMvgiDg1T8uoEQtYFiwB0a0bxqJuww+LKx58+b4+++/cezYMXTp0gVPPfUUZsyYYZAMWhkfHx8cPHgQarUaI0aMQKdOnTB//nw4Ozvrg5YlS5Zg0aJFeO2119CuXTtMnjwZaWliF+iDDz6IBQsWYM6cOejatSsOHTqEJUuW6I8vk8mQkZGBxx57DG3atMGkSZMwcuRILFu2DADQt29fPPXUU5g8eTLc3d0NkmGJiICyWS79gtyqvcg62lhjyQPtAQAbj8ejRK0xS/ss5ch1MQG3T0vjh1x0dMHHKW29j82nE3Hk+m3YWEvx+oMdGu3sljtJhEZW3zY7OxtKpRIqlcog+REACgsLERsbi8DAQK6SSybj64fIvB764hCOx2XizbEd8Wgf/2r3LVFrELp8N9Jzi/H1Yz0wvAl8gs8vLsWne2IwLNgDPQKq7tkpTxAE9Hx7N9Jzi7BxVh+TA5BT8ZkYv/oQmtlZY+9zgzFsRSQy8orxwn1t8czgVrX5NepNddfvO7Hng4iI6p0qv0RfjXNIW/ca97eWSTGuW3MAwKYTCQ3atvry6Z4YrNl3DS/8ds7odWqu3cpDem4R5FZSdPV1Nvk5O/ooIbeSIjO/BHN/Oo2MvGK09nDAzP4tTT6WJTH4ICKierc/+hY0AtDG0wEtmtkZ9ZiJIb4AgD1X0pCRW9SQzauztJxCrDsYCwC4fisPUanGrTary/cI8WtmUr6HjtxKii4tlACAA9FiRes3x3aE3KppXc6bVmuJiKhJuLOqqTHaejmicwslSjUC/jxTTe2mRuDzPTEoLCnLTfn7nHGL5Onqe9Qm30Onu3/ZDJnx3ZvX6ViWwuCDiIjqlUYjIFJbwbOy+h7VmRgilhjYdPJmvberviTczsePx+IBAJN7iL01f2sXiauOIAg4qg0+Qk2o73GnXtr8EqWtNV6+v12tj2NJTTL4aGQ5stRE8HVDZB7nE1XIyCuGg8IKPQKMr2MBAA928YFcJsXl5GxcTKqfNbTq2ye7o1GiFjCgtRteeaAd5DIpYtJycbWGoZeYtFyk5xZDYSVFF19lrZ9/SFsPLB3dHhue6AU3B0Wtj2NJTSr4sLYW6/6zpgTVhu51o3sdEVHD2HNFHHIZ0NoN1jLTLjPOdnL9TJdNJxpf70d0ag5+PyW267kRbeFkY40BrcUS6dtqGHrR5Xv0CGgGhZXp+R46UqkEj/cLrFXCamPR+MuglSOTyeDs7KyvVWFnZ9dk5jST5QiCgPz8fKSlpcHZ2RkyWe3/6YmoZvtqke9R3sQeLbDtfDL+PJOIl+9v16iSKT/adRUaAQjv4Iku2ov//Z28sftKGv4+n4wFw9tU+VhdvkdoE8zRqG9NKvgAoF9FVReAEBnL2dmZq/ASNbBbOUU4e1McLhlkxBTbygxo5QYPRwXScoqw50oq7uto/DpYDenczSxsv5ACiQRYNKKtfntYe09YyySITstFdGoOWns6VnisRiPUqbjY3abJBR8SiQTe3t7w8PBASUmJpZtDTYS1tTV7PIjMYP9VMdG0g4+T0UvF38lKJsX47i3wReQ1/HryZqMJPj785yoAYFzX5mhTLsBQ2lpjQGt37LmShr/Pp+DZSoKP6LRc3M4rhq21DJ1bOJuryY1Wkws+dGQyGS8mRESNTG2m2FZmYogYfOyNuoW0nEJ4ODZMVWK1RsCvJxMQ7OWkH0apzJHrGdh/9RaspBLMD6s4tDKyo5c2+EjGs2EVV5U9fE2sydEjoFmjGkayFJ4BIiKqF6Vqjb7nY0hw7YZcdFp5OKCbnzPUGgF/nm64mh8bj8fjxd/OY8znBzHnx1NIuF1xQoMgCPhwZxQAYEovP/i5ViyaNqK9F6xlEkSl5iAmLbfC/RxyMcTgg6gGiVkFGP3pf/i1EdcdIGoMTidkIbuwFM521ujqa9oU28qU1fxIaLCp8uWLmW09l4xhH0Vi+fbLyC4sG9bfG5WGEzcyYWMtxdyhla+forSzRr9W4qyX7ecNZ71oNAKOxNa9uNjdhMEHUQ12X07F+UQVfjx6w9JNIWrUvt5/HQAwuI07ZNK6z0R8oLMPFFZSXE3NxfnEqmt+pGYX4uv91yvttahOanYhjseJPRJrp/VAv1auKC7V4MvI6xj8wT58ezgOxaUafLBTzPWY1jcAHtXksdyvzU3ZdkfwEZWag6z8EtjJZejcovb1Pe4mDD6IapCYWQAASFYVWrglRI3X3itp+OdSKqykEjwzpH5WV1XaWiO8gzhDrbKaH8WlGnwReQ1DP9yHt/++jGc3njbp+H+fT4YgiMvUD2vnie9n9MY303sgyN0et/OK8dqfF9HvvT24nJwNR4UVnhoYVO3xRnTwhJVUgispObh+q2zo5fA1XX0PF5PrntyteBaIapCYJQYfqdmFKFFratib6N5TWKLG61suAgCe6B9oMBOkrh7qIQ69/HU2CYUlav32fVFpuG/lfry7/QryisXtp+KzaqwyWt5WbVGwUZ3EHguJRIKhwZ7YMX8g3hzTAS72ctzKERe4e3JgSzSzl1d7PGc7Ofrqhl7KlVtnfY+KGHwQ1UAXfGgEMQAhIkNf7b+OGxn58HRSYN6wijM96qJvkBu8lTZQFZRg9+U0xGfk48lvT2D6uuO4np4HNwcFPnyoi74q6s/HE4w6blJWAU7eyIREAozqbDiV11omxaOhAdj3/GDMHdoKD/f0xcwBgUYdd1QnsadGV+1UoxFwNFaXbOpi1DHuBU12qi2RueiGXQAgKavQ6OXBie4FCbfz8fneGADAq6Paw0FRv5cVmVSCCd1b4LO9MXjn78u4lVuE4lINrKQSTO8bgHlhreFkYw0Xe2vsupSK30/dxAv3ta2xfLkuOOgZ4FJlPRInG2uDYmLGGN7eCy9vvoBLydmIS89DblEpVAUlcFBYoVNz5nvosOeDqBpFpWqkabtdASAxi+sKEZW3bMslFJVq0DfIFQ90bphiYBO0s14SswpQXKpBv1au2P7sALz6QHs42YhrNQ1s7Q4vJxtk5pdg16XUGo+5VZsUOrqe2+xiL0df7Yq1f19I1g+59AxoBivme+jxTBBVI+WOJNOkLA67EOnsvpyKfy+LSaZvjOnQYGttBbrZ47FQf3TwccKaqd3x/YzeFUqYW8mk+vyQmoZeEm7n42xCFqQSNEj11Pu1OSR/ny8LPjjF1hCDD6JqlB9yAcryP4judeWTTGcMCEQrj/pLMq3MG2M6Ytu8ARjZybvKIGdSD19IJMCB6PRqp93qEk37tHSFu2P9L0kf3sELMqkEFxKzcSBarGwaGsTgozwGH0TVuHlHsJHE4KNO/jyTiDGf/YcbGXmWbkqT92XkNXwRec1iz/9F5DUk3C6Al5MN5g2t3yTT2vJ1sUN/7WyTTSeq7v3Yek4sLPZAZ58GaYeLvVyfXFpUqoGjwgrtvZ0a5LmaKgYfRNXQ9Xy0aGYLgMFHXf3vQCzO3lThm/9iLd2UJu3kjUws334F726/gpuZ5s9Dis/Ix+p9YuCz5IH2sK/nJNO6mNzTFwDwy4mbKK1kanxseh4uJmVDJpXgvo4Nt8q1bugFAHoFujDf4w48G0TV0A2z9AwQP8UkZhY0WJnnu11RqRpXUrIBAH9fSIFaw/NYW1+W6/E4FZ9l9udftuUiiks16N/KDfd3argLeG0Mb++JZnbWSMkuxP7oWxXu36bt9egb5AqXGup21EV4By/oirwy36MiBh9E1dD1dPQIENepyCtWI7uw1JJNarIuJ+egRC0GHLdyinBMW/uATBOTlotdl8tmc5y6kWnW5//3Uip2X0mDtUyC1x9suCTT2lJYyTC+u5h4uvFYxaEXXb7H6AYactFxc1DgwS4+sJfL9FVaqYxJwYdarcaSJUsQGBgIW1tbBAUF4c033zT4JCgIAl577TV4e3vD1tYWYWFhiI6OrveGE5mDruejlbuD/lMSh15q52xClsHP28433EqllqTWCIhOzcHm0zfx1tZLmPvTacSl11+Oy1f7r0EQACcbcajjdLz5go+C4rIk05kDWqKVh4PZntsUuqGX3VfSkJZTNkMtJi0HV1JyYC2TmCUgWDGpK04uGV7pKrj3OpMG6t577z2sWbMGGzZsQIcOHXDixAk8/vjjUCqVmDdvHgDg/fffx6pVq7BhwwYEBgZiyZIlCA8Px6VLl2BjU/WCPESNjUYjIFk7tbZ5M1v4ONvgdl4xkrIK0I7JYyY7ezMLANDNzxmn47Ow/XwKXh/docmPhcdn5OPgtXRcSFThYlI2rqRko7DEMNcgM68Y38/sXefnSs0uxObTiQCAN8d2xLMbz+BiUjYKS9Swsa6+qFZ9WLUnGjczC+CjtKlyddfGoI2nI7r7OeNUfBZ+O5mIpweLa7JsOSv2evRv5QalnXWDt0MmlUAmbfi/S1Nk0n/9oUOHMGbMGIwaNQoBAQGYOHEiRowYgWPHjgEQez1WrlyJV199FWPGjEHnzp3x7bffIikpCX/88UelxywqKkJ2drbBjagxuJVbhGK1BlIJ4OVkAx+lmHRan9NtBUFAUam65h3vAuduiquSPjUoCM521sjIK9aXnW5ocel5+HBnlMEy6fUhK78YIz/Zj8W/n8cPR+NxJiELhSUa2MllCPFvhqm9/WAtk+C/mHQcupZe5+f75r9YlKgF9ApwwYNdfODmoECpRsCFalZ8rS9RKTn6VWuXjekIO3njSTKtzMM9/QAAPx+PhyAIEARBv9psQ81yIeOZFHz07dsXu3fvxtWr4vLCZ8+exX///YeRI0cCAGJjY5GSkoKwsDD9Y5RKJXr37o3Dhw9Xeszly5dDqVTqb76+vrX9XYjqlS7I8HKygZVMCh/n+g8+XvrtPLq/sQtbzt6dQxA6OYUluKZd5TPEvxnu03Z566Y8NrTnNp3FZ3tj8Mm/9TsE/O/lNOQVq+HuqMDsgS2xako37F40COdfD8dvT/fF2+M6YUov8SL44c6oOiUrZxeW4Iej8QCA2YNaQiKRoLufMwDgVAMPvWg0Al7efB6lGgEj2nvq11FpzEZ19oaDwgpxGfk4GnsbUak5iEnLhVwmxfAOjb/9dzuTgo+XXnoJDz/8MIKDg2FtbY1u3bph/vz5mDp1KgAgJUVcxc/T0/AP6+npqb/vTosXL4ZKpdLfEhKMWxSIqKHpptk2106zbe6sm25bf1VOd19JRV6xGnN/Oo1Pd0fftTNpzieqIAjiOXRzUOg/ee64kNLgKwWfjs/ECW1S5u+nbtZrT9M/F8X3tSm9/LD4/nZ4sIsPgtwdIJOWJWHOGdIKNtZSnIrPwp4rabV+rh+OxCO3qBRtPB0wpK0HAKCbn5gIfbqBZ7z8fCIBJ29kwl4uw+sPdmjQ56ov9gorjO4ivs5+Pp6Ardohl0Ft3fUl2clyTAo+fvnlF/zwww/48ccfcerUKWzYsAEffvghNmzYUOsGKBQKODk5GdyIGgNdD4cu6PBxrt9aH9mFJUjPLdb/vGLXVSzadPauHIbRDbl08RUX1urT0gWu9nJk5pfg0LWMBn3uteVqimTml+CfizWv+2GMgmK1fipneDWfpD2cbDCtbwAA4MN/rkJTiynGRaVqfHNQ/D1mDQyCVBvclO/5aKjA9VZOEZb/fRkAsHBEW/3/QVPwsDbx9O/zyfpcmYZaf4ZMY1Lw8fzzz+t7Pzp16oRHH30UCxYswPLlywEAXl5iV2pqquE/d2pqqv4+oqaiQs9HPRca082AcHdU4K2xHSGTSvD7qUQ8uvYYMvOKa3h003JOm2zauYUzAHEdDl2Bp20NOPRyMzMf2y+IvRMjTFxyvSaRV2+hsESDFs1sa6xe+dTAIDgqrHA5OVufd2CKzacScSunCN5KGzzYpSxfoXMLZ1hJJUjNLkKSqmHWHXp72yVkF5aig48TpoX6N8hzNJTOLZQI9nJEUakGiVkFUFhJMawdh1waA5OCj/z8fEilhg+RyWTQaMRu08DAQHh5eWH37t36+7Ozs3H06FGEhobWQ3OJzEfX8+Gj7/kQZ2ulZhfWy1BBrDb4CHS1xyN9/LFuek84KqxwLPY2xq0+iOvaHIm7wdkEseejc4uyJcVHaT+B7ryYiuLShhl6WX8wDmqNgH6tXLHkgfaQSID/YtIRn1H3qqD/XBKDmvAOXjXWumhmL8eTA1sCAD7edbXSyptVUWsEfKVN9JzRPxByq7L3YFu5TD/zqiHqffwXnY4/ziRBIgHeGdepyc1Mkkgk+t4PABga7AGHRlSN9V5m0itp9OjRePvtt7Ft2zbExcVh8+bN+OijjzBu3DgA4h96/vz5eOutt/DXX3/h/PnzeOyxx+Dj44OxY8c2RPuJGkzSHcMubvYKyGVSaAQxAKkrffDhZg8AGNjGHb890xfNnW0Rl5GPcasP6VfEbMrSc4uQmFUAiQTo1Lws+OgdKC7qpSoowcGYus8EuVNOYQk2ans5Zg5oabDuxy/VrPthjBK1Brsvi/kbI4xMvnyifyBc7OW4np6H308lGv1cuy6l4np6HpxsrPCwNnm1vG7aoZf6zvsoLFHj1T/OAwAe6+OPLr7O9Xp8cxnbrbk+YOMsl8bDpODj008/xcSJE/HMM8+gXbt2eO655zB79my8+eab+n1eeOEFzJ07F7NmzULPnj2Rm5uLHTt2sMYHNTl3rusilUrgre39qI+kU13wEaANPgCxPsEfEf3Q1dcZqoISPLr2KN7bcQWn4zNrlSvQGOiGXILcHeBYLtFPJpXg/o66WS+mD0XU5OfjCcgtKkUrDwcMau0OoGz65aaTCSb1PtzpWOxtqApK4GovRw9t6f2aOCis8Iy23sTKf68aldsjCIJ+8bjHQgMq/dTeXZt0Wt8zXlbvjUFcRj48nRRYFN62Xo9tTs52crwzrhOm9w3ACM5yaTRM6n9ydHTEypUrsXLlyir3kUgkeOONN/DGG2/UtW1EFqMqKEFOkVhGvXyCnY/SFjcy8usl7+POng8dd0cFNs7qg0W/nMW288lYs+8a1uy7Bld7OQa39cDQYA8MaONmkLEvCALScopwKSkbl5KzcSkpGzFpuXiwqw8ihli2GFRlQy46ozr7YMPhG/jnUgqKSjtCYVU/BZlK1RqsOxgHQByq0CVoDm/vCRd7OVKzi7Av6hbCajlldKd2lktYO0+DmS01eaSPP/53IBZJqkL8eDQej/cLrHb/Y7G3cSYhC3IrqT5p9U664ONikqreio3FpOVijTboWTq6Q5OfHTIxpAUmhrSwdDOoHA5+EVVC1+vhYi83KKZUX7U+BEGoMvgAABtrGT6d0g0jOnjin4up2H/1FjLyivHbqZv47dRNWEkl6BnggmBvR8Sk5eJSUjYyKklS/fCfKPQNctVPybQEXc9HF22yaXk9/JvB00mB1OwiHLiaXutg4E47LqYgMasArvZyjOvWXL9dbiXFhO7N8fWBWGw8Hl+r5xMEQT9jJryjaY+3sZZh7rBWeGXzBXy+NwaTe/pWW6xL1+vxUEgLuDsqKt3H18UWbg5ypOcW42JSNkL86/a3FgQBr2w+jxK1gCFt3TGyAVd+pXtX08oeIjKTJH2yqeFwYXPtz3UNPjLyipFTWAqJBPCvYt0HqVSCMV2b4/Op3XHqteH48cneeHJAIFq626NUI+Dw9QysOxiHA9HpyMgrhlQCtPZwwNiuPnj5/mCMaO8JQQBe3nyhTkMMdSEIAs7qp9k6V7hfKpXolx6vr4JjgiDg6wPitNRH+vhX6AmYrB162XMlDSm1mCFy7qYKKdmFsJfL0DfIzeTHT+rhCz8XO6TnFut7Z+5UXKrBzosp2Bt1C1IJ8OSAllUeTyKRoKuvrt5H3Yde/jqbhKOxt2FjLcUbYzo2uoXj6O7Ang+iStxZ40Onvmp96KbZ+ihtjeomt5ZJ0TfIDX2D3PDKqPa4kZGHPVfSkHC7AK09HdDe2wltvRwNjjWhexGOxd3G5eRsrD8Uh5nVXMAays3MAtzOK4a1TIJ23o6V7vNAZx+sOxiHXZdS62XY4FR8Js5qhyoe6VNxamgrDwf0DGiG43GZ+O3UTZOHpXRDLoPbetSqrdYyKRYOb4P5P5/Bl5HX8EgffyhtrZGWXYh9Ubew50oa/otJR6522O++jl4GeUGV6e7vjH8vp9Y570OjEfDpnhgAQMTgVvB14YJo1DAYfFClrt3KRXGp5p5dQK0s+DB8862v4ON6NUMuxvB3ta8xX8DVQYHFI4Px4m/n8dGuq7i/k7fZC0TpiosFezlVmc/RzdcZPkobJKnEi+99dezm/5+212Nc1+ZVDlVM7umH43GZ2Hg8Hk8PKivaZYx/LolDLnVJXhzdxQer98XgamounvnhJLLyS3AxyXBdKzcHOYYFe+LFkcE1Hk+fdHojq9ZtAoBdl1MRk5YLRxsrTO8XUKdjEVWHwy5UwY2MPIz+9D+MW30Q6blFlm6ORdxZYExHn/ORWVCnipJxdQw+jPVQiC96+DdDfrEay7RLoZtTWXGxismmOlKpRF/zozYFuMqLz8jX90zMGFB1cDaqkzccFVZIuF2AwyZMZ752KxcxabmwlkkwJNij1u2USSVYNEKcQXIwJgMXk7IhkYhDU/PDWuOvOf1w7OUwvDexM1zs5TUer3MLJWRSCVKyC5Gsql1gLAgCVu8Tc0we7eNvMDOJqL4x+CADgiDgpd/OI79YjcISDSKjblm6SRZxU9/zcWfOhxh85BWrkV1YWuvjVzbNtiFIpRK8Na4jrKQS7LyYin8v1U9pcWOdScgCUHm+R3mjtPUXdl9ORUFx7cvLf3MwFhoBGNTGHW08Kx/mAcTiXGO6ic/507F4o4+vC2xCg9zqPANkRHtPzB7UEg928cGKh7rg+Cth+DOiH+aHtUHnFs4m9cbYya0Q7CX+vrXt/Th8LQNnE7KgsJLiif7V96oR1RWDDzLw07EEg0+Ce6JqvxBWU5ZUxbCLrVym/yRal6EXXfDRsoGDD0Ac8tD1Aiz96yLyi2sfNAHimiYxaTk17qcut9R7ZTNdyuvSQokWzWyRX6zG3lq+5lQFJfriYTOr6fXQ0dX8+OdiKm4bWc5eP8ulHupFSCQSLB7ZDqumdMOEkBZwc6h8iMhYda33oZtaO7mnb53bQlQTBh+kl6wqwDvaBaR060fsv3rLYjMlLKWwRI1bOeJw053DLkDZDJjaBh8ajYC4DPP0fOg8O6w1mjvbIjGrAJ/srtuy8i/9fg5hH+3H3zUMkVy/lYu8YjXs5DK08nCodl+JpGzopbazXjYei0d+sRptPR31lUyr07G5Eh2bO6FYrcHvp27WuH+KqhBnErIgkaBRLinf3d8ZQO2Cj/M3VTgQnQ6ZVFLtzBqi+sLggwDo5vZfQG5RKbr7OWPFpC5oZmeNnMJSnGyANSMas2Tt9Etbaxma2VXsWvdR1i3pNCW7EIUlGlhJJfrqqQ3NTm6FN8aIS6GvPRCLKynZNTyicqr8En3Q8f6OK9WucaObYtvRR2lUIa7R2qGXnRdTEZ1ac89KecWlGqw/FAdAzPUwdnqorvfj5+MJNebw7NKu5dLdrxk8HBtfxeZu2um2FxOzTV4ZefU+cYbLg118OMOFzILBBwEA/jyThD1X0iCXSfH+xM6wlkkxqI1YknrvPZb3UT7ZtLKLWFmhsdqVWNclm/q52MHajAt1DWvnifAOnijViIFmbcq177yYghK1+Li4jPxqewz0xcV8q042La9jcyXC2nlCrRHwxtZLJiX0frX/GpJVhXB3VGBMV+PX73iwqw9srWWITsutscdgp3bIxdi1XMzN39UOLvZyFKs1FWbOVOfarVzs0OayPDUoqKGaR2SAwQchPbdIPxNi3rBWaOUhJq7psvn33QV5H9GpORi/+iD+Oltzl37SHavZ3ql5HaucXjdTsmlllo7uAHu5DCdvZNZqcbUt2iER3SydVbtjqvyUfVabbNq5hnyP8pY80A5ymRQHotOxy8jk2Lj0PKzS1qZ4dVQ7k0q0O9lY64d7vj8SX2XAo8ov0S/yF96hcVb8lEgk6K5dZM6UFW6/jLwGQQDC2nmgrVfVSbpE9YnBRxOmKijBl5HXjEr+q87Svy4iM78E7b2dMLvcJ5+Brd0hlQBXUnLqXNHTkkrVGiz85SxOxWdh9d6YGve/WUWBMZ261vow1zTbyvg422LB8DYAgOXbryDDhKnUt3KK9KvPfvloCDydFEjMKsBPRyvOFiku1eBysvi6rCnZtDx/V3t9suhb2y6jsKT64QNBEPDKH+dRXKrBgNZu+lwlU+iWXN98OhGTvzxS6TDjnqhUlGoEtPV0tEjQaCxdGf3T2sCvJsmqAmw+La6w+/Rgy64BRPcWBh9N2Ef/RGH59iu4b+UBvLfjSq2mKO64kIJt55Ihk0r0wy06zezl+jezptz7se5gHM5rZ11cScmpsXbJnavZ3qmuCafmmmZblel9A9DO2wmqghJs0OZJGGP7hWRoBHFmShtPR8wd2hoA8NneaxVm0FxJyUaxWoNmdtbwdTEtryViSCt4OikQfzsfa/+LrXbfP84k4mBMBhRWUrw1tnalwEP8m2HR8DaQW0lxLO42Jqw5hFnfnjAI6ndeqL9ZLg2pm7bn47SRPR//OxCLErWAXoEudV4ThsgUDD6MoNYIWPz7OXzyb91mCdS3A9Hip9BSjYA1+64h7KNI7L5sfB0HVX4Jlvx5AQAwe2BLdGxecWx+qHboZe+Vphl8xGfkY8WuKACAwkp8uR+6Vn1RqcSsfABV93zotqdmF1abcFmV2AzzTbOtjJVMioghYg/XD0fja+xd0NmiHbIare1dmNTDF74utkjPLcKGQzcM9tUlm3Zu4WxyQGCvsMJL2qqen++NqXL9lcy8Yry5VZydNW9Ya/i71u58SiQSzB3WGvueG4xJPVpAKhGrmI74eD9e/PUcYtPzEHlVzHsa0UiHXHS6tHCGVAIkqQprXLcmM69YX+PkmcHM9SDzYvBhhGOxt/HTsQR8/O9V/XoLlpasKsD19DxIJcDHk7vop1HO2HACs749YdQwyZvbLuFWThGC3O0xb1jrSvcZ3FZMOj0Yk2H0RWr7+WT8WElXvLkJgoCXN59HYYkGfYNc9et8HNQGbVVJrCHnw81BAblMCo0gBiCmKFVrEJ8hBjeW7L4P7+AFb6UNMvKK9UFFdZKyCnA8LhMSCfQ5EnIrKeYPE4dwvoi8huzCEv3+unyPLtVUNq3O2K7N0d3PGfnFary7/XKl+yzffhm384rRxtOhXqaH+jjb4v2JXbBz/kCMaO8JjQD8fCIBQ1fsQ0GJGs2dbdHBp3EvN2CvsEKwl9jGmhJo1x+KQ36xGu29nfTJ5UTmwuDDCHuulPUmXDIhi7whHYwRP713auGMcd1aYNfCgZg9qCWspBL8cykVYSsi8UXkNeQWleL6rVwciL6Fn4/H46N/orDol7OY/OVh/HryJiQS4P2JnatcIKu9txM8nRQoKFHjaOztGtsVm56HiB9P4eXN5+tlhc26+PXkTfwXkw6FlRTvjOuE/q3F2g//xaRXmVio1gj6T4yV1fgAxKqh3vqhF9OCj5uZBSjVCFBYSeHtZLnpmtYyKR4LDQAgDkvVNLNk2zlxem3PABd4K8vOy9huzRHkbg9VQQnWHigbIikrq+5cq/ZJJBIse7AjJBLgjzNJOHnD8LV35HoGfjkhzrRZPr4T5Fb191bW2tMRXz3WA7893Re9AlygOzUjOng2iRVedfU+qvv/yysqxYbDcQCApwcHNYnfi+4uDD6MsKfckIOuYqOlHdIm/vULcgUg1nFYPLIdts0bgF4BLigoUePd7VfQcelODF0RiUfXHsOLv53Hqj0x+O3UTX0gMWtAS4T4u1T5PBKJBEPaGj/08tmeGOhmcOouDpZwK6cIb20TPzEvGN4GAW726BXgAiupBIlZBYi/nV/l40rUAmRSCTyrWJQMqH2tD92QS6CbvUnlsxvClF6+sLGW4lJydo2BpW6Wy+g7EjplUgkWDhfXKFn7Xywy84qRV1SKmLRcAEBnI6fZVqZTCyUmhYjJoK//dUk/NbioVI2XN58HAPxfb79qX791EeLfDD/P7oNvpvfArIEt8WwVvYONja7ex6n4rCr3+elYPLLySxDgaof7O3mbqWVEZRh81OBGRh6u3crT/3whyfLBhyAI+ryFvkGGlRzbejni59l98EG5Bans5DK09nDAoDbu+L/efng+vC1WTu6KPyP6YfH97Wp8Pt2U271RadV+Qo5Lz8MfZxL1P289m1SndTrqYtmWi1AVlKCDjxNmatepsFdY6UtQ63qO7qTL9/BysoFVNTU4fGo53TZW+1oKqGV+Qn1ytpNjXLcWAIB1B6tO7IxNz8O5myrIpBKMrGTF2ZEdvdDe2wm5RaX4IvIaLiSqoBEAH6VNnYtxPX9fWzgqrHA+UYVNJ8WpwV/su47rt/Lg5qDAi/fVvOJrXUgkEgwN9sTL97eDs13NC7w1Bt21iaPnE1UoLi3LSUrLKcTGY/GYueE43t8p5kHNHhRkVAE4ovpmZekGNHa6Xg9baxkKStSNoufjenoeUrILIbeSokdAxQx1iUSCh3r4Ymy35sgrKoXS1rpO3ar9WrnBWibBjYx8xKbnoaV75aWyP9sbA7VGwKA27rienouE2wXYcTFZf4Ezl38vpWKrdgbPexM6GwQRfVu54ljcbRyMScf/9far8NibVaxme6fmtZzxoiurHuhu+eADAJ7oF4CfjsVj16VUJNzOr7S65VZtTkjfINdK1/yQSiV4LrwNnlh/AhsOx0Gt7aGo7ZBLeW4OCjwb1hpvbbuM93dEoa2XEz7XTpdeOro9lLZcefVOAdpiY7fzirH1XBKSVYXYdSlVv8ifTq9AF4zv3twyjaR7Hns+aqALPh7pI16oYtJyLfZpXkc35BLi16zKXA1AHNd3tpPXeTzXQWGFXoFi1/aeKoZebmTk6esFLBjeBg9pu8t/OW7a0MvJG5n4+3xyrZerzyksm8Ezc0BghRk8ujU/Dl1Lr7TCpy6Ho6qZLjq17vnQ1fhoBD0fgJjfMKC1GzQCqpx2W9WQS3lD2nqgu58zCks0WKvtRanLkEt5j4UGIMjdHhl5xZj85WEUqzUY1MYdD3TmcEFlJBIJumlXEV74y1l8sDOqbHXhFko8N6INdswfgJ9n9TGpIBtRfWLwUY3colIcvS6OhT/cyw9uDgpoBOByLdfFqC+6IYN+rVzN9py6vI99VZRa/2yP2OsxuK07uvo6Y0JIC0gkwOHrGfrZHTW5lVOER/53FM/8cApf7r9eq3Z+sDMKyapC+Lva6WdilNfF1xn2chky80twKbni37GmabY6tS00pg8+GknPBwA80U8clvr5RALy7pjNFZWSg6upuZDLpNVW9pRIJHhuhJj7oYsbTSkuVh25lRSvjRbXpSkq1cDGuvY1Pe4VQ9uJ/69yKymGtHXHO+M64ejLw/DnnP6YM7Q1gr2ceP7Iohh8VOO/6HQUqzUIcLVDkLsDOjYXp7BZcuhFoxH0S96HBtW8cmd90eV9HI3NqHCBupGRh9+1vR66pLzmzrb6XoZfjVgxFBAXtyrQTud9d/sV/HbStF6TE3G38d0Rsd7E8nGdYCuv+KnOWiZF75Zi0HboWsUpt4lGDrvoez4yC4zupSksUet7ShpDzofOoDbuaOlmj5zCUvx2x99KNw13UFv3Goc4+rZyQ9+gsoC4Uy2n2VbVRl2Br4XD23DxsxpM6emHHfMH4PSS4Vj3eC/8X28/eFpwdhXRnRh8VEM3u2NosPim10nbhW/J4ONScjZUBSVwUFjVuoZCbbR0s4e/qx1K1AL+izG8aH9eLtdDVxEVEItQAcCvJxL0eQBVScoqwA9HxNogA7U1B1747Rz2GllZ9UKiCvN+Og1BACb1aIG+1Syp3q+VbsptxaTTxBpKq+voqpzmFauRXWhc7Zf42/kQBMBRYQU3h8aTvCiVSjCtbwAAYP3BOP1wlCAI+rVwqhtyKe/58LawkkrQzc8ZTjb1m4/xycPd8PszfbnkuxGkUgmCvZxgr2BaHzVODD6qoNEI2BOlCz7ET/0dfHTBh+WGXXRra/QOdKl2NkZ9Kz/ltnyp9fiMfPx2StvrEWY4FXF4e0842VghSVVYaS9DeZ/tjUGxWoNegS5YP70nxnVrDrVGwDPfn6qQKHenP88kYuIXh5CkKkSgmz1ermEGj2646lhshsGiaIIg6Hs+qiowpmMnt0IzO/HiauzQS/khl8bW5T0xpAUcbaxwvVw1z3M3VYi/nQ9baxnCtN34Nenm1wy7Fg7CN9N61nsbbaxl6O7XrNGdOyIyHYOPKlxIUuFWThHs5TJ9sqVu2OVqak6VK3k2tIO6KbbVfLJvKLpqp3uv3NIPNeh6PQa2cddPY9WxsZZhbDcxm766mh/xGfn45bg4jXLR8DaQamepDGjthoISNZ5YfxzXb+VWeFypWoM3t17CsxvPoLBEg8Ft3fHHM/1qnBLZ1tMRbg5yFJZocLpcLYTsglLkaZOJa+r5AEzP+9Cv6dKIhlx07BVWmKztqfpGmzCqG3IZ1s4DdnLjP0EHutmjmX3j6dkhosaHwUcVdLM6BrR211dPbO5si2Z21ijVCIhKqdtKsrVRXKrBcW0xqPJj6+bSp6UrbKylSMkuxOXkHCTcztfnCFRVgEk39LLzYgpU+SWV7vPJ7miUagQMaO2mz8eQW0nxxSMh6NxCidt5xXjsm2NIK1fKPCO3CI99c0y/8FjEkCCsndYTSruau/olEom+PsrBckNIN7XJpq728krzRe7U3MTgw5Kr2RpjWt8ASCXimkFXU3OwVVvVtDYrxRIRVYfBRxV0wcfQct3NEolEP3XTlKGXjcfi8We54lu1dSYhCwUlarjay9HW07HOxzOVjbUM/bQX7b1Rafh8b4w+aKhqRcwOPk5o5+2E4lIN/jpb8RzEpOVg82kxgNHNltCxV1jhm+k9EeBqh5uZBZi27jiyC0twIVGFBz87iEPXMmAnl2HN1O54PjzYpGJJumTY8sGHscmmOmXTbY0rsX69kQcfvi52GN5em9T5yxmkZBfC0cYKg9py3Q8iql8MPiqRllOIc9pVOQff8carz/swstJpTFoOXvr9POb/fKbOvSW6C2VokKvFSnPrZr38dvImfj1Zfa8HoC14FiIWGats6OXjf6OhEcT8kC7a2gTluTko8O0TveHmoMDl5GxM/vIIJqw5hMSsAgS42uGPiH4YWYvy0H21eR9nb6qQo10QzdhkU527recDAB7XTrvVBdfhHbxYC4KI6h2Dj0rsuyIm3HVpoaxQHtrU6bb/XhZ7UAQB+HjX1Tq1S5e02c8C+R46uuDjenoeSjUC+rdyQ4+A6tfWGNutOaxlEpxPVBkszHcpKVu/YNnC4RVrcuj4udph/eM94aCwwuXkbBSVivkdf0b0R5ta9gC1aGaHAFc7qDWCvpZLUg2r2d7JlEJjuUWlSMspAmDZ1Wxr0jvQBe29y1ZuNXaWCxGRKRh8VEI35KK70Janm257JTkHJWpNhfvvtPty2Yq4Oy6m1Hqabl5RqT450hL5HjrNnW0NhnzunOFSGRd7ub47X7c+BwB8pA3GHujsjXbe1S9V3rG5El89FoK2no54dlhro/M7qtO3Vdkqt4DpPR8+JpRY1/V6uNrLG3VJcIlEgsf7BQAQ/26WfK0R0d2LwccdikrVOBAt9nwM09b3KM/PxQ6ONlYoVmsQnVpxBkZ5mXnFOHlDXNY6VJtI+VEtez+Ox91GqUZAc2db+Fm4wJIuD6ZfK1f0rKHXQ+chbeLpH6cTUVyqwZmELPx7ORVSCTA/rOpej/L6Brlh54KBWDC8Tb0shlW+1Dpges6HLkhJzS6sMRCNbQJDLjrju7fAC/e1xWdTusHajNO5iejewXeWOxyPzUResRrujgp08Kn4aVwikei315T3sTcqDRoBCPZyxDvjO0EmlWDPlTScis80uV26VWz7tXK1eJ2DZwYH4fnwtvh4UlejHzOwtTu8nGyQmV+C3ZdTseIfcVXNcd1aoJVH5QvVNbTQlq6QSICrqblIyy40uefDzUEBa5kEGkEMQKqjn2bbBIIPmVSCZwa3ssh0biK6NzD4uMPuK+IwydC2HlUmdRpb6XS3Nt8jrJ0nAt3sMUG7gmRtcj90yaaWzPfQcbSxRsSQVvAwoVyzTCrRr6C5fPsVHIhOh5VUgvlGDNs0lGb2cn0guftKGtJziwEYH3xIpRJ4K3VJp9UHH00h2ZSIyFwYfJQjCEK1+R46HY0IPopLNdivrRQ5TDtMMXdoa1jLJDgQnY6j1yuW9q5KZl6xfhE03fBNU6Qbeom/LdbTmNzT1+JrdOiCOd3MHTu5DM4m5JIYm/fR2KfZEhGZE4OPcq6n5+FGRj7kMin6t666h0E33fZScnaVa5Ycj7uNnKJSuDko9Kt7+rrY6Yturdh11egFyY5cz4AgAK09HEzqbWhsAt3s0UubIyK3kmLO0FYWbhH0dUt0uTnNnW1NGtZq7iwGTzXNeInLYPBBRKTD4KMc3UJyvVu6wKGaBZkC3exhJ5ehsERTadlvAPhXO8tlaLC7wfDNnKGtILeS4ljsbRysZGGzyhxsBFNs68vMAWIdiacGBemHLCypZ4AL5OWSKo1NNtXvb0TPR2ZeMbK01V0bY2l1IiJzMyn4CAgIgEQiqXCLiIgAABQWFiIiIgKurq5wcHDAhAkTkJqaWsNRGw9djsbQaoZcADF/QZcrcL6SoRdBEMody3DGjLfSFlN7+wEAVuyKMqr345A2SLkbpj2O6OCFs0tHYIEFcz3Ks5XL0N3fWf+zsfkeOsas76IbcvFW2hhVtp2I6G5nUvBx/PhxJCcn62+7du0CADz00EMAgAULFmDLli3YtGkTIiMjkZSUhPHjx9d/qxtAdmEJjseJxaZqCj6A6le4jUnLRfxtcfhmQCXDN08PDoKNtRSn47NqXDI+WVWA6+l5kEqgX/ekqVPaWlt8xk55/cv1KBlbYOzO/asbdmGyKRGRIZOCD3d3d3h5eelvW7duRVBQEAYNGgSVSoW1a9fio48+wtChQxESEoJ169bh0KFDOHLkSEO1v94cuJqOUo2AIHd7+BvRNa5POq1kuq2uqmlokCvsKxm+8XC0wbTQAABi3Y/qej90QzOdmisbdXGqpqz8lNIWJg676IOPzIIq/45NaZotEZE51Drno7i4GN9//z2eeOIJSCQSnDx5EiUlJQgLC9PvExwcDD8/Pxw+fLjK4xQVFSE7O9vgZk45hSVY+e9VvPjbOQDG9XoAZdNtLyVlQ3NH0qmuqmlYu6qPNXtQEOzlMlxIzMbOi1UPTekKYLHmQsPp3FwJRxsxSDR19o1utktesRrZhaWV7hOrTTZtyeCDiAgAUHVWZQ3++OMPZGVlYfr06QCAlJQUyOVyODs7G+zn6emJlJSUKo+zfPlyLFu2rLbNqLXCEjW+P3IDn++NQaY2GbBjcyfMGhhk1OOD3O2hsJIit6gUcRl5aOkuFsq6nVesLyI2tF3FCqk6LvZyPN4vEJ/tjcHHu66iZ0AzpGYXITW7ECnZhUhRFSItpxD/XhIDE92sDKp/VjIpVk7uiktJ2ehWyeJ21bGTW6GZnTUy80uw4p8ozOzfEn6uhgFM7C1tzweTTYmIANQh+Fi7di1GjhwJH5+6LTy1ePFiLFy4UP9zdnY2fH1963TM6pSqNfj15E18sjsaySqxMFRLN3ssGtEWIzt6Gb1arJVMinbeTjiTkIULSdn64GNfuaqmNSUvPjmgJTYcjkNUag5C3vq3yv0cbayqXLKe6sewdp4YVk2wWJ2+rdyw7Vwyvj18A98duYGBrd3xaB9/DAn2gFRSbpqtO4MPIiKglsHHjRs38O+//+L333/Xb/Py8kJxcTGysrIMej9SU1Ph5eVV5bEUCgUUCkVtmmESjUbAtvPJ+GjXVf0YvLfSBvPDWmNC9xawqsUaFh2bi8HHxUQVHtSu/lm+qmlNlHbWeHZYa7y17TIAcdExTycbeClt4OmkEL93skHPQBfOkmjEPpncFWO6+OD7o/HYf/UWIrW35s62GN3FB/nFakglgG8zyxZUIyJqLGoVfKxbtw4eHh4YNWqUfltISAisra2xe/duTJgwAQAQFRWF+Ph4hIaG1k9r62DX5VTM/ek0AHHI45nBQXikjz9srGt/Udflfeim2xaXahB5R1XTmswc0BITureAnUIGhRUDjKbISibFiA5eGNHBC3HpefjxWDx+OZGAxKwCfBF5DYCYSyK3YlkdIiKgFsGHRqPBunXrMG3aNFhZlT1cqVRixowZWLhwIVxcXODk5IS5c+ciNDQUffr0qddG10ZYO0/08G+GAa3dMWNAYLVFxIxVNt1WBUEQcCz2NnLvqGpqjGb28jq3hRqHADd7vHx/Oywc3gZbzyXj+yM3cCYhq9Ip10RE9yqTr8D//vsv4uPj8cQTT1S47+OPP4ZUKsWECRNQVFSE8PBwrF69ul4aWlcyqQSbngqt1/oSbTwdIZdJkV1YipuZBVVWNaV7j421DBNDWmBiSAtk5BbBidOkiYj0TA4+RowYUWU9AxsbG3z++ef4/PPP69ywhlDfha3kVlK09XLE+UQVzieqylbEDa5d4iLdnVwdGj6niYioKeEgdB11bC6WWd98OhEJtwuqrGpKREREIgYfdaTL+9ilrcdRVVVTIiIiEjH4qCNdmXWd6qqaEhEREYOPOgv2coSsXHJpdVVNiYiIiMFHndlYy9DaQ6xuakxVUyIionsdg496oCt9Ht6h6kquREREJGJmZD14bkRbdGquxLjuzS3dFCIiokaPwUc9aGYvx8O9/CzdDCIioiaBwy5ERERkVgw+iIiIyKwYfBAREZFZMfggIiIis2LwQURERGbF4IOIiIjMisEHERERmRWDDyIiIjIrBh9ERERkVgw+iIiIyKwYfBAREZFZMfggIiIis2LwQURERGbF4IOIiIjMisEHERERmRWDDyIiIjIrBh9ERERkVgw+iIiIyKwYfBAREZFZMfggIiIis2LwQURERGbF4IOIiIjMisEHERERmRWDDyIiIjIrBh9ERERkVgw+iIiIyKwYfBAREZFZMfggIiIis2LwQURERGZlcvCRmJiIRx55BK6urrC1tUWnTp1w4sQJ/f2CIOC1116Dt7c3bG1tERYWhujo6HptNBERETVdJgUfmZmZ6NevH6ytrbF9+3ZcunQJK1asQLNmzfT7vP/++1i1ahW++OILHD16FPb29ggPD0dhYWG9N56IiIiaHokgCIKxO7/00ks4ePAgDhw4UOn9giDAx8cHixYtwnPPPQcAUKlU8PT0xPr16/Hwww/X+BzZ2dlQKpVQqVRwcnIytmlERERkQaZcv03q+fjrr7/Qo0cPPPTQQ/Dw8EC3bt3w9ddf6++PjY1FSkoKwsLC9NuUSiV69+6Nw4cPV3rMoqIiZGdnG9yIiIjo7mVS8HH9+nWsWbMGrVu3xs6dO/H0009j3rx52LBhAwAgJSUFAODp6WnwOE9PT/19d1q+fDmUSqX+5uvrW5vfg4iIiJoIk4IPjUaD7t2745133kG3bt0wa9YsPPnkk/jiiy9q3YDFixdDpVLpbwkJCbU+FhERETV+JgUf3t7eaN++vcG2du3aIT4+HgDg5eUFAEhNTTXYJzU1VX/fnRQKBZycnAxuREREdPcyKfjo168foqKiDLZdvXoV/v7+AIDAwEB4eXlh9+7d+vuzs7Nx9OhRhIaG1kNziYiIqKmzMmXnBQsWoG/fvnjnnXcwadIkHDt2DF999RW++uorAIBEIsH8+fPx1ltvoXXr1ggMDMSSJUvg4+ODsWPHNkT7iYiIqIkxKfjo2bMnNm/ejMWLF+ONN95AYGAgVq5cialTp+r3eeGFF5CXl4dZs2YhKysL/fv3x44dO2BjY1PvjSciIqKmx6Q6H+bAOh9ERERNT4PV+SAiIiKqKwYfREREZFYMPoiIiMisGHwQERGRWTH4ICIiIrNi8EFERERmxeCDiIiIzIrBBxEREZkVgw8iIiIyKwYfREREZFYMPoiIiMisGHwQERGRWTH4ICIiIrNi8EFERERmxeCDiIiIzIrBBxEREZkVgw8iIiIyKwYfREREZFYMPoiIiMisGHwQERGRWTH4ICIiIrNi8EFERERmxeCDiIiIzIrBBxEREZkVgw8iIiIyKwYfREREZFYMPoiIiMisGHwQERGRWTH4ICIiIrNi8EFERERmxeCDiIiIzIrBBxEREZkVgw8iIiIyKwYfREREZFYMPoiIiMisGHwQERGRWTH4ICIiIrMyKfh4/fXXIZFIDG7BwcH6+wsLCxEREQFXV1c4ODhgwoQJSE1NrfdGExERUdNlcs9Hhw4dkJycrL/9999/+vsWLFiALVu2YNOmTYiMjERSUhLGjx9frw0mIiKips3K5AdYWcHLy6vCdpVKhbVr1+LHH3/E0KFDAQDr1q1Du3btcOTIEfTp06furSUiIqImz+Sej+joaPj4+KBly5aYOnUq4uPjAQAnT55ESUkJwsLC9PsGBwfDz88Phw8frvJ4RUVFyM7ONrgRERHR3cuk4KN3795Yv349duzYgTVr1iA2NhYDBgxATk4OUlJSIJfL4ezsbPAYT09PpKSkVHnM5cuXQ6lU6m++vr61+kWIiIioaTBp2GXkyJH67zt37ozevXvD398fv/zyC2xtbWvVgMWLF2PhwoX6n7OzsxmAEBER3cXqNNXW2dkZbdq0QUxMDLy8vFBcXIysrCyDfVJTUyvNEdFRKBRwcnIyuBEREdHdq07BR25uLq5duwZvb2+EhITA2toau3fv1t8fFRWF+Ph4hIaG1rmhREREdHcwadjlueeew+jRo+Hv74+kpCQsXboUMpkMU6ZMgVKpxIwZM7Bw4UK4uLjAyckJc+fORWhoKGe6EBERkZ5JwcfNmzcxZcoUZGRkwN3dHf3798eRI0fg7u4OAPj4448hlUoxYcIEFBUVITw8HKtXr26QhhMREVHTJBEEQbB0I8rLzs6GUqmESqVi/gcREVETYcr1m2u7EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZVZ2Cj3fffRcSiQTz58/XbyssLERERARcXV3h4OCACRMmIDU1ta7tJCIiortErYOP48eP48svv0Tnzp0Nti9YsABbtmzBpk2bEBkZiaSkJIwfP77ODSUiIqK7Q62Cj9zcXEydOhVff/01mjVrpt+uUqmwdu1afPTRRxg6dChCQkKwbt06HDp0CEeOHKm3RhMREVHTVavgIyIiAqNGjUJYWJjB9pMnT6KkpMRge3BwMPz8/HD48OFKj1VUVITs7GyDGxEREd29rEx9wMaNG3Hq1CkcP368wn0pKSmQy+VwdnY22O7p6YmUlJRKj7d8+XIsW7bM1GYQERFRE2VSz0dCQgKeffZZ/PDDD7CxsamXBixevBgqlUp/S0hIqJfjEhERUeNkUvBx8uRJpKWloXv37rCysoKVlRUiIyOxatUqWFlZwdPTE8XFxcjKyjJ4XGpqKry8vCo9pkKhgJOTk8GNiIiI7l4mDbsMGzYM58+fN9j2+OOPIzg4GC+++CJ8fX1hbW2N3bt3Y8KECQCAqKgoxMfHIzQ0tP5aTURERE2WScGHo6MjOnbsaLDN3t4erq6u+u0zZszAwoUL4eLiAicnJ8ydOxehoaHo06dP/bWaiIiImiyTE05r8vHHH0MqlWLChAkoKipCeHg4Vq9eXd9PQ0RERE2URBAEwdKNKC87OxtKpRIqlYr5H0RERE2EKddvru1CREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMiuTgo81a9agc+fOcHJygpOTE0JDQ7F9+3b9/YWFhYiIiICrqyscHBwwYcIEpKam1nujiYiIqOkyKfho0aIF3n33XZw8eRInTpzA0KFDMWbMGFy8eBEAsGDBAmzZsgWbNm1CZGQkkpKSMH78+AZpOBERETVNEkEQhLocwMXFBR988AEmTpwId3d3/Pjjj5g4cSIA4MqVK2jXrh0OHz6MPn36GHW87OxsKJVKqFQqODk51aVpREREZCamXL9rnfOhVquxceNG5OXlITQ0FCdPnkRJSQnCwsL0+wQHB8PPzw+HDx+u8jhFRUXIzs42uBEREdHdy+Tg4/z583BwcIBCocBTTz2FzZs3o3379khJSYFcLoezs7PB/p6enkhJSanyeMuXL4dSqdTffH19Tf4liIiIqOkwOfho27Ytzpw5g6NHj+Lpp5/GtGnTcOnSpVo3YPHixVCpVPpbQkJCrY9FREREjZ+VqQ+Qy+Vo1aoVACAkJATHjx/HJ598gsmTJ6O4uBhZWVkGvR+pqanw8vKq8ngKhQIKhcL0lhMREVGTVOc6HxqNBkVFRQgJCYG1tTV2796tvy8qKgrx8fEIDQ2t69MQERHRXcKkno/Fixdj5MiR8PPzQ05ODn788Ufs27cPO3fuhFKpxIwZM7Bw4UK4uLjAyckJc+fORWhoqNEzXYiIiOjuZ1LwkZaWhsceewzJyclQKpXo3Lkzdu7cieHDhwMAPv74Y0ilUkyYMAFFRUUIDw/H6tWrG6ThRERE1DTVuc5HfWOdDyIioqbHLHU+iIiIiGqDwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrBh8EBERkVkx+CAiIiKzYvBBREREZsXgg4iIiMyKwQcRERGZFYMPIiIiMisGH0RERGRWDD6IiIjIrKws3QAiIroHFecBMbsB1U1AlSDespPF+2RyoM0IoP8C8efSYuCvOQAkgKYEUJcAmlLxpi4BAvoDA5/T7lsErA4Vv6qLxK+lhYDUGnD2A1oNA8LfLmtHejTg6CXery4Wj6cuFm9WNoCjp7ifRgPc+E9si1p7TP33RYCyBRA8quy4OxYDJfnatqrL2iuoAfd2wNBXyva9dRVoFgBYyRvqbDc6DD6IiO5WgiBe/EryAakVoHAQtxfnAYmnxAu5Rq29QGov6OpSwK010Ly7uG9BFnBktfZiq73oChrxwiyTAy16Ah3GivuqS4CT64GiHKAwS3xs+a9t7gOGvCzuW5QL/PJo1W13bVn2fWkhcO7nqve1dS77XmoN3L5WcR91MXDrMuDRrmybRi0GKpqSyo/bYRzw0HrtDwKwYXTVbWg9wjD4OLEOKC2ofN/8zHJt0ADr7wdKCoGgIUCbcKDV8LKg5y7F4IOI6G4TtQP48xnxoi+oxW0DngOGLRG/z04CNjxQ9eN7P10WfJTkA5HvVb1vt0fLgo/iPODv56re17VV2ff27oBvH7HXwdkXUPoCTj6ARCYGCkrfsn1lcmDEW2LQI7UGZNZiMCWzFn9u5l+2r1QKPL4DsFJobzbi15JCICsOsHEu2zc/QwzICsoFA4B4bKn2OfTbZIBHB/GrlQKQKcSeCpn2eby7GB5jwEJt27XHkci0x5WJv6eOKkEMEotzgMt/iTcA8OkGtNQGI359qj6nTRSDDyKiu0leOvBnhHhhLa+0sOx7uQPg1kZ7IS93odVdKF3K9ToonICeM8su4lY2ACRlww26IAUAJFKg3WhA7ij2Rtg4i19tm4nfO/uV7SuVAjN2Gvc7WdsAfecafw78Qyvf7tbK8GcHD+DFOLEXBoIY5EitxbZV5plDxrdh0AvG7dfMH3guGkg6DUTvBK7uBJLPiD8nnQasbcuCj4xrwM+PAi6B2mEaGzFQ05SKX9s9CLQcJO6begn493Vtj5X2VqL96tEO+L9qepLMgMEHEdHd5O/ngfx0wKM9MPVX8ZO9tZ0YWOg4eQNzjht3PIUDMGqFcfvaOAGTvze9zZamG46yFKkUaBEi3oa8DOSkAjG7gJvHAd/eZftlXAPSLoq3yjQLLAs+inPFYKYyCqf6bX8tMPggIrpbpF0BLv0hdvGPXQ0om1u6RVQbjp5At0fEW3kteogB5e1YIOuGmGMj0w5D6fJvdFxaAg9+JvaOWNtoe660NxvLBx8SQRAESzeivOzsbCiVSqhUKjg5Wf4EERE1KTdPAkmngF5PWroldI8x5frNng8ioruJrvueqBFjkTEioqYudr845ELURDD4ICJqyvJvA7/OAL4cAMQesHRriIzC4IOIqCnb/iKQlyYmGPr2snRriIzC4IOIqKm6sg04/4tYX2PMarEOB1ETwIRTunfoCuyUL8V86U+x27ooG3DwBDo9JFYgJGrs8m8DW+aL3/edxyRTalIYfFDjIAji2g+5aeK6EHIHwCO47P6Y3WWV/PSzw7VfbV2AwAFlxzn4CZCbqr2lATkp2uOqgIABwPStZcfdusCwEuSpb4HxX7M+wr2mpFAszKUu1i4Wpr2VFolf3duWlcTOSRFzK3QLhWlKxLLfutelXx/Aq5P4fXayWHdD0FR+CxhQVr1SlSiuoaJfhEy71ooAAIK4Lkr7B8vasDoUKLgtViodvNiMJ4uo7hh8UP0pLQaubBUv+rpyxfo3ZQFwCQK6TBb3VZeIZYJzU4G8W+JXdXHZsVqFAY/8VvbzL4+JFfsq4xcKBO4Qv5dIxOCj4Hbl+xZlG/7ccoi4doXcHojaDtw4CHzRT+zCDr6/NmeBdAShYlnn0kLxfLu1LasqmXBMLCldqBJvgrrcOhhSoM8zgGcHcd/4o8CFX7UXZ3XF1UL7zisr9331H2DvW9rF0IrKrXKqXYl03BdAxwnafXcAm6ZV/bs8+CnQ/THx+9QLwO8zq943fHlZ8JEZB+x4qep9h71WFnzkpwOHP6t6X0fvsuCjKEd8jeuGW6xtqn4cUSPE4KOpKs4XPxnZKMWfNWrxTVEiE4cN9F8lACRiT4KDu7ivIIgLS+kJhr0JVrZl+6pLgMtbxN6BvFviuhH56eLXnBSxx2H0J+K+Egnw6+NVt7lVWFnwIbMWpweW5BnuY6MUb/buhtt9uokXLYlMfMPVPR9QdmHSCZkuXogcPO+4eZSdL52Ja8u+z7gG/PqEuK7Cxili8NMqrOrfp7EqzhcXyirKERf6KskTt5XkASUF4kqdcntx35jdwI1D4vkSNOLrSPepvLQQGPxy2eqaJzeIPUO6IEJTKq7IKWgDgKmbyhbXOvgJsOu1qtv4xM6yi27SaeDAh1Xv22Fc2d/41hXg2FfV76sLPoqygeSzVe9bWlT2vZWNdp0TedliYfrv5YDCsWxfOzeg5WBtcKRbMEyXPicxXBfF3k0McHSvW/1NIn717FS2r4OnGDzp1leRWpXtDxiW2bZ3A4a/CXh3BnzLVbUkaiIYfDS0Eu2btO5TnrpEvMiVJ2jEi0JJHmDvUTbcUJQLHPtSHNvNTdUOH6SKdf+LVECvWcD9H4j7FucBXw6suh0dJwATvxG/15QCH7evet+29wNTfhK/l0jFCzKqKIRbfnhCZi12DVvZiBd53ZssJOJX92DDx47+RLwIOniKwY69R9Wf4MoPldQkbKnx+5bnGgTM2AXsXgaknBd7RRqSIIi9OUW52m5+7bLmuu+9u4qLfgFA3H/ihVTXO1CQVfZ9oQp4fJu4eBcA7HwZOLmu6uf17ycuTAWIAeDBlVXv2/PJsuAjNxVIPFH1vuUv5lJrw/skMnGBLCuFuM6IprTsPu8uQK/Z2sDTSbzo6no0BLXYY6bftzMw8AUxsJbKKq4W6tmxbN+A/mIp6vIrkOqWgbdSiMN1Om3vA15Lr/p3K8+nK/DYn8bt69a67P+uJo5ewIg3jdvXthnQb55x+xI1Qgw+TKEuFT9NFWYB1vZlb8oFmcDp78sCg9yUslyDwiyg33xg+DJx3/wMYHXvKp4A4qd2XU+CuhjY/UbV++aVe7MUNGK3rEat/SRa7pMsBPHNtzyZXLz46XoPoP0qkVRcRrr1CPGN295d/NRn7w7Yu4pBg7KF4XFNWSmx80PG72suVnIg/G3x4q9LPC0pAKJ3iUFZaYF2CKGgbCjBu3PZ4+P+A9KjxWBQ3+uQVxYwTNlYFlD8NlMcQqjK89fET7gAcP7X6gOKQlVZ8GHjJF6QbZzEHi9rO0BuJ75m5XaGf1+/PkDpU4afyqXaT+kyBWDnWrZv+7FiD4RufQjdp3OptOJKqN0fE5N3dWtKyO4IRsrz62P8kuE+3cSbMRy9xBsRNToMPkoKy5IT7VzFT78AoLopjtXm3hLn0OfeAopzyh4XOke8SAHixeWfV6t+jrxbZd9LpIZv6OLGsguEvUfZZrkD0PUR8ROh7o3UwbPs+/IrE9o6A4uMrHAoswaW3Kp5P52pvxi/792i/MVy5yvAibVV77skvWz/E+uqDyiKsgE77Sdu3RCQRCYGgzJ5uUWirMXgUadFT3EYxUapXapcKS5RbuOkHaYq97oZ+hoQtqxcYFmNtiPFmzHc24g3YygcLL9SKBE1WvdW8JGdBPy7TOyZyEkFcpLFngmdvnOBEW+V/Xx5S+XHkd/xpmrbTPyUZ+8h9oY4eGm/am+6T6SAmHfwwnXj2mslB8Z+bty+1DAEQexRklqLQyI6MoX2U72tONygCz6adxd7SuR24pCSrudBFzSUr8MwfJn4erO2rTlQ6DZVvBlDdm/9WxNR03NvrWqrSqw810EmF3sSuj4CDH5R3FZaDJzaIA4xOHiIgYWdi9jbwDf3e48uL0M/5MD6fERE5XFV26o4eABhr2t7JsoNY9g2q/jJ00rOJampDIcQiIjqzb0VfMisgf4LLN0KIiKiexr7jomIiMisTAo+li9fjp49e8LR0REeHh4YO3YsoqKiDPYpLCxEREQEXF1d4eDggAkTJiA1NbVeG01ERERNl0nBR2RkJCIiInDkyBHs2rULJSUlGDFiBPLyyqpULliwAFu2bMGmTZsQGRmJpKQkjB8/vt4bTkRERE1TnWa73Lp1Cx4eHoiMjMTAgQOhUqng7u6OH3/8ERMnTgQAXLlyBe3atcPhw4fRp0/NhYQadLYLERERNQhTrt91yvlQqVQAABcXsWjSyZMnUVJSgrCwsvUwgoOD4efnh8OHD1d6jKKiImRnZxvciIiI6O5V6+BDo9Fg/vz56NevHzp2FNdTSElJgVwuh7Ozs8G+np6eSElJqfQ4y5cvh1Kp1N98fX1r2yQiIiJqAmodfERERODChQvYuHFjnRqwePFiqFQq/S0hIaFOxyMiIqLGrVZ1PubMmYOtW7di//79aNGibGExLy8vFBcXIysry6D3IzU1FV5elS/wpFAooFAoKr2PiIiI7j4m9XwIgoA5c+Zg8+bN2LNnDwIDAw3uDwkJgbW1NXbv3q3fFhUVhfj4eISGhtZPi4mIiKhJM6nnIyIiAj/++CP+/PNPODo66vM4lEolbG1toVQqMWPGDCxcuBAuLi5wcnLC3LlzERoaatRMFyIiIrr7mTTVVlLFypvr1q3D9OnTAYhFxhYtWoSffvoJRUVFCA8Px+rVq6scdrkTp9oSERE1PaZcv++tVW2JiIioQZitzgcRERGRqRrdqra6jhgWGyMiImo6dNdtYwZUGl3wkZOTAwAsNkZERNQE5eTkQKlUVrtPo8v50Gg0SEpKgqOjY5UJrrWVnZ0NX19fJCQkMJ+kBjxXxuO5Mh7PlfF4rkzD82W8hjpXgiAgJycHPj4+kEqrz+podD0fUqnUoHBZQ3BycuKL00g8V8bjuTIez5XxeK5Mw/NlvIY4VzX1eOgw4ZSIiIjMisEHERERmdU9FXwoFAosXbqUa8kYgefKeDxXxuO5Mh7PlWl4vozXGM5Vo0s4JSIiorvbPdXzQURERJbH4IOIiIjMisEHERERmRWDDyIiIjIrBh9ERERkVvdM8PH5558jICAANjY26N27N44dO2bpJjUK+/fvx+jRo+Hj4wOJRII//vjD4H5BEPDaa6/B29sbtra2CAsLQ3R0tGUaa0HLly9Hz5494ejoCA8PD4wdOxZRUVEG+xQWFiIiIgKurq5wcHDAhAkTkJqaaqEWW9aaNWvQuXNnfQXF0NBQbN++XX8/z1Xl3n33XUgkEsyfP1+/jeeqzOuvvw6JRGJwCw4O1t/Pc2UoMTERjzzyCFxdXWFra4tOnTrhxIkT+vst+f5+TwQfP//8MxYuXIilS5fi1KlT6NKlC8LDw5GWlmbppllcXl4eunTpgs8//7zS+99//32sWrUKX3zxBY4ePQp7e3uEh4ejsLDQzC21rMjISERERODIkSPYtWsXSkpKMGLECOTl5en3WbBgAbZs2YJNmzYhMjISSUlJGD9+vAVbbTktWrTAu+++i5MnT+LEiRMYOnQoxowZg4sXLwLguarM8ePH8eWXX6Jz584G23muDHXo0AHJycn623///ae/j+eqTGZmJvr16wdra2ts374dly5dwooVK9CsWTP9PhZ9fxfuAb169RIiIiL0P6vVasHHx0dYvny5BVvV+AAQNm/erP9Zo9EIXl5ewgcffKDflpWVJSgUCuGnn36yQAsbj7S0NAGAEBkZKQiCeF6sra2FTZs26fe5fPmyAEA4fPiwpZrZqDRr1kz43//+x3NViZycHKF169bCrl27hEGDBgnPPvusIAh8Xd1p6dKlQpcuXSq9j+fK0Isvvij079+/yvst/f5+1/d8FBcX4+TJkwgLC9Nvk0qlCAsLw+HDhy3YssYvNjYWKSkpBudOqVSid+/e9/y5U6lUAAAXFxcAwMmTJ1FSUmJwroKDg+Hn53fPnyu1Wo2NGzciLy8PoaGhPFeViIiIwKhRowzOCcDXVWWio6Ph4+ODli1bYurUqYiPjwfAc3Wnv/76Cz169MBDDz0EDw8PdOvWDV9//bX+fku/v9/1wUd6ejrUajU8PT0Ntnt6eiIlJcVCrWoadOeH586QRqPB/Pnz0a9fP3Ts2BGAeK7kcjmcnZ0N9r2Xz9X58+fh4OAAhUKBp556Cps3b0b79u15ru6wceNGnDp1CsuXL69wH8+Vod69e2P9+vXYsWMH1qxZg9jYWAwYMAA5OTk8V3e4fv061qxZg9atW2Pnzp14+umnMW/ePGzYsAGA5d/frRr8GYjuMhEREbhw4YLBWDNV1LZtW5w5cwYqlQq//vorpk2bhsjISEs3q1FJSEjAs88+i127dsHGxsbSzWn0Ro4cqf++c+fO6N27N/z9/fHLL7/A1tbWgi1rfDQaDXr06IF33nkHANCtWzdcuHABX3zxBaZNm2bh1t0DPR9ubm6QyWQVMp5TU1Ph5eVloVY1Dbrzw3NXZs6cOdi6dSv27t2LFi1a6Ld7eXmhuLgYWVlZBvvfy+dKLpejVatWCAkJwfLly9GlSxd88sknPFflnDx5EmlpaejevTusrKxgZWWFyMhIrFq1ClZWVvD09OS5qoazszPatGmDmJgYvq7u4O3tjfbt2xtsa9eunX6YytLv73d98CGXyxESEoLdu3frt2k0GuzevRuhoaEWbFnjFxgYCC8vL4Nzl52djaNHj95z504QBMyZMwebN2/Gnj17EBgYaHB/SEgIrK2tDc5VVFQU4uPj77lzVRWNRoOioiKeq3KGDRuG8+fP48yZM/pbjx49MHXqVP33PFdVy83NxbVr1+Dt7c3X1R369etXoRzA1atX4e/vD6ARvL83eEprI7Bx40ZBoVAI69evFy5duiTMmjVLcHZ2FlJSUizdNIvLyckRTp8+LZw+fVoAIHz00UfC6dOnhRs3bgiCIAjvvvuu4OzsLPz555/CuXPnhDFjxgiBgYFCQUGBhVtuXk8//bSgVCqFffv2CcnJyfpbfn6+fp+nnnpK8PPzE/bs2SOcOHFCCA0NFUJDQy3Yast56aWXhMjISCE2NlY4d+6c8NJLLwkSiUT4559/BEHguapO+dkugsBzVd6iRYuEffv2CbGxscLBgweFsLAwwc3NTUhLSxMEgeeqvGPHjglWVlbC22+/LURHRws//PCDYGdnJ3z//ff6fSz5/n5PBB+CIAiffvqp4OfnJ8jlcqFXr17CkSNHLN2kRmHv3r0CgAq3adOmCYIgTsdasmSJ4OnpKSgUCmHYsGFCVFSUZRttAZWdIwDCunXr9PsUFBQIzzzzjNCsWTPBzs5OGDdunJCcnGy5RlvQE088Ifj7+wtyuVxwd3cXhg0bpg88BIHnqjp3Bh88V2UmT54seHt7C3K5XGjevLkwefJkISYmRn8/z5WhLVu2CB07dhQUCoUQHBwsfPXVVwb3W/L9XSIIgtDw/StEREREors+54OIiIgaFwYfREREZFYMPoiIiMisGHwQERGRWTH4ICIiIrNi8EFERERmxeCDiIiIzIrBBxEREZkVgw8iIiIyKwYfREREZFYMPoiIiMis/h+L/HyIVoDYRAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of Results\n",
        "\n",
        "#### 1. **Loss and Val Loss**\n",
        "   - **Loss:** Measures the average error on the **training** data.\n",
        "   - **Val Loss:** Measures the average error on the **validation** data, indicating the model's ability to generalize.\n",
        "\n",
        "#### 2. **Training Evolution**\n",
        "   - **Loss consistently decreases**, showing that the model is learning.\n",
        "   - **Val Loss follows a similar trend** but stabilizes or fluctuates at some point.\n",
        "\n",
        "#### 3. **Overfitting or Underfitting?**\n",
        "   - **Overfitting:** If **val_loss > loss** and starts increasing, the model is memorizing training data instead of generalizing.\n",
        "   - **Underfitting:** If both **loss and val_loss remain high**, the model is not learning enough.\n",
        "\n",
        "#### 4. **Current Interpretation**\n",
        "   - The **initial epochs show a strong decrease in loss and val_loss**, indicating proper learning.\n",
        "   - **After epoch 100, val_loss stabilizes around 7.3**, suggesting a decent generalization.\n",
        "\n",
        "#### 5. **Possible Improvements**\n",
        "   - **Regularization:** Dropout and L2 regularization already help prevent overfitting.\n",
        "   - **Learning Rate Reduction:** Could improve stability in later epochs.\n",
        "   - **More Data?** If data is limited, generalization might suffer.\n",
        "\n",
        "### **Conclusion**\n",
        "- **Good performance** with an **acceptable val_loss** for time series forecasting.\n",
        "- **Optimization is possible**, but without overfitting.\n",
        "- **Fine-tuning the learning rate** in later epochs could enhance stability.\n"
      ],
      "metadata": {
        "id": "cku_HiS5rRXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Early Stopping: Why It's Not a Problem!**\n",
        "\n",
        "### **Why Is It Not a Problem?**\n",
        "1. **Prevents Overfitting**  \n",
        "   - If `val_loss` **stops improving or starts increasing**, the model is learning **noise** instead of generalizing.  \n",
        "   - Early stopping **prevents memorizing unnecessary details** from the training data.\n",
        "\n",
        "2. **Saves Time and Resources**  \n",
        "   - If improvement stops after **30-40 epochs**, running **100 epochs** is **wasteful**.  \n",
        "   - **Early Stopping** finds the optimal number of epochs **without manual tuning**.\n",
        "\n",
        "3. **Restores the Best Weights**  \n",
        "   - With `restore_best_weights=True`, the model **does not use the last epoch’s weights** but the ones from **the best val_loss**.  \n",
        "   - If it stops at **epoch 40**, it might actually use **epoch 32’s weights**.\n",
        "\n",
        "---\n",
        "\n",
        "### **What Happens If Training Stops Early?**\n",
        "- **Stops at Epoch 30 (out of 100):**  \n",
        "  The model **stopped improving** after 30 epochs, so the extra 70 epochs were **unnecessary**.\n",
        "\n",
        "- **Stops at Epoch 70 (out of 100):**  \n",
        "  The model **kept improving** until epoch 70.\n",
        "\n",
        "---\n",
        "\n",
        "### **How to Check If Early Stopping Was Effective?**\n",
        "After training, check how many epochs were actually used:\n",
        "\n",
        "```python\n",
        "print(f\"Training stopped at epoch {len(history.history['loss'])}\")\n"
      ],
      "metadata": {
        "id": "GlkG0Cs-BzxV"
      }
    }
  ]
}