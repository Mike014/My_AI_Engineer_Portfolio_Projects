{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a64629",
   "metadata": {},
   "source": [
    "# **What are hyperparameters?**\n",
    "\n",
    "These are values **manually chosen before the training of the model**; they are **not learned** by the model **itself**.\n",
    "Therefore, **unlike parameters (such as the weights of the neural network), which are optimized during training**, hyperparameters are **decided beforehand** and can determine whether the training will go well or poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92934c",
   "metadata": {},
   "source": [
    "## **Why is it important to choose them well?** \n",
    "\n",
    "Because they can:\n",
    "- Make the model **converge faster**\n",
    "- **Prevent** overfitting or underfitting\n",
    "- **Improve** generalization on unseen data\n",
    "- **Optimize** the use of time and computational resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9383adad",
   "metadata": {},
   "source": [
    "### Some classic examples of hyperparameters that are often \"tweaked\" (i.e. tried, tested, optimized):\n",
    "\n",
    "* **Learning rate**: how fast the model updates the weights\n",
    "* **Batch size**: how many instances per update\n",
    "* **Number of epochs**: how many complete cycles on the data\n",
    "* **Model architecture**: number of layers, neurons per layer, activation type\n",
    "* **Dropout rate**: percentage of neurons deactivated to avoid overfitting\n",
    "* **Optimizer type**: SGD, Adam, RMSprop...\n",
    "* **Regularization**: L1, L2, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85797c",
   "metadata": {},
   "source": [
    "## **What is Keras Tuner?**\n",
    "\n",
    "Keras Tuner is a library to **automate the search for the best hyperparameters** in deep learning models. It allows you to find the **optimal model** (e.g. number of layers, neurons, learning rate, etc.) by testing different combinations in a structured way.\n",
    "\n",
    "---\n",
    "\n",
    "## **How ​​does it work?**\n",
    "\n",
    "1. **Define a model** using a function `build_model(hp)`\n",
    "2. Inside you use `hp` to declare the hyperparameters to test\n",
    "3. Choose a search method (Random, Bayesian, Grid...)\n",
    "4. Start tuning with `.search()`\n",
    "\n",
    "---\n",
    "\n",
    "## **Basic example**\n",
    "\n",
    "```python\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(\n",
    "units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "activation='relu'\n",
    "))\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) \n",
    "model.compile( \n",
    "optimizer=keras.optimizers.Adam( \n",
    "hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) \n",
    "), \n",
    "loss='sparse_categorical_crossentropy', \n",
    "metrics=['accuracy'] \n",
    ") \n",
    "return model\n",
    "\n",
    "tuner = RandomSearch( \n",
    "build_model, \n",
    "objective='val_accuracy', \n",
    "max_trials=5, \n",
    "directory='my_dir', \n",
    "project_name='helloworld'\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=10, validation_split=0.2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Available search types**\n",
    "\n",
    "* `RandomSearch`: random tests\n",
    "* `Hyperband`: Optimized for speed and efficiency\n",
    "* `BayesianOptimization`: learns from previous iterations\n",
    "* `GridSearch`: try all combinations (high cost)\n",
    "\n",
    "---\n",
    "\n",
    "## **Installation**\n",
    "\n",
    "```bash\n",
    "pip install keras-tuner\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
