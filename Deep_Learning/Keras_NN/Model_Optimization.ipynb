{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d30e769",
   "metadata": {},
   "source": [
    "## **Why optimize a model**\n",
    "- **Better performance** (accuracy and speed)\n",
    "- **More efficient use of hardware**\n",
    "- **Increased scalability**\n",
    "\n",
    "---\n",
    "\n",
    "### **Main optimization techniques**\n",
    "\n",
    "1. **Weight Initialization**\n",
    "- Fundamental to avoid problems like *vanishing* or *exploding gradients*\n",
    "- Common techniques: **Xavier Glorot** and **He Initialization** (ideal with ReLU)\n",
    "- Example with Keras and He initialization\n",
    "\n",
    "2. **Learning Rate Scheduling**\n",
    "- Dynamically adapts the learning rate during training\n",
    "- Example: start with a constant learning rate, then decrease it exponentially after 10 epochs\n",
    "- Applied on the **MNIST** dataset (normalization + reshaping)\n",
    "\n",
    "3. **Batch Normalization**\n",
    "- Normalizes and scales the activations\n",
    "- Helps convergence and stabilizes the training\n",
    "\n",
    "4. **Mixed Precision Training**\n",
    "- Use 16 and 32-bit floating point to speed up training and reduce memory usage\n",
    "\n",
    "5. **Model Pruning**\n",
    "- Removes insignificant connections or neurons\n",
    "- Reduces parameters while maintaining good accuracy\n",
    "\n",
    "6. **Quantization**\n",
    "- Reduces weight precision (e.g. int8)\n",
    "- Great for models deployed on **edge devices**\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "The combined use of these techniques can improve:\n",
    "- **Efficiency**\n",
    "- **Precision**\n",
    "- **Portability of models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867b8af",
   "metadata": {},
   "source": [
    "### **Weight Initialization Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7933c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e2ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with \"He\" Initialization\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation=\"relu\", kernel_initializer=HeNormal()),\n",
    "# He initialize applied here\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02599a7",
   "metadata": {},
   "source": [
    "### **Learning Rate Scheduling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "\n",
    "# Normalize the input data\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "y_train = y_train.astype(\"float32\")/255.0\n",
    "\n",
    "# Reshape the input data (if necessary)\n",
    "x_train = x_train.reshape(-1, 28, 28)\n",
    "x_val = x_val.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e413647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.match.exp(-0, 1))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca598367",
   "metadata": {},
   "source": [
    "### **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e896c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is defined and the scheduler function is corrected\n",
    "model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4848867",
   "metadata": {},
   "source": [
    "### **Model Evalution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Compile the model with an Optimizer and loss function \n",
    "model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\")\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675940b",
   "metadata": {},
   "source": [
    "#### **Model Optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3112b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab61ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision training\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712408be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train) (x_test, y_test) = tf.keras.datasets, mnist.load_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
