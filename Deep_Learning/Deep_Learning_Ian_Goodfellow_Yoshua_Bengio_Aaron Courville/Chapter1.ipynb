{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 1 - Introduction**\n",
    "[Book](https://www.deeplearningbook.org/)\n",
    "\n",
    "**Deep learning** is a **specialized branch of machine learning**, which itself is a **subfield of artificial intelligence (AI)**. The **fundamental** idea behind deep learning is the **use of multiple layers of processing units (neurons)** to extract and learn **hierarchical representations of data**.\n",
    "\n",
    "### **Key Concepts in Deep Learning**\n",
    "\n",
    "1. **Depth in Deep Learning Models**\n",
    "\n",
    "    * The **depth of a model** can be defined in **two ways**:\n",
    "       * **Computational Graph Depth**: Measures the number of sequential computational steps required to evaluate the model. This is like tracing the longest path through a computational flowchart.\n",
    "       * **Conceptual Depth**: Measures how deep the relationships between abstract concepts go. Some AI models refine simple concepts into more complex ones over multiple layers of understanding.\n",
    "\n",
    "2. **Why Depth Matters**\n",
    "\n",
    "    * **More depth allows more computation per step**: A deep neural network can execute multiple instructions sequentially, similar to a program running in a computer.\n",
    "    * **Later layers refine previous layers' results**: For example, an AI system might first recognize an eye, then infer the presence of a full face even if parts of it are in shadow.\n",
    "    * **Hierarchical Representation of Data**: Deep learning organizes knowledge into layers of increasing abstraction.\n",
    "\n",
    "3. **No Single Definition of \"Deep\"**\n",
    "\n",
    "   * The depth of a model depends on the way we define computational steps.\n",
    "   * Different researchers may define what constitutes a single computational step differently.\n",
    "   * There is no strict rule for how many layers a model needs to be considered \"deep.\"\n",
    "\n",
    "4. **Deep Learning vs Traditional Machine Learning**\n",
    "\n",
    "   * Traditional ML often relies on manually designed features to represent data.\n",
    "   * Deep Learning learns these features automatically by stacking multiple transformation layers.\n",
    "   * Deep learning enables greater flexibility and adaptability, making it well-suited for complex real-world tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep Learning & Forward/Backward Propagation**\n",
    "\n",
    "**Deep learning builds hierarchical representations** by stacking multiple layers that transform input data step by step. \n",
    "This is achieved **through two core processes**:\n",
    "\n",
    "1. **Forward Propagation**\n",
    " * The input data flows through the network, layer by layer.\n",
    " * Each layer extracts more abstract features.\n",
    " * The computational depth grows with the number of layers, increasing model complexity.\n",
    "Example: In facial recognition, early layers detect edges, mid-layers detect eyes/nose, and deeper layers recognize full faces.\n",
    "\n",
    "\n",
    "#### **2. Backward Propagation**\n",
    " - The model computes the **error** between predicted and actual output.\n",
    " - This error **propagates backward**, adjusting **weights** using gradient descent.\n",
    " - Enables the network to **automatically learn** patterns without manual feature engineering.\n",
    "\n",
    "### **Key Connections**\n",
    "| **Concept** | **Connection to Forward & Backward Propagation** |\n",
    "|------------|-------------------------------------------------|\n",
    "| **Hierarchical Representation** | Forward propagation builds feature layers, refining data abstraction. |\n",
    "| **Computational Depth** | More layers = deeper models, enabling more complex computations. |\n",
    "| **Machine Learning vs. Deep Learning** | Backpropagation enables self-learning, removing manual feature design. |\n",
    "| **Adaptability** | Networks adjust dynamically to data through continuous learning. |\n",
    "\n",
    "Deep learning surpasses traditional models by **automating feature learning** and refining representations through **iterative error correction**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Neural Networks & Iterative Learning: A Human Analogy**  \n",
    "\n",
    "A neural network **mimics the human learning process**, using **forward and backward propagation**. It can be compared to how we read and understand a text:\n",
    "\n",
    "1. **Forward Propagation (First Reading)**  \n",
    "   - We read a new concept for the first time.  \n",
    "   - We absorb information and build an initial mental representation.  \n",
    "   - Similarly, in a neural network, data flows through layers, transforming into increasingly abstract representations.\n",
    "\n",
    "2. **Backward Propagation (Revising & Correcting)**  \n",
    "   - After the first reading, we may realize some parts are unclear.  \n",
    "   - We go back to re-read, refine our understanding, or correct misunderstandings.  \n",
    "   - Likewise, the neural network **calculates the error** and **updates its weights**, improving its accuracy.\n",
    "\n",
    "3. **Iterative Learning (Deep Learning Process)**  \n",
    "   - The more we review and reflect on a text, the deeper our understanding becomes.  \n",
    "   - In the same way, a neural network **repeats this process iteratively**, gradually reducing errors and enhancing performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep Learning: Evolution and Key Advances**\n",
    "\n",
    "Deep learning has **evolved through three major waves of research**, each marked by breakthroughs in neural network architectures, training methods, and computational capabilities.\n",
    "\n",
    "1. **Distributed Representation**\n",
    " * Instead of using one neuron per concept, **deep learning models use a distributed representation**, where **multiple neurons encode different aspects of a feature** (e.g., color and object identity separately).\n",
    " * This reduces redundancy and allows better generalization—a neuron representing \"red\" can learn from all red objects, not just one type.\n",
    "\n",
    "2. **The Rise and Fall of Neural Networks**\n",
    " * **Backpropagation (1986):** The **key algorithm that enabled deep networks to learn from data**.\n",
    "     * 1990s Decline:\n",
    " * Neural networks struggled with long sequences due to mathematical difficulties (solved later by LSTMs in 1997).\n",
    " * Alternative models like **Support Vector Machines (SVMs**) and Graphical Models gained traction.\n",
    " * Unfulfilled promises in AI led to reduced investments and skepticism.\n",
    "\n",
    "### **3. The Deep Learning Revolution (2006 - Present)**  \n",
    "- **Breakthrough in 2006**:  \n",
    "  - Geoffrey Hinton introduced **Deep Belief Networks (DBNs)** and **greedy layer-wise pretraining**, making it possible to train deep models efficiently.  \n",
    "- **CIFAR Initiative**:  \n",
    "  - Collaboration between **Hinton, Bengio, and LeCun** kept deep learning research alive, combining insights from neuroscience, computer vision, and machine learning.  \n",
    "- **2010s Boom**:  \n",
    "  - Deep networks **outperformed all competing AI models**.  \n",
    "  - Shift from **unsupervised learning** (small datasets) to **supervised learning** (large labeled datasets).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Advances in Deep Learning**  \n",
    "\n",
    "Deep learning has evolved to solve increasingly complex tasks, extending its capabilities across different domains.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Sequence Learning & Neural Networks**  \n",
    "- Traditional models required **labeling each sequence element**; modern deep learning networks **learn entire sequences at once** (Goodfellow et al., 2014).  \n",
    "- **Recurrent Neural Networks (RNNs)**, such as **LSTMs**, model **relationships between sequences**, enabling breakthroughs in machine translation (Sutskever et al., 2014; Bahdanau et al., 2015).  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Self-Programming Neural Networks**  \n",
    "- **Neural Turing Machines (Graves et al., 2014)** can **read and write to memory**, enabling networks to **learn simple programs** like sorting numbers.  \n",
    "- This technology is still in early stages but could **generalize to various tasks** in the future.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Deep Learning & Reinforcement Learning**  \n",
    "- Deep learning has **revolutionized reinforcement learning**, allowing **autonomous agents** to learn through **trial and error** without human guidance.  \n",
    "- **DeepMind’s system (Mnih et al., 2015)** achieved **human-level performance** in Atari video games, and deep learning is now widely applied in robotics (Finn et al., 2015).  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. Industry Adoption & Software Infrastructure**  \n",
    "- Leading tech companies (**Google, Microsoft, Facebook, IBM, Apple, NVIDIA**) rely on deep learning for core AI advancements.  \n",
    "- Growth has been driven by powerful **software frameworks** such as **TensorFlow, PyTorch, Theano, Caffe, MXNet**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Scientific Contributions of Deep Learning**  \n",
    "- Deep learning aids scientific research, including:  \n",
    "  - **Drug discovery** (predicting molecular interactions) (Dahl et al., 2014).  \n",
    "  - **Particle physics** (detecting subatomic particles) (Baldi et al., 2014).  \n",
    "  - **Neuroscience** (mapping the human brain in 3D) (Knowles-Barley et al., 2014).  \n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**  \n",
    "Deep learning, inspired by **neuroscience, statistics, and applied mathematics**, has grown due to **faster hardware, large datasets, and improved training techniques**. The field continues to expand, bringing **new challenges and opportunities** for AI innovation.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
