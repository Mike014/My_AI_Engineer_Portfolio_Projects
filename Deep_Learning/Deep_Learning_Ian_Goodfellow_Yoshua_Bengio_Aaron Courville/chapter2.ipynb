{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 2 - Linear Algebra in Deep Learning**\n",
    "\n",
    "**Linear algebra is fundamental in deep learning**, as neural networks rely on vectors, matrices, and tensors for computations. Below, we rewrite key concepts using a **Python-style notation**, making it easier to translate them into code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Algebra in Deep Learning (Python Approach)**  \n",
    "\n",
    "---\n",
    "\n",
    "### **1. Scalars (Single Values)**  \n",
    "A scalar is a **single number**. In Python, it is typically represented as an integer (`int`) or floating-point (`float`).\n",
    "\n",
    "```python\n",
    "a = 5  # Scalar example (integer)\n",
    "b = 3.14  # Scalar example (floating-point)\n",
    "```\n",
    "A scalar can be considered a **1Ã—1 matrix**, and it is its own transpose:  \n",
    "\\[\n",
    "a = a^T\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Vectors (1D Arrays)**\n",
    "A **vector** is an **ordered list of numbers**. It can be thought of as a **point in space**, where each element represents a coordinate.  \n",
    "A vector with \\( n \\) elements belongs to $$\\displaystyle A \\in \\mathbb{R}^{m \\times n} $$. \n",
    "\n",
    "Mathematically, a column vector is represented as:\n",
    "\\[\n",
    "x = \n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "**Python representation (using NumPy):**\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([x1, x2, x3])  # Row vector (default representation in NumPy)\n",
    "x_col = x.reshape(-1, 1)  # Convert to column vector\n",
    "```\n",
    "Indexing elements:\n",
    "```python\n",
    "x[0]  # First element (equivalent to x_1)\n",
    "x[S]  # Selecting a subset of elements using a set S\n",
    "```\n",
    "\n",
    "**Operations:**\n",
    "- **Vector Addition**: `c = a + b` (element-wise sum)\n",
    "- **Scalar Multiplication**: `c = k * a` (each element is multiplied by `k`)\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Matrices (2D Arrays)**\n",
    "\n",
    "A **matrix** is a **2D array of numbers** with \\( m \\) rows and \\( n \\) columns, denoted as $$\\displaystyle A \\in \\mathbb{R}^{m \\times n}$$.\n",
    "\n",
    "Example matrix:\n",
    "\\[\n",
    "A = \n",
    "\\begin{bmatrix} \n",
    "A_{1,1} & A_{1,2} \\\\ \n",
    "A_{2,1} & A_{2,2} \\\\ \n",
    "A_{3,1} & A_{3,2} \n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "**Python representation:**\n",
    "```python\n",
    "A = np.array([[A11, A12],\n",
    "              [A21, A22],\n",
    "              [A31, A32]])  # 3x2 matrix\n",
    "```\n",
    "**Indexing Elements:**\n",
    "```python\n",
    "A[0, 0]  # First element (A_1,1)\n",
    "A[i, :]  # Row i\n",
    "A[:, j]  # Column j\n",
    "```\n",
    "\n",
    "#### **Matrix Operations**\n",
    "- **Addition/Subtraction**: `C = A + B` (element-wise)\n",
    "- **Scalar Multiplication**: `D = a * B + c`\n",
    "- **Matrix Transpose**: `A.T`  \n",
    "\\[\n",
    "(A^T)_{i,j} = A_{j,i}\n",
    "\\]\n",
    "```python\n",
    "A_transpose = A.T\n",
    "```\n",
    "Example:\n",
    "```python\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "A_T = A.T  # Transpose\n",
    "```\n",
    "\n",
    "\\[\n",
    "A^T =\n",
    "\\begin{bmatrix} \n",
    "A_{1,1} & A_{2,1} & A_{3,1} \\\\ \n",
    "A_{1,2} & A_{2,2} & A_{3,2} \n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Tensors (Multidimensional Arrays)**\n",
    "A **tensor** is a **generalization** of a matrix to higher dimensions.\n",
    "\n",
    "For example, a **3D tensor** (3Ã—3Ã—3) is represented as:\n",
    "```python\n",
    "T = np.random.rand(3, 3, 3)  # 3D tensor\n",
    "T[i, j, k]  # Accessing the (i, j, k) element\n",
    "```\n",
    "Each dimension corresponds to an **axis** in the tensor.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Broadcasting (Matrix + Vector Operations)**\n",
    "Deep learning frameworks like NumPy, TensorFlow, and PyTorch **automatically broadcast** vectors to match matrix dimensions.\n",
    "\n",
    "\\[\n",
    "C = A + b\n",
    "\\]\n",
    "where `b` is a **vector**, and it's **implicitly copied** across all rows of `A` before addition.\n",
    "\n",
    "**Python example:**\n",
    "```python\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])  # 3x2 matrix\n",
    "b = np.array([10, 20])  # 1x2 vector\n",
    "\n",
    "C = A + b  # Broadcasting b across each row\n",
    "```\n",
    "This eliminates the need for explicitly reshaping `b` before adding it.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "| **Concept** | **Mathematical Representation** | **Python Equivalent** |\n",
    "|------------|--------------------------------|----------------------|\n",
    "| **Scalar** | $ a \\in \\mathbb{R} $ | `a = 5` |\n",
    "| **Vector** | $ x \\in \\mathbb{R}^n $ | `x = np.array([x1, x2, x3])` |\n",
    "| **Matrix** | $$ A \\in \\mathbb{R}^{m \\times n} $$ | `A = np.array([[A11, A12], [A21, A22]])` |\n",
    "| **Transpose** | $ A^T $ | `A.T` |\n",
    "| **Tensor** | $ A_{i,j,k} $ | `T = np.random.rand(3,3,3)` |\n",
    "| **Broadcasting** | $ C = A + b $ | `C = A + b` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Scalar** â†’ A single number, an isolated value. Example: `a = 5`  \n",
    "- **Vector** â†’ An ordered list of numbers, representing a point in space. Example: `x = np.array([x1, x2, x3])`  \n",
    "- **Matrix** â†’ A table of numbers with rows and columns, used for linear transformations. Example: `A = np.array([[A11, A12], [A21, A22]])`  \n",
    "- **Transpose** â†’ Swaps rows and columns of a matrix. Example: `A.T`  \n",
    "- **Tensor** â†’ A multi-dimensional array, a generalization of vectors and matrices. Example: `T = np.random.rand(3,3,3)`  \n",
    "- **Broadcasting** â†’ A rule that allows operations between arrays of different sizes by automatically adjusting dimensions. Example: `C = A + b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Matrix and Vector Multiplication in Python**  \n",
    "\n",
    "Matrix and vector multiplication is fundamental in deep learning, as it allows for efficient transformations and computations. Below, we summarize the key concepts and rewrite the formulas using a **Python-based approach**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Matrix Multiplication**  \n",
    "\n",
    "The **matrix product** of two matrices **A** and **B** results in a third matrix **C**, defined as:  \n",
    "\\[\n",
    "C = AB\n",
    "\\]\n",
    "For this multiplication to be valid:\n",
    "- **A** must have the same number of columns as **B** has rows.\n",
    "- If **A** is of shape **(m Ã— n)** and **B** is of shape **(n Ã— p)**, then **C** will have shape **(m Ã— p)**.\n",
    "\n",
    "Mathematically:\n",
    "\\[\n",
    "$C_{i,j} = \\sum_k A_{i,k} B_{k,j}$\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "**Python Implementation:**\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])  # 2x2 matrix\n",
    "B = np.array([[5, 6], [7, 8]])  # 2x2 matrix\n",
    "\n",
    "C = np.dot(A, B)  # Matrix multiplication\n",
    "```\n",
    "Alternatively, using the `@` operator (Python 3.5+):\n",
    "```python\n",
    "C = A @ B\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Element-wise (Hadamard) Product**  \n",
    "Unlike standard matrix multiplication, the **Hadamard product** is an **element-wise** multiplication:\n",
    "\n",
    "\\[\n",
    "$C = A \\odot B$\n",
    "\\]\n",
    "\n",
    "**Python Implementation:**\n",
    "```python\n",
    "C = A * B  # Element-wise multiplication\n",
    "```\n",
    "---\n",
    "\n",
    "### **3. Dot Product of Two Vectors**  \n",
    "The **dot product** is a special case of matrix multiplication, where two vectors **x** and **y** (of the same dimension) result in a **scalar**:\n",
    "\n",
    "\\[\n",
    "$x^T y = \\sum_i x_i y_i$\n",
    "\\]\n",
    "\n",
    "**Python Implementation:**\n",
    "```python\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "dot_product = np.dot(x, y)  # Equivalent to x.T @ y\n",
    "```\n",
    "Since the result is a **scalar**, the dot product is **commutative**:\n",
    "\\[\n",
    "x^T y = y^T x\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Properties of Matrix Multiplication**\n",
    "Matrix multiplication follows certain algebraic properties:\n",
    "\n",
    "- **Distributive Property**:  \n",
    "\\[\n",
    "A(B + C) = AB + AC\n",
    "\\]\n",
    "```python\n",
    "C = A @ (B + B)  # Equivalent to A @ B + A @ B\n",
    "```\n",
    "\n",
    "- **Associative Property**:  \n",
    "\\[\n",
    "A(BC) = (AB)C\n",
    "\\]\n",
    "```python\n",
    "D = A @ (B @ C)  # Same as (A @ B) @ C\n",
    "```\n",
    "\n",
    "- **Transpose Property**:  \n",
    "\\[\n",
    "(AB)^T = B^T A^T\n",
    "\\]\n",
    "```python\n",
    "C_T = (A @ B).T\n",
    "C_T_check = B.T @ A.T  # Should be equal to C_T\n",
    "```\n",
    "---\n",
    "\n",
    "### **5. Solving Linear Systems (Ax = b)**\n",
    "A system of linear equations is represented as:\n",
    "\n",
    "\\[\n",
    "Ax = b\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **A** is an $m \\times n$ matrix (coefficients),\n",
    "- **b** is a **known** vector,\n",
    "- **x** is an **unknown** vector we want to solve for.\n",
    "\n",
    "Expanded:\n",
    "\n",
    "\\[\n",
    "$A_{1,1}x_1 + A_{1,2}x_2 + \\dots + A_{1,n}x_n = b_1$\n",
    "\\]\n",
    "\\[\n",
    "$A_{2,1}x_1 + A_{2,2}x_2 + \\dots + A_{2,n}x_n = b_2$\n",
    "\\]\n",
    "\n",
    "**Python Solution using `numpy.linalg.solve`:**\n",
    "```python\n",
    "A = np.array([[2, 1], [1, 3]])  # 2x2 coefficient matrix\n",
    "b = np.array([8, 13])  # Known values\n",
    "\n",
    "x = np.linalg.solve(A, b)  # Solve for x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "| **Concept** | **Mathematical Representation** | **Python Equivalent** |\n",
    "|------------|--------------------------------|----------------------|\n",
    "| **Matrix Multiplication** | \\( C = AB \\) | `C = A @ B` |\n",
    "| **Element-wise Multiplication (Hadamard Product)** | \\( C = A \\odot B \\) | `C = A * B` |\n",
    "| **Dot Product of Vectors** | \\( x^T y \\) | `np.dot(x, y)` |\n",
    "| **Distributive Property** | \\( A(B + C) = AB + AC \\) | `A @ (B + C) == A @ B + A @ C` |\n",
    "| **Associative Property** | \\( A(BC) = (AB)C \\) | `A @ (B @ C) == (A @ B) @ C` |\n",
    "| **Transpose Property** | \\( (AB)^T = B^T A^T \\) | `(A @ B).T == B.T @ A.T` |\n",
    "| **Solving Linear Equations** | \\( Ax = b \\) | `np.linalg.solve(A, b)` |\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "Matrix and vector multiplication is at the core of deep learning, where:\n",
    "- **Matrix operations** define transformations,\n",
    "- **Dot products** are used in optimization,\n",
    "- **Solving systems** helps in parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define matrices and vectors for the exercise\n",
    "A = np.array([[1, 2], [3, 4]])  # 2x2 matrix\n",
    "B = np.array([[5, 6], [7, 8]])  # 2x2 matrix\n",
    "x = np.array([1, 2])  # 1D vector\n",
    "y = np.array([3, 4])  # 1D vector\n",
    "\n",
    "# Matrix multiplication\n",
    "C = A @ B\n",
    "\n",
    "# Element-wise (Hadamard) product\n",
    "hadamard_product = A * B\n",
    "\n",
    "# Dot product of two vectors\n",
    "dot_product = np.dot(x, y)\n",
    "\n",
    "# Verify distributive property: A(B + B) == A @ B + A @ B\n",
    "distributive_test = np.allclose(A @ (B + B), A @ B + A @ B)\n",
    "\n",
    "# Verify associative property: A(BC) == (AB)C\n",
    "D = np.array([[2, 3], [4, 5]])  # Extra matrix for associative test\n",
    "associative_test = np.allclose(A @ (B @ D), (A @ B) @ D)\n",
    "\n",
    "# Transpose property: (AB)^T == B^T A^T\n",
    "transpose_test = np.allclose((A @ B).T, B.T @ A.T)\n",
    "\n",
    "# Solving a linear system Ax = b\n",
    "A_sys = np.array([[2, 1], [1, 3]])  # Coefficient matrix\n",
    "b_sys = np.array([8, 13])  # Known values\n",
    "x_solution = np.linalg.solve(A_sys, b_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Matrix Multiplication (C=AB)': array([[19, 22],\n",
       "        [43, 50]]),\n",
       " 'Hadamard Product (Element-wise)': array([[ 5, 12],\n",
       "        [21, 32]]),\n",
       " 'Dot Product (x^Ty)': 11,\n",
       " 'Distributive Property Verified': True,\n",
       " 'Associative Property Verified': True,\n",
       " 'Transpose Property Verified': True,\n",
       " 'Solution of Ax=b': array([2.2, 3.6])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results\n",
    "import pandas as pd\n",
    "results = {\n",
    "    \"Matrix Multiplication (C=AB)\": C,\n",
    "    \"Hadamard Product (Element-wise)\": hadamard_product,\n",
    "    \"Dot Product (x^Ty)\": dot_product,\n",
    "    \"Distributive Property Verified\": distributive_test,\n",
    "    \"Associative Property Verified\": associative_test,\n",
    "    \"Transpose Property Verified\": transpose_test,\n",
    "    \"Solution of Ax=b\": x_solution\n",
    "}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ace_tools_open\n",
      "  Downloading ace_tools_open-0.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from ace_tools_open) (2.2.3)\n",
      "Collecting itables (from ace_tools_open)\n",
      "  Downloading itables-2.2.5-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: IPython in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from ace_tools_open) (8.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from IPython->ace_tools_open) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from IPython->ace_tools_open) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from IPython->ace_tools_open) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from IPython->ace_tools_open) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from IPython->ace_tools_open) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from IPython->ace_tools_open) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from IPython->ace_tools_open) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from IPython->ace_tools_open) (5.14.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from itables->ace_tools_open) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from pandas->ace_tools_open) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from pandas->ace_tools_open) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from pandas->ace_tools_open) (2025.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from jedi>=0.16->IPython->ace_tools_open) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->ace_tools_open) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ace_tools_open) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from stack_data->IPython->ace_tools_open) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from stack_data->IPython->ace_tools_open) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from stack_data->IPython->ace_tools_open) (0.2.3)\n",
      "Downloading ace_tools_open-0.1.0-py3-none-any.whl (3.0 kB)\n",
      "Downloading itables-2.2.5-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.5 MB/s eta 0:00:00\n",
      "Installing collected packages: itables, ace_tools_open\n",
      "Successfully installed ace_tools_open-0.1.0 itables-2.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ace_tools_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix and Vector Operations Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table id=\"itables_cef5280b_19bb_4398_9681_27983cad6676\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      \n",
       "      <th>Operation</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "Loading ITables v2.2.5 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</tr></tbody>\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_cef5280b_19bb_4398_9681_27983cad6676:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        // Define the table data\n",
       "        const data = [[\"Matrix Multiplication (C=AB)\", \"[[19, 22], [43, 50]]\"], [\"Hadamard Product (Element-wise)\", \"[[5, 12], [21, 32]]\"], [\"Dot Product (x^Ty)\", \"11\"], [\"Distributive Property Verified\", \"True\"], [\"Associative Property Verified\", \"True\"], [\"Transpose Property Verified\", \"True\"], [\"Solution of Ax=b\", \"[2.2, 3.6]\"]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display results in a structured table format\n",
    "import ace_tools_open as tools\n",
    "\n",
    "# Formatting results for display\n",
    "formatted_results = {\n",
    "    \"Matrix Multiplication (C=AB)\": str(C.tolist()),\n",
    "    \"Hadamard Product (Element-wise)\": str(hadamard_product.tolist()),\n",
    "    \"Dot Product (x^Ty)\": dot_product,\n",
    "    \"Distributive Property Verified\": distributive_test,\n",
    "    \"Associative Property Verified\": associative_test,\n",
    "    \"Transpose Property Verified\": transpose_test,\n",
    "    \"Solution of Ax=b\": str(x_solution.tolist())\n",
    "}\n",
    "\n",
    "# Convert results into a structured DataFrame with strings for display compatibility\n",
    "df_results = pd.DataFrame(list(formatted_results.items()), columns=['Operation', 'Result'])\n",
    "\n",
    "# Display the results\n",
    "tools.display_dataframe_to_user(name=\"Matrix and Vector Operations Results\", dataframe=df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How Matrix and Vector Multiplication is Used in Deep Learning**\n",
    "\n",
    "1. **Neural Network Computation**  \n",
    "   - Matrix multiplication is essential for forward propagation, where **inputs are transformed by weight matrices**.  \n",
    "   - Each layer in a neural network performs **\\( C = A @ B \\)**, where **A** is the input matrix and **B** represents learned weights.\n",
    "\n",
    "2. **Optimization & Learning**  \n",
    "   - The **dot product** helps compute gradients in **backpropagation**, adjusting weights to minimize loss.  \n",
    "   - Matrix transposition \\( (AB)^T = B^T A^T \\) is frequently used in computing derivatives.\n",
    "\n",
    "3. **Feature Extraction & Transformations**  \n",
    "   - **Hadamard products** (\\( C = A \\odot B \\)) appear in element-wise operations like activation functions and feature-wise scaling.\n",
    "\n",
    "4. **Solving Systems in AI Models**  \n",
    "   - Many machine learning algorithms solve systems of equations **Ax = b**, using methods like `np.linalg.solve(A, b)`, particularly in **linear regression** and **model parameter estimation**.\n",
    "\n",
    "5. **Efficiency & Parallelization**  \n",
    "   - **Batch processing** in deep learning relies on efficient matrix operations, leveraging **GPUs** for parallelized multiplication.\n",
    "\n",
    "Matrix operations **enable deep learning models to process, transform, and optimize data**, forming the mathematical foundation of modern AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix and Vector Operations Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table id=\"itables_acfa1313_8999_4bd9_919b_714f1c8fa221\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      \n",
       "      <th>Operation</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "Loading ITables v2.2.5 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</tr></tbody>\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_acfa1313_8999_4bd9_919b_714f1c8fa221:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        // Define the table data\n",
       "        const data = [[\"Input:\", \"[[tensor(1.), tensor(2.), tensor(3.)]]\"], [\"Output:\", \"[[tensor(-0.6031, grad_fn=<UnbindBackward0>), tensor(0.5964, grad_fn=<UnbindBackward0>)]]\"], [\"Access learned weights (B):\", \"tensor([[-0.4519,  0.1769, -0.2242],\\\\n        [-0.3039,  0.2561,  0.2913]])\"], [\"Access learned bias:\", \"tensor([ 0.1675, -0.4859])\"], [\"Manual calculation:\", \"tensor([[-0.6031,  0.5964]])\"]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Neural Network Computation\n",
    "import torch \n",
    "from torch import nn\n",
    "import ace_tools_open as tools\n",
    "\n",
    "# Simple Neural Network class\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Matrix Multiplication\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "# Example data\n",
    "input_size = 3\n",
    "output_size = 2\n",
    "input_data = torch.tensor\n",
    "\n",
    "input_data = torch.tensor([[1.0, 2.0, 3.0]])  # Input Matrix (A)\n",
    "\n",
    "model = SimpleNeuralNetwork(input_size, output_size)\n",
    "\n",
    "# Perform forward propagation\n",
    "output = model.forward(input_data)\n",
    "\n",
    "# print(\"Input:\", input_data)\n",
    "# print(\"Output:\", output)\n",
    "\n",
    "# # Access learned weights (B)\n",
    "# weights = model.linear.weight.data\n",
    "# print(\"\\nAccess learned weights (B):\")\n",
    "# print(weights)\n",
    "\n",
    "# # Access learned bias\n",
    "# bias = model.linear.bias.data\n",
    "# print(\"\\nAccess learned bias:\")\n",
    "# print(bias)\n",
    "\n",
    "# # Manual calculation of matrix multiplication\n",
    "# manual_output = torch.mm(input_data, weights.T) + bias\n",
    "# print(\"\\nManual calculation:\")\n",
    "# print(manual_output)\n",
    "\n",
    "\n",
    "\n",
    "# Formatting results for display\n",
    "formatted_results = {\n",
    "    \"Input:\": input_data,\n",
    "    \"Output:\": output,\n",
    "    \"Access learned weights (B):\": str(model.linear.weight.data),\n",
    "    \"Access learned bias:\": str(model.linear.bias.data),\n",
    "    \"Manual calculation:\": str(torch.mm(input_data, model.linear.weight.data.T) + model.linear.bias.data),\n",
    "}\n",
    "\n",
    "# Convert results into a structured DataFrame with strings for display compatibility\n",
    "df_results = pd.DataFrame(list(formatted_results.items()), columns=['Operation', 'Result'])\n",
    "\n",
    "# Display the results\n",
    "tools.display_dataframe_to_user(name=\"Matrix and Vector Operations Results\", dataframe=df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Matrix Inverses, Linear Dependence, and Span in Python**\n",
    "\n",
    "In deep learning and linear algebra, the concept of **matrix inversion** and **linear dependence** is essential for solving equations, optimizing models, and understanding transformations. Below, we summarize these key concepts and implement them using Python.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Matrix Inverse & Solving Equations**\n",
    "To solve the equation:  \n",
    "\\[\n",
    "$Ax = b$\n",
    "\\]\n",
    "we can express the solution using the **inverse of A**:\n",
    "\\[\n",
    "$x = A^{-1} b$\n",
    "\\]\n",
    "This method works **only if** the inverse of **A** exists.\n",
    "\n",
    "**Python Implementation:**\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 3], [1, 4]])  # 2x2 invertible matrix\n",
    "b = np.array([8, 11])  # Known vector\n",
    "\n",
    "# Compute the inverse of A\n",
    "A_inv = np.linalg.inv(A)\n",
    "\n",
    "# Solve for x using matrix inversion\n",
    "x = A_inv @ b\n",
    "```\n",
    "âš  **Note:**  \n",
    "In practice, **using the inverse is not recommended** due to numerical precision issues. Instead, use `np.linalg.solve(A, b)`, which is more stable.\n",
    "\n",
    "```python\n",
    "x = np.linalg.solve(A, b)  # Preferred way to solve Ax = b\n",
    "```\n",
    "---\n",
    "\n",
    "## **2. Linear Dependence & Span**\n",
    "A **set of vectors is linearly dependent** if one of them can be written as a **linear combination** of the others.\n",
    "\n",
    "\\[\n",
    "$Ax = \\sum_i x_i A_{:,i}$\n",
    "\\]\n",
    "\n",
    "The **span** of a set of vectors is the set of all points that can be obtained by a **linear combination** of those vectors:\n",
    "\n",
    "\\[\n",
    "$\\sum_i c_i v^{(i)}$\n",
    "\\]\n",
    "\n",
    "**Python Implementation (Checking Linear Dependence):**\n",
    "```python\n",
    "A = np.array([[1, 2], [2, 4]])  # Two identical columns â†’ linearly dependent\n",
    "rank_A = np.linalg.matrix_rank(A)  # Rank of the matrix\n",
    "\n",
    "# If rank < number of columns, the matrix is linearly dependent\n",
    "is_dependent = rank_A < A.shape[1]\n",
    "```\n",
    "ðŸ’¡ **Key Idea**:  \n",
    "If the number of **linearly independent** columns **is less than the total columns**, the matrix **cannot span the entire space**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Conditions for a Matrix to Have an Inverse**\n",
    "For **A** to be invertible:\n",
    "- **It must be square**: \\( m = n \\)\n",
    "- **Its columns must be linearly independent** (full rank)\n",
    "\n",
    "If **A** is **singular** (non-invertible), solving \\( Ax = b \\) requires an alternative approach like **pseudo-inverse**.\n",
    "\n",
    "```python\n",
    "# Compute the pseudo-inverse (Moore-Penrose)\n",
    "A_pinv = np.linalg.pinv(A)\n",
    "x_pseudo = A_pinv @ b\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Right and Left Inverses**\n",
    "A matrix **inverse** satisfies:\n",
    "\n",
    "\\[\n",
    "$A A^{-1} = I$\n",
    "\\]\n",
    "\n",
    "For **square matrices**, the **left** and **right** inverse are the same.\n",
    "\n",
    "**Python Implementation:**\n",
    "```python\n",
    "I = A_inv @ A  # Identity matrix\n",
    "is_identity = np.allclose(I, np.eye(A.shape[0]))  # Check if A_inv * A = I\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "| **Concept** | **Mathematical Representation** | **Python Equivalent** |\n",
    "|------------|--------------------------------|----------------------|\n",
    "| **Matrix Inverse** | \\( A^{-1} \\) | `np.linalg.inv(A)` |\n",
    "| **Solving Ax = b** | \\( x = A^{-1}b \\) | `np.linalg.solve(A, b)` |\n",
    "| **Linear Dependence** | \\( \\text{rank}(A) < n \\) | `np.linalg.matrix_rank(A) < A.shape[1]` |\n",
    "| **Pseudo-inverse** | \\( A^+ \\) | `np.linalg.pinv(A)` |\n",
    "| **Right & Left Inverse** | \\( A A^{-1} = I \\) | `A_inv @ A == np.eye(n)` |\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "Understanding **matrix inversion, dependence, and span** is crucial for **solving equations, optimizing neural networks, and understanding data transformations** in deep learning. While matrix inverses are important in theory, numerical methods like **least squares solutions** and **pseudo-inverses** are often preferred in real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise Imagine you have a simple dataset with two inputs (x1, x2) and one output (y). We want to build a linear neural network to predict y data x1 and x2.\n",
    "\n",
    "# Step 1: Data Generation\n",
    "# Let's create a synthetic dataset with linear dependence between input and output.\n",
    "# Linear dependence and span affect the stability and learning ability of models.\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]]) # Input: 4 Samples 2 Features\n",
    "y = np.array([3, 5, 7, 9]) # Output: 4 Samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial predictions: [15 25 35 45]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Building the Linear Neural Network\n",
    "\n",
    "# We use NumPy to build a \"manual\" linear neural network.\n",
    "\n",
    "# Initialize the weights\n",
    "weights = np.array([5, 5]) # Initial weights\n",
    "\n",
    "# Prediction function\n",
    "def predict(X, weights):\n",
    "    return np.dot(X, weights) # Matrix multiplication (input * weights)\n",
    "\n",
    "# Perform prediction\n",
    "predictions = predict(X, weights)\n",
    "print(\"Initial predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error: 656.0\n",
      "New predictions: [ 9.84 16.56 23.28 30.  ]\n",
      "New error: 221.6144\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Calculate Error and Update Weights\n",
    "\n",
    "# We calculate the error and update the weights using the gradient.\n",
    "\n",
    "# Cost function (Mean Squared Error)\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Calculate the initial error\n",
    "error = mse(y, predictions)\n",
    "print(\"Initial error:\", error)\n",
    "\n",
    "# Calculate the gradient (derivative of the error with respect to the weights)\n",
    "gradient = 2 * np.dot(X.T, (predictions - y)) / len(y)\n",
    "\n",
    "# Update the weights (gradient descent)\n",
    "learning_rate = 0.01\n",
    "weights = weights - learning_rate * gradient\n",
    "\n",
    "# Make a new prediction and calculate the error\n",
    "new_predictions = predict(X, weights)\n",
    "new_error = mse(y, new_predictions)\n",
    "print(\"New predictions:\", new_predictions)\n",
    "print(\"New error:\", new_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of input matrix: 2\n",
      "Linear dependence: False\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Linear Dependence and Rank Analysis\n",
    "\n",
    "# Let's analyze the linear dependence of the input data.\n",
    "\n",
    "# Calculate the rank of the input matrix\n",
    "rank_X = np.linalg.matrix_rank(X)\n",
    "print(\"Rank of input matrix:\", rank_X)\n",
    "\n",
    "# Check for linear dependence\n",
    "is_linearly_dependent = rank_X < X.shape[1]\n",
    "# If rank < number of columns, the matrix is linearly dependent\n",
    "print(\"Linear dependence:\", is_linearly_dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Inverse and Pseudo-Inverse (Optional)\n",
    "\n",
    "# Let's try to solve the system Ax = y using the inverse and pseudo-inverse.\n",
    "\n",
    "try: # Try to compute the inverse (may not exist)\n",
    "    X_inv = np.linalg.inv(X)\n",
    "    x_solution = np.dot(X_inv, y)\n",
    "    print(\"Solution with inverse:\", x_solution)\n",
    "except np.linalg.LinAlgError:\n",
    "    print(\"The input matrix is â€‹â€‹not invertible.\")\n",
    "\n",
    "# Compute the pseudo-inverse\n",
    "X_pinv = np.linalg.pinv(X)\n",
    "x_pseudo_solution = np.dot(X_pinv, y)\n",
    "print(\"Solution with pseudo-inverse:\", x_pseudo_solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
