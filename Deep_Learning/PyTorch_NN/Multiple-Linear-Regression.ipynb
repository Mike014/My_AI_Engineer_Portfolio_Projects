{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ffe6f6",
   "metadata": {},
   "source": [
    "### **Multiple Linear Regression**\n",
    "\n",
    "1. **What is it?**\n",
    "\n",
    "* Instead of a single predictor (X), multiple independent variables are used (*X₁, X₂, …, Xₙ*).\n",
    "* Each variable has a **weight (w)** that measures its influence on Y, plus a **bias (b)**.\n",
    "* The equation becomes:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w_1X_1 + w_2X_2 + … + w_nX_n + b\n",
    "$$\n",
    "\n",
    "2. **Tensor Representation**\n",
    "\n",
    "* An input sample is a **(1×D) vector**.\n",
    "* The weights are a **(D×1) vector**.\n",
    "* The prediction is calculated as the **dot product** of X and w, plus the bias.\n",
    "* For multiple samples, use a **matrix X (N×D)** where N = number of samples and D = number of features.\n",
    "\n",
    "3. **Visualization**\n",
    "\n",
    "* Each sample can be colored to show how it is transformed.\n",
    "* Directed graphs (nodes = features, edges = weights) help understand the mechanism, also useful for neural networks.\n",
    "\n",
    "4. **Using PyTorch**\n",
    "\n",
    "* Use `nn.Linear(in_features, out_features)`, which directly implements the linear function.\n",
    "* The parameters (weights and biases) are initialized randomly.\n",
    "* We can inspect them with `parameters()` or `state_dict()`.\n",
    "* Input → tensor (samples as rows). Output → tensor with predictions.\n",
    "\n",
    "5. **Custom Module**\n",
    "\n",
    "* In PyTorch, you can create custom modules by inheriting from `nn.Module`.\n",
    "* It implements a constructor (`__init__`) and the `forward` method.\n",
    "* Although similar to `nn.Linear`, it serves as a foundation for building more complex models (e.g., neural networks).\n",
    "\n",
    "---\n",
    "\n",
    "### In Summary\n",
    "\n",
    "* Multiple linear regression is a linear transformation that combines independent variables to predict an output.\n",
    "* In PyTorch, it's easily managed with `nn.Linear`, which automates weights and biases.\n",
    "* Creating a custom module is a crucial intermediate step in understanding how neural network building blocks work.§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be0ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2631642acf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the libraries and set the random seed\n",
    "from torch import nn\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# In PyTorch, weights and biases for models (nn.Linear, neural networks, etc.) are initialized randomly.\n",
    "# If you don't specify a seed, the values ​​change every time you run the program → different results.\n",
    "# If you specify torch.manual_seed(1), you always get the same sequence of random numbers, and therefore the same initial weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d097dd",
   "metadata": {},
   "source": [
    "### **Prediction**\n",
    "\n",
    "Set weight and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03993385",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([[2.0], [3.0]], requires_grad=True) # weights\n",
    "b = torch.tensor([[1.]], requires_grad=True) # bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23237e60",
   "metadata": {},
   "source": [
    "Define the parameters. torch.mm uses matrix multiplication instead of scaler multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def forward(x):\n",
    "    yhat = torch.mm(x, w) + b\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c0b50",
   "metadata": {},
   "source": [
    "$$ y = xw + b $$\n",
    "\n",
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.6.1_matrix_eq.png\" width=\"600\" alt=\"Matrix Linear Regression\">\n",
    "\n",
    "\n",
    "1. **x** → the input data (features).\n",
    "\n",
    "* It can be a single sample (vector) or multiple samples (matrix).\n",
    "* Ex: in the case of multiple linear regression, each column is an independent variable $X_1, X_2, ... X_D$.\n",
    "\n",
    "2. **w (weights)** → the model weights.\n",
    "\n",
    "* These are **trainable parameters** that change during training.\n",
    "* They indicate the importance of each variable in influencing the output.\n",
    "\n",
    "3. **b (bias)** → offset term.\n",
    "\n",
    "* This is not an \"error\", but a constant that **translates** the line (or hyperplane) with respect to the origin.\n",
    "* It is used to allow the model to better fit the data even when the inputs are zero.\n",
    "\n",
    "4. **yhat** → the predicted output.\n",
    "\n",
    "* This is the linear combination of the inputs with the weights plus the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "391c0a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result:  tensor([[9.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate yhat\n",
    "x = torch.tensor([[1.0, 2.0]])\n",
    "yhat = forward(x)\n",
    "print(\"The result: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aabc038",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/JBkvPoMCCa-PDXCF_4aQfQ/image%20-1-.png\" width=\"300\" alt=\"Linear Regression Matrix Sample One\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33b9da",
   "metadata": {},
   "source": [
    "# Each row of the following tensor represents a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec14accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result:  tensor([[ 6.],\n",
      "        [ 9.],\n",
      "        [12.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sample tensor X\n",
    "\n",
    "X = torch.tensor([[1.0, 1.0], [1.0, 2.0], [1.0, 3.0]])\n",
    "\n",
    "# Make the prediction of X \n",
    "\n",
    "yhat = forward(X)\n",
    "print(\"The result: \", yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Class\n",
    "\n",
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # input size are features, the output it's just the predicted value\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "        \n",
    "    # Prediction Function\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43894d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Build a model to predict the follow tensor.\n",
    "X = torch.tensor([[11.0, 12.0, 13, 14], # first row \n",
    "                  [11, 12, 13, 14]])  # second row\n",
    "\n",
    "# It has the form (2, 4) → 2 rows and 4 columns.\n",
    "# Each row is a sample.\n",
    "# Each column is a feature (independent variable).\n",
    "\n",
    "\n",
    "model = linear_regression(4, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb2df59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.2828],\n",
       "        [6.2828]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction \n",
    "yhat = model(X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb9f7d",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "1. **Cost function**\n",
    "\n",
    "* It is used to measure how far the predictions $\\hat{y}$ are from the actual values ​​$y$.\n",
    "* In regression, the **MSE (Mean Squared Error)** is commonly used:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum (y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "2. **Model parameters**\n",
    "\n",
    "* If you have $d$ inputs (features), the model has **d weights + 1 bias**.\n",
    "* Ex: 2-dimensional input → 3 parameters (w₁, w₂, b).\n",
    "* 3-dimensional input → 4 parameters (w₁, w₂, w₃, b).\n",
    "\n",
    "3. **Gradient descent**\n",
    "\n",
    "* Calculate the derivative of the loss with respect to weights and biases.\n",
    "* Update the parameters in the direction that reduces the error:\n",
    "\n",
    "$$\n",
    "w := w - \\eta \\frac{\\partial L}{\\partial w}, \\quad b := b - \\eta \\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementation in PyTorch\n",
    "\n",
    "1. **Dataset**\n",
    "\n",
    "* A `Data2D` class is used (two input variables, one output).\n",
    "* The data is loaded with a **DataLoader** that returns batch (here batch\\_size=2).\n",
    "\n",
    "2. **Model**\n",
    "\n",
    "* Created with `nn.Linear(2,1)` → 2 input features, 1 output.\n",
    "\n",
    "3. **Criterion (loss function)**\n",
    "\n",
    "* Use `nn.MSELoss()` to calculate the mean squared error.\n",
    "\n",
    "4. **Optimizer**\n",
    "\n",
    "* Ex: `torch.optim.SGD(model.parameters(), lr=0.1)` to update the weights.\n",
    "\n",
    "5. **Training loop**\n",
    "For each epoch:\n",
    "\n",
    "* Make the prediction (`yhat = model(x)`).\n",
    "* Calculate the loss.\n",
    "* Set the gradients to zero (`optimizer.zero_grad()`).\n",
    "* Perform backpropagation (`loss.backward()`).\n",
    "* Update the parameters (`optimizer.step()`).\n",
    "\n",
    "---\n",
    "\n",
    "### Result\n",
    "\n",
    "* Initially, the plane (the learned linear function) **does not fit the data well**.\n",
    "* After ~100 epochs, the plan adapts and follows the dataset points much better.\n",
    "\n",
    "---\n",
    "\n",
    "In summary:\n",
    "The algorithm is used to **teach the model the optimal values ​​of weights and biases** to reduce the error between predictions and actual data, using **gradient descent** and a **cost function**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4164382",
   "metadata": {},
   "source": [
    "### **What it is:** Multi-output linear regression.\n",
    "\n",
    "With $D$ input features and $M$ outputs, the model is\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = W^\\top \\mathbf{x} + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "where $W \\in \\mathbb{R}^{D\\times M}$ (columns = features/outputs) and $\\mathbf{b} \\in \\mathbb{R}^{M}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd4154",
   "metadata": {},
   "source": [
    "* **Column insight:** Each **column of $W$** defines a different linear function of the input $\\mathbf{x}$. Take the **dot product** $\\mathbf{x}\\cdot W_{:,j}$ and then add $b_j$ → you get the $j$-th output.\n",
    "\n",
    "* **Sample batch:** with $X \\in \\mathbb{R}^{N\\times D}$ (rows = samples) the prediction is\n",
    "\n",
    "$$\n",
    "Y = XW + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "with $Y \\in \\mathbb{R}^{N\\times M}$. The bias is broadcast across all rows.\n",
    "\n",
    "* **Element-by-element reading:** $Y_{i,j} = X_{i,:}\\cdot W_{:,j} + b_j$.\n",
    "\n",
    "* **PyTorch:** uses `nn.Linear(in_features=D, out_features=M)`.\n",
    "\n",
    "* Single input: `x` with shape `(D,)` → output `(M,)`.\n",
    "* Batch: `X` with shape `(N, D)` → output `(N, M)`.\n",
    "(Internally, PyTorch stores the weights as `(M, D)` and adds the bias `(M,)`.)\n",
    "\n",
    "* **Mental graph:** feature nodes → (weights = edges) → output nodes. Each output sums weights × features + bias.\n",
    "\n",
    "* **Basic idea**: We want a **model** that, given one **input** (several numbers together), produces **multiple results** instead of just one.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfcbb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c7b69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11ae08ced50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d807e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # input size are features, the output it's just the predicted value\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "        \n",
    "    # Prediction Function\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd131d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7926, -0.3920,  0.1714,  0.0797, -1.0143,  0.5097, -0.0608,  0.5047,\n",
       "          1.0132,  0.1887]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_regression(1, 10)\n",
    "model(torch.tensor([[1.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8229a94",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/icmwnxru7nytlhnq5x486rffea9ncpk7.png\" width=\"600,\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d51f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5153],\n",
       "         [-0.4414],\n",
       "         [-0.1939],\n",
       "         [ 0.4694],\n",
       "         [-0.9414],\n",
       "         [ 0.5997],\n",
       "         [-0.2057],\n",
       "         [ 0.5087],\n",
       "         [ 0.1390],\n",
       "         [-0.1224]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2774,  0.0493,  0.3652, -0.3897, -0.0729, -0.0900,  0.1449, -0.0040,\n",
       "          0.8742,  0.3112], requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8b5c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ad67e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7926, -0.3920,  0.1714,  0.0797, -1.0143,  0.5097, -0.0608,  0.5047,\n",
       "          1.0132,  0.1887]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can make a prediction with the model\n",
    "yhat = model(x)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38637bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7926, -0.3920,  0.1714,  0.0797, -1.0143,  0.5097, -0.0608,  0.5047,\n",
       "          1.0132,  0.1887],\n",
       "        [ 0.7926, -0.3920,  0.1714,  0.0797, -1.0143,  0.5097, -0.0608,  0.5047,\n",
       "          1.0132,  0.1887],\n",
       "        [ 1.8232, -1.2748, -0.2164,  1.0184, -2.8972,  1.7091, -0.4722,  1.5222,\n",
       "          1.2912, -0.0561]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row in the following tensor represents a different sample with a single feature\n",
    "\n",
    "X=torch.tensor([[1.0],[1.0],[3.0]])\n",
    "Yhat=model(X)\n",
    "Yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c420b18",
   "metadata": {},
   "source": [
    " <img src=\"https://ibm.box.com/shared/static/768cul6pj8hc93uh9ujpajihnp8xdukx.png\" width=\"600,\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba76daa",
   "metadata": {},
   "source": [
    "### **Training Linear Regression Multiple Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59870798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn,optim\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c8e820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25dab9eabf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1174dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset class with two-dimensional features and two targets: \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "            self.x=torch.zeros(20,2)\n",
    "            self.x[:,0]=torch.arange(-1,1,0.1)\n",
    "            self.x[:,1]=torch.arange(-1,1,0.1)\n",
    "            self.w=torch.tensor([ [1.0,-1.0],[1.0,3.0]])\n",
    "            self.b=torch.tensor([[1.0,-1.0]])\n",
    "            self.f=torch.mm(self.x,self.w)+self.b\n",
    "            \n",
    "            self.y=self.f+0.001*torch.randn((self.x.shape[0],1))\n",
    "            self.len=self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fcbde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset object \n",
    "data_set=Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a72f23",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h2 align=center>Create the Model, Optimizer, and Total Loss Function (cost)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d67ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(linear_regression,self).__init__()\n",
    "        self.linear=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        yhat=self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066fa29",
   "metadata": {},
   "source": [
    "Create an optimizer object and set the learning rate to 0.1. **Don't forget to enter the model parameters in the constructor.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e7aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=linear_regression(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5c0f7",
   "metadata": {},
   "source": [
    "Create an optimizer object and set the learning rate to 0.1. **Don't forget to enter the model parameters in the constructor.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1666f",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/f8hskuwrnctjg21agud69ddla0jkbef5.png\" width=\"100,\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ed92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319f8c0",
   "metadata": {},
   "source": [
    "Create the criterion function that calculates the total loss or cost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f877eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f5ab1",
   "metadata": {},
   "source": [
    "Create a data loader object and set the batch_size to 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8dea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=data_set,batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2c9e0",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "<h2 align=center>Train the Model via Mini-Batch Gradient Descent </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c54a5",
   "metadata": {},
   "source": [
    "Run 100 epochs of Mini-Batch Gradient Descent and store the total loss or cost for every iteration. Remember that this is an approximation of the true total loss or cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bab0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS=[]\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x,y in train_loader:\n",
    "        #make a prediction \n",
    "        yhat=model(x)\n",
    "        #calculate the loss\n",
    "        loss=criterion(yhat,y)\n",
    "        #store loss/cost \n",
    "        LOSS.append(loss.item())\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        #the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390b8c7",
   "metadata": {},
   "source": [
    "Plot the cost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3106b0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LOSS)\n",
    "plt.xlabel(\"iterations \")\n",
    "plt.ylabel(\"Cost/total loss \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7775c5b",
   "metadata": {},
   "source": [
    "### 1. **Objective**\n",
    "\n",
    "Train a **linear regression model with two inputs and two outputs** using PyTorch, that is, teach the model the relationship between the data and the labels (targets).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Create the data**\n",
    "\n",
    "* Define a `Data` class that generates:\n",
    "\n",
    "* **input (x)**: pairs of numbers (2 columns).\n",
    "* **target (y)**: values ​​calculated with a formula that uses weights and biases, plus a small amount of noise.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **The model**\n",
    "\n",
    "* Create a `linear_regression` class that uses the pre-built `nn.Linear` layer.\n",
    "* This layer learns the **weights** and **biases** that connect inputs → outputs.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Optimizer and Cost**\n",
    "\n",
    "* **Optimizer**: `optim.SGD` with learning rate 0.1 → used to update the weights.\n",
    "* **Cost Function**: `nn.MSELoss()` → measures how far the predictions are from the targets (smaller = better).\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Data Loader**\n",
    "\n",
    "* A `DataLoader` is used with batches of 5 → instead of passing all the data at once, it sends it to the model in chunks.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Training**\n",
    "\n",
    "* **100 epochs** cycle:\n",
    "\n",
    "1. The model makes a **prediction**.\n",
    "2. The **loss** (error) is calculated.\n",
    "3. The old gradients are reset to zero.\n",
    "4. The **new gradients** are calculated (how much to change the weights).\n",
    "5. The optimizer takes a step → updates the parameters.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Result\n",
    "\n",
    "* The loss is saved at each step.\n",
    "* Finally, a graph is drawn: the error should decrease over time.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
