{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ffe6f6",
   "metadata": {},
   "source": [
    "### Key Concepts\n",
    "\n",
    "1. **Multiple Linear Regression**\n",
    "\n",
    "* Instead of a single predictor (X), multiple independent variables are used (*X₁, X₂, …, Xₙ*).\n",
    "* Each variable has a **weight (w)** that measures its influence on Y, plus a **bias (b)**.\n",
    "* The equation becomes:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w_1X_1 + w_2X_2 + … + w_nX_n + b\n",
    "$$\n",
    "\n",
    "2. **Tensor Representation**\n",
    "\n",
    "* An input sample is a **(1×D) vector**.\n",
    "* The weights are a **(D×1) vector**.\n",
    "* The prediction is calculated as the **dot product** of X and w, plus the bias.\n",
    "* For multiple samples, use a **matrix X (N×D)** where N = number of samples and D = number of features.\n",
    "\n",
    "3. **Visualization**\n",
    "\n",
    "* Each sample can be colored to show how it is transformed.\n",
    "* Directed graphs (nodes = features, edges = weights) help understand the mechanism, also useful for neural networks.\n",
    "\n",
    "4. **Using PyTorch**\n",
    "\n",
    "* Use `nn.Linear(in_features, out_features)`, which directly implements the linear function.\n",
    "* The parameters (weights and biases) are initialized randomly.\n",
    "* We can inspect them with `parameters()` or `state_dict()`.\n",
    "* Input → tensor (samples as rows). Output → tensor with predictions.\n",
    "\n",
    "5. **Custom Module**\n",
    "\n",
    "* In PyTorch, you can create custom modules by inheriting from `nn.Module`.\n",
    "* It implements a constructor (`__init__`) and the `forward` method.\n",
    "* Although similar to `nn.Linear`, it serves as a foundation for building more complex models (e.g., neural networks).\n",
    "\n",
    "---\n",
    "\n",
    "### In Summary\n",
    "\n",
    "* Multiple linear regression is a linear transformation that combines independent variables to predict an output.\n",
    "* In PyTorch, it's easily managed with `nn.Linear`, which automates weights and biases.\n",
    "* Creating a custom module is a crucial intermediate step in understanding how neural network building blocks work.§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be0ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2631642acf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the libraries and set the random seed\n",
    "from torch import nn\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# In PyTorch, weights and biases for models (nn.Linear, neural networks, etc.) are initialized randomly.\n",
    "# If you don't specify a seed, the values ​​change every time you run the program → different results.\n",
    "# If you specify torch.manual_seed(1), you always get the same sequence of random numbers, and therefore the same initial weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d097dd",
   "metadata": {},
   "source": [
    "### **Prediction**\n",
    "\n",
    "Set weight and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03993385",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([[2.0], [3.0]], requires_grad=True)\n",
    "b = torch.tensor([[1.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23237e60",
   "metadata": {},
   "source": [
    "Define the parameters. torch.mm uses matrix multiplication instead of scaler multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e699f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    yhat = torch.mm(x, w) + b\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c0b50",
   "metadata": {},
   "source": [
    "$$ y = xw + b $$\n",
    "\n",
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.6.1_matrix_eq.png\" width=\"600\" alt=\"Matrix Linear Regression\">\n",
    "\n",
    "\n",
    "1. **x** → the input data (features).\n",
    "\n",
    "* It can be a single sample (vector) or multiple samples (matrix).\n",
    "* Ex: in the case of multiple linear regression, each column is an independent variable $X_1, X_2, ... X_D$.\n",
    "\n",
    "2. **w (weights)** → the model weights.\n",
    "\n",
    "* These are **trainable parameters** that change during training.\n",
    "* They indicate the importance of each variable in influencing the output.\n",
    "\n",
    "3. **b (bias)** → offset term.\n",
    "\n",
    "* This is not an \"error\", but a constant that **translates** the line (or hyperplane) with respect to the origin.\n",
    "* It is used to allow the model to better fit the data even when the inputs are zero.\n",
    "\n",
    "4. **yhat** → the predicted output.\n",
    "\n",
    "* This is the linear combination of the inputs with the weights plus the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "391c0a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result:  tensor([[9.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate yhat\n",
    "x = torch.tensor([[1.0, 2.0]])\n",
    "yhat = forward(x)\n",
    "print(\"The result: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aabc038",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/JBkvPoMCCa-PDXCF_4aQfQ/image%20-1-.png\" width=\"300\" alt=\"Linear Regression Matrix Sample One\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33b9da",
   "metadata": {},
   "source": [
    "# Each row of the following tensor represents a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec14accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result:  tensor([[ 6.],\n",
      "        [ 9.],\n",
      "        [12.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sample tensor X\n",
    "\n",
    "X = torch.tensor([[1.0, 1.0], [1.0, 2.0], [1.0, 3.0]])\n",
    "\n",
    "# Make the prediction of X \n",
    "\n",
    "yhat = forward(X)\n",
    "print(\"The result: \", yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Class\n",
    "\n",
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # input size are features, the output it's just the predicted value\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "        \n",
    "    # Prediction Function\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43894d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Build a model to predict the follow tensor.\n",
    "X = torch.tensor([[11.0, 12.0, 13, 14], # first row \n",
    "                  [11, 12, 13, 14]])  # second row\n",
    "\n",
    "# It has the form (2, 4) → 2 rows and 4 columns.\n",
    "# Each row is a sample.\n",
    "# Each column is a feature (independent variable).\n",
    "\n",
    "\n",
    "model = linear_regression(4, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb2df59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.2828],\n",
       "        [6.2828]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction \n",
    "yhat = model(X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb9f7d",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "1. **Cost function**\n",
    "\n",
    "* It is used to measure how far the predictions $\\hat{y}$ are from the actual values ​​$y$.\n",
    "* In regression, the **MSE (Mean Squared Error)** is commonly used:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum (y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "2. **Model parameters**\n",
    "\n",
    "* If you have $d$ inputs (features), the model has **d weights + 1 bias**.\n",
    "* Ex: 2-dimensional input → 3 parameters (w₁, w₂, b).\n",
    "* 3-dimensional input → 4 parameters (w₁, w₂, w₃, b).\n",
    "\n",
    "3. **Gradient descent**\n",
    "\n",
    "* Calculate the derivative of the loss with respect to weights and biases.\n",
    "* Update the parameters in the direction that reduces the error:\n",
    "\n",
    "$$\n",
    "w := w - \\eta \\frac{\\partial L}{\\partial w}, \\quad b := b - \\eta \\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementation in PyTorch\n",
    "\n",
    "1. **Dataset**\n",
    "\n",
    "* A `Data2D` class is used (two input variables, one output).\n",
    "* The data is loaded with a **DataLoader** that returns batch (here batch\\_size=2).\n",
    "\n",
    "2. **Model**\n",
    "\n",
    "* Created with `nn.Linear(2,1)` → 2 input features, 1 output.\n",
    "\n",
    "3. **Criterion (loss function)**\n",
    "\n",
    "* Use `nn.MSELoss()` to calculate the mean squared error.\n",
    "\n",
    "4. **Optimizer**\n",
    "\n",
    "* Ex: `torch.optim.SGD(model.parameters(), lr=0.1)` to update the weights.\n",
    "\n",
    "5. **Training loop**\n",
    "For each epoch:\n",
    "\n",
    "* Make the prediction (`yhat = model(x)`).\n",
    "* Calculate the loss.\n",
    "* Set the gradients to zero (`optimizer.zero_grad()`).\n",
    "* Perform backpropagation (`loss.backward()`).\n",
    "* Update the parameters (`optimizer.step()`).\n",
    "\n",
    "---\n",
    "\n",
    "### Result\n",
    "\n",
    "* Initially, the plane (the learned linear function) **does not fit the data well**.\n",
    "* After ~100 epochs, the plan adapts and follows the dataset points much better.\n",
    "\n",
    "---\n",
    "\n",
    "In summary:\n",
    "The algorithm is used to **teach the model the optimal values ​​of weights and biases** to reduce the error between predictions and actual data, using **gradient descent** and a **cost function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a96732",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
