{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unsupervised Learning in Keras**\n",
    "\n",
    "**What is Unsupervised Learning?**\n",
    "\n",
    "A **machine learning technique** in which the **algorithm analyzes data** to identify **hidden structures and patterns**, **without** using **predetermined labels** or **output variables**.\n",
    "\n",
    "**Unlike supervised learning**—where the **goal is to predict a well-defined outcome—in unsupervised learning**, the main goal is to **understand the intrinsic structure of the data**, discovering spontaneous correlations and groupings.\n",
    "\n",
    "The **three main categories of Unsupervised Learning**\n",
    "\n",
    "1. **Clustering**\n",
    "It consists of **grouping similar data into clusters**, such that the data points in the **same group are more similar to each other** than those in other groups.\n",
    "\n",
    "2. **Association**\n",
    "It consists of **identifying relationships between variables** within **large datasets**.\n",
    "Commonly used in market analysis to discover products that are frequently bought together (e.g., bread and milk).\n",
    "\n",
    "3. **Dimensionality Reduction**\n",
    "It reduces the **number of variables required to describe the data**, while retaining most of the original information.\n",
    "Useful **when datasets have a very large number of variables** that can complicate and slow down the analysis.\n",
    "\n",
    "## **Autoencoder**\n",
    "A special **type of artificial neural network** used predominantly to **learn efficient representations of data**, reducing dimensionality or **extracting relevant features**.\n",
    "\n",
    "**Structure of an Autoencoder:**\n",
    "\n",
    "- **Encoder**: compresses **(encodes)** the **input data** into a **reduced representation (latent space)**.\n",
    "- **Bottleneck**: Compressed Representation\n",
    "- **Decoder**: reconstructs the original data from the compressed representation.\n",
    "\n",
    "### **The autoencoder** is trained by minimizing the **difference between the original input and its generated reconstruction**. This process **forces the model to capture the most significant features** of the data, eliminating redundant or noisy ones.\n",
    "\n",
    "## **Generative Adversarial Networks (GANs)**\n",
    "**GANs** are **neural networks** introduced by Ian Goodfellow in 2014. They **use two neural networks that compete with each other**, creating a competitive **\"game\"**.\n",
    "\n",
    "- **Generator**:\n",
    "\n",
    "**Produces new synthetic data**, trying to **mimic the real data** from the training dataset as closely as possible.\n",
    "\n",
    "- **Discriminator**:\n",
    "\n",
    "**Evaluates** whether the provided **data (real or synthetic) is authentic or not**.\n",
    "\n",
    "The **generator** continually **tries to \"trick\" the discriminator**, producing increasingly realistic data.\n",
    "The **discriminator**, on the other hand, **tries to get better at distinguishing between real data and artificially** generated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)**\n",
    "\n",
    "How can we perform efficient **inference** in direct probabilistic models with continuous latent variables when the posterior distribution is intractable and the datasets are large?\n",
    "\n",
    "- **Inference**: The process of using a trained model to **make predictions** on new, unseen data.\n",
    "- **Latent Variables**: which are **variables that are not directly observable** but are **deduced through mathematical models** from observable variables.\n",
    "\n",
    "### **Fundamental Concepts**\n",
    "\n",
    "Here is a **detailed and clearly explained summary** of the paper **\"Auto-Encoding Variational Bayes\" (Kingma & Welling, 2013-2022)** with the fundamental concepts and key formulas.\n",
    "## What does a **VAE** (Variational AutoEncoder) do, in practice?\n",
    "\n",
    "### 1. **Encoder**\n",
    "- It takes an input data (e.g. an image)\n",
    "- Instead of returning a single point in the compressed space (like a normal autoencoder),\n",
    "**it returns a distribution**:\n",
    "a **mean** $( \\mu )$ and a **standard deviation** $( \\sigma )$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Latent Space**\n",
    "- There is no single \"z\", but it **picks a random point** $$( z )$$ from the distribution $$( \\mathcal{N}(\\mu, \\sigma^2) )$$\n",
    "- This latent space is a **probabilistic representation** of the data:\n",
    "it encodes its main characteristics but also leaves room for uncertainty.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Reparameterization Trick**\n",
    "- The trick is to write:\n",
    "$$[\n",
    "z = \\mu + \\sigma \\cdot \\epsilon \\quad \\text{con} \\quad \\epsilon \\sim \\mathcal{N}(0, 1)\n",
    "]$$\n",
    "- So you can do **backpropagation** even if you have a random component.\n",
    "(Otherwise, the network would not be trainable with gradients.)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Decoder**\n",
    "- Takes the point $( z )$ from the latent space\n",
    "- Tries to **reconstruct the original input**\n",
    "- The goal is that the result resembles the input as much as possible\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Loss Function = Reconstruction + Regularization**\n",
    "\n",
    "$$[\n",
    "\\text{Loss} = \\underbrace{\\text{Reconstruction error}}_{\\text{how well I recreate x}} + \\underbrace{D_{KL}(q(z|x) \\parallel p(z))}_{\\text{how \"normal\" the encoding is}}\n",
    "]$$\n",
    "\n",
    "- The **first part** (reconstruction) measures how well the network has regenerated the input.\n",
    "- The **second part** (KL divergence) forces the latent space to resemble a **standard normal** $( \\mathcal{N}(0, I) )$, so everything stays regular and continuous.\n",
    "\n",
    "---\n",
    "\n",
    "## So, in a dummies summary:\n",
    "\n",
    "> A **VAE** is like a **smart compressor**:\n",
    "> - it takes your data,\n",
    "> - it summarizes it in a **cloud of possibilities** (a distribution),\n",
    "> - from there it extracts a point,\n",
    "> - and **tries to reconstruct** what it had at the beginning.\n",
    ">\n",
    "> The trick is that this probabilistic encoding **can also be used to generate new realistic data**.\n",
    "> And thanks to a \"math trick\" (reparameterization trick), we can train it like a normal neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **“[Generative Adversarial Nets” by Ian Goodfellow (2014), where GANs were introduced.](https://arxiv.org/pdf/1406.2661)**\n",
    "\n",
    "## WHAT ARE GANs?\n",
    "\n",
    "A **GAN (Generative Adversarial Network)** is like a **two-player game** between two neural networks:\n",
    "\n",
    "- **Discriminator (D)**: tries to figure out if an image is **real** (taken from real data) or **fake** (generated).\n",
    "- **Generator (G)**: tries to **trick** the discriminator, creating fake images so realistic that they look real.\n",
    "\n",
    "Imagine G as a counterfeiter drawing money, and D as a policeman trying to catch them.\n",
    "\n",
    "---\n",
    "\n",
    "## HOW IT WORKS (Key Steps)\n",
    "\n",
    "1. G takes a **random vector** (e.g. noise $( z \\sim p(z) )$)\n",
    "and transforms it into a **fake** image $( G(z) )$\n",
    "\n",
    "2. D receives **both real and fake images**\n",
    "and tries to figure out if they are real or generated.\n",
    "\n",
    "3. The system is **trained together**:\n",
    "\n",
    "- D learns to **recognize the fakes**.\n",
    "- G learns to **trick D**.\n",
    "\n",
    "---\n",
    "\n",
    "## BASIC FORMULA: The Minimax Game\n",
    "\n",
    "The goal is:\n",
    "\n",
    "$$[\n",
    "\\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\log D(x)] + \\mathbb{E}_{z \\sim p(z)}[\\log(1 - D(G(z)))]\n",
    "]$$\n",
    "\n",
    "### What this means:\n",
    "- The discriminator **maximizes** the probability of **guessing** the labels.\n",
    "- The generator **minimizes** the probability that D recognizes its \"fakes\".\n",
    "\n",
    "In theory, the game ends when D **cannot distinguish** true from false anymore → $( D(x) = 0.5 )$\n",
    "\n",
    "---\n",
    "\n",
    "## A TRICK: Alternative Objective for G\n",
    "\n",
    "At the beginning, G is terrible, so D always beats it → the gradient for G is too weak.\n",
    "\n",
    "So, instead of minimizing:\n",
    "\n",
    "$[\n",
    "\\log(1 - D(G(z)))\n",
    "]$\n",
    "\n",
    "the generator can directly **maximize**:\n",
    "\n",
    "$[\n",
    "\\log(D(G(z)))\n",
    "]$\n",
    "\n",
    "It's the same in the end, but G gets stronger signals to learn.\n",
    "\n",
    "---\n",
    "\n",
    "## HOW DO YOU TRAIN GANs? (Basic Algorithm)\n",
    "\n",
    "1. Take a **minibatch** of real data $( x )$ and a minibatch of **random noise** $( z )$.\n",
    "2. Train D to **distinguish** (maximize the probability of saying \"true\" for the reals and \"false\" for the generated ones).\n",
    "3. Then update G to **trick D**.\n",
    "\n",
    "Repeat alternating **k steps for D** and **1 step for G**.\n",
    "\n",
    "---\n",
    "\n",
    "## WHAT HAPPENS WHEN IT WORKS?\n",
    "\n",
    "- The generator **learns the distribution of the real data** → $( p_g = p_{\\text{data}} )$\n",
    "- The discriminator **cannot distinguish anymore**, it always gives $( D(x) = 0.5 )$\n",
    "- The system is in equilibrium.\n",
    "\n",
    "---\n",
    "\n",
    "## OPTIMAL EQUILIBRIUM FORMULA\n",
    "\n",
    "When the GAN is perfectly trained:\n",
    "\n",
    "$[\n",
    "D^*(x) = \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}\n",
    "]$\n",
    "\n",
    "and the function to minimize for G is related to the **Jensen–Shannon divergence** between $( p_{\\text{data}} )$ and $( p_g )$.\n",
    "It is minimized when the two become **equal**.\n",
    "\n",
    "---\n",
    "\n",
    "## VISUAL EXAMPLES (experiments)\n",
    "\n",
    "They tested GAN on:\n",
    "\n",
    "- **MNIST** (handwritten numbers)\n",
    "- **TFD** (human faces)\n",
    "- **CIFAR-10** (complex images)\n",
    "\n",
    "The generator created new images, **without ever seeing real examples**, only with noise as input.\n",
    "\n",
    "---\n",
    "\n",
    "## GAN PROS AND CONS\n",
    "\n",
    "### Pros:\n",
    "- **No complicated inference**, just backpropagation.\n",
    "- No **Markov chains**, so easier and faster training.\n",
    "- Can generate **ultra-realistic data**.\n",
    "\n",
    "### Cons:\n",
    "- G and D must be **synchronized** well → otherwise one \"wins\" too much and the GAN crashes.\n",
    "- Generator can fall into **collapse mode**: always produces the same type of data.\n",
    "\n",
    "---\n",
    "\n",
    "## IMPORTANT EXTENSIONS\n",
    "\n",
    "1. **Conditional GAN ​​(cGAN)**: adds labels as input to control the output.\n",
    "2. **Inference nets**: you can train a network to predict $( z )$ from $( x )$, to map data into latent space.\n",
    "3. **Z-space interpolation** → creates smooth transitions between images.\n",
    "4. **Semi-supervised learning** → uses the discriminator as a feature extractor.\n",
    "\n",
    "---\n",
    "\n",
    "## In short, for dummies:\n",
    "\n",
    "> **GANs** are a **game between two neural networks**:\n",
    "> one creates fake data, the other tries to unmask it.\n",
    "> The forger gets better until his creations look real,\n",
    "> the policeman gets better at distinguishing them.\n",
    "> Eventually, the forger gets so good that the policeman **can no longer tell** what is real and what is not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating an AUTOENCODER IN KERAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,960</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │        \u001b[38;5;34m50,960\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,200</span> (395.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,200\u001b[0m (395.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,200</span> (395.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,200\u001b[0m (395.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Encoder\n",
    "input_layer = Input(shape=(784, ))\n",
    "encoded = Dense(64, activation=\"relu\")(input_layer)\n",
    "# Define the Encoder\n",
    "decoded = Dense(784, activation=\"sigmoid\")(encoded)\n",
    "# Combine the Encoder and Decoder into an AutoEncoder Model\n",
    "model = Model(input_layer, decoded)\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "# Summary of the Model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255\n",
    "x_train = x_train.reshape((len(x_train), 784))\n",
    "x_test = x_test.reshape((len(x_test), 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3480 - val_loss: 0.1630\n",
      "Epoch 2/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1541 - val_loss: 0.1279\n",
      "Epoch 3/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1239 - val_loss: 0.1090\n",
      "Epoch 4/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1071 - val_loss: 0.0979\n",
      "Epoch 5/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0970 - val_loss: 0.0907\n",
      "Epoch 6/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0904 - val_loss: 0.0857\n",
      "Epoch 7/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0855 - val_loss: 0.0818\n",
      "Epoch 8/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0818 - val_loss: 0.0792\n",
      "Epoch 9/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0796 - val_loss: 0.0775\n",
      "Epoch 10/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0780 - val_loss: 0.0764\n",
      "Epoch 11/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0769 - val_loss: 0.0755\n",
      "Epoch 12/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0759 - val_loss: 0.0749\n",
      "Epoch 13/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0755 - val_loss: 0.0744\n",
      "Epoch 14/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0750 - val_loss: 0.0741\n",
      "Epoch 15/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0745 - val_loss: 0.0739\n",
      "Epoch 16/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0743 - val_loss: 0.0736\n",
      "Epoch 17/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0741 - val_loss: 0.0734\n",
      "Epoch 18/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0740 - val_loss: 0.0733\n",
      "Epoch 19/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0739 - val_loss: 0.0732\n",
      "Epoch 20/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0738 - val_loss: 0.0730\n",
      "Epoch 21/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0736 - val_loss: 0.0730\n",
      "Epoch 22/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0734 - val_loss: 0.0729\n",
      "Epoch 23/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0734 - val_loss: 0.0728\n",
      "Epoch 24/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 25/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0732 - val_loss: 0.0728\n",
      "Epoch 26/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 27/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0732 - val_loss: 0.0726\n",
      "Epoch 28/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0733 - val_loss: 0.0726\n",
      "Epoch 29/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 30/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 31/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 32/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 33/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0729 - val_loss: 0.0725\n",
      "Epoch 34/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 35/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 36/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 37/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 38/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 39/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 40/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 41/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 42/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 43/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 44/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 45/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 46/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 47/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 48/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 49/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 50/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0726 - val_loss: 0.0723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ee60d2c430>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "model.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating an GAN IN KERAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator model\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(128, input_dim = 100))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(784, activation=\"tanh\"))\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(128, input_shape =(784, ))) \n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan, generator, discriminator, x_train, epochs=400, batch_size=128):\n",
    "    # Loop Through Epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Generate random noise as input for the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        generated_images = generator.predict(noise)\n",
    "\n",
    "        # Generate random set of real images\n",
    "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "        real_images = x_train[idx]\n",
    "\n",
    "        # Labels for real and fake images\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "        # Print the progress\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}%] [G loss: {g_loss}]\")\n",
    "\n",
    "        return d_loss, g_loss\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
