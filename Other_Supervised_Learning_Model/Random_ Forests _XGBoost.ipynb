{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ef5300-5fc6-46dc-a1a6-23dec5611278",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "# Lab: Comparing Random Forest and XGBoost modeling performance\n",
    "Estimated time needed: **20** minutes\n",
    "    \n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "* Use scikit-learn to implement Random Forest and XGBoost regression models\n",
    "* Compare the performances of the two models \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a6bdc-7ae8-42e8-bf9e-52262a64ceda",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, you'll create and measure the relative performances of Random Forest and XGBoost regression models for predicting house prices using the California Housing Dataset.\n",
    "'Performance' means both speed and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961fe51-ab5c-4509-8dbf-bbeb5286adc8",
   "metadata": {},
   "source": [
    "First, we need to install the libraries that will be required in this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0f4304-122a-4617-949d-df3e388a5392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==2.2.0\n",
      "  Using cached numpy-2.2.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.0-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.0) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.0) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.0) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib==3.9.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from matplotlib==3.9.3) (2.9.0.post0)\n",
      "Collecting numpy>=1.23 (from matplotlib==3.9.3)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.9.3) (1.16.0)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.0\n",
      "    Uninstalling numpy-2.2.0:\n",
      "      Successfully uninstalled numpy-2.2.0\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting xgboost==2.1.3\n",
      "  Downloading xgboost-2.1.3-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from xgboost==2.1.3) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from xgboost==2.1.3) (1.13.1)\n",
      "Downloading xgboost-2.1.3-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.1/124.9 MB 11.8 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 5.0/124.9 MB 13.1 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 7.9/124.9 MB 13.5 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 12.3/124.9 MB 15.8 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 16.8/124.9 MB 16.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 20.7/124.9 MB 17.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 23.3/124.9 MB 16.8 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 26.2/124.9 MB 16.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 28.6/124.9 MB 15.5 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 32.2/124.9 MB 15.7 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 16.0 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 38.0/124.9 MB 15.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 43.0/124.9 MB 16.0 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 47.4/124.9 MB 16.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 52.4/124.9 MB 16.9 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 57.9/124.9 MB 17.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 61.3/124.9 MB 17.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 64.7/124.9 MB 17.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 67.4/124.9 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 71.8/124.9 MB 17.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 75.0/124.9 MB 17.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 79.7/124.9 MB 17.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 83.4/124.9 MB 17.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 17.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 90.2/124.9 MB 17.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 92.3/124.9 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 95.2/124.9 MB 16.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 97.5/124.9 MB 16.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 102.0/124.9 MB 16.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 103.8/124.9 MB 16.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 106.2/124.9 MB 16.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 109.1/124.9 MB 16.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 112.7/124.9 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 115.6/124.9 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 119.8/124.9 MB 16.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  122.4/124.9 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 15.2 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy==2.2.0\n",
    "%pip install scikit-learn==1.6.0\n",
    "%pip install matplotlib==3.9.3\n",
    "%pip install xgboost==2.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f355e-57b1-490d-b3dc-a6daf0e36e4f",
   "metadata": {},
   "source": [
    "You may now start by importing the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449feeab-64ff-4570-b314-459c707437ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ff24d0-d1f6-4585-bbb2-a966a6389401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce01166-850e-44f8-a1e8-198d62ce1bae",
   "metadata": {},
   "source": [
    "### Exercise 1: How many observations and features does the dataset have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2a1a03-d078-4d4f-be98-eb4816547c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations: 20640\n",
      "Number of Features: 8\n"
     ]
    }
   ],
   "source": [
    "#  Extract the number of rows and columns of the dataset automatically\n",
    "N_observations, N_features = X.shape\n",
    "print('Number of Observations: ' + str(N_observations))\n",
    "print('Number of Features: ' + str(N_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f5a974-011f-4e6f-904e-501ff8e24634",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "N_observations, N_features = X.shape\n",
    "print('Number of Observations: ' + str(N_observations))\n",
    "print('Number of Features: ' + str(N_features))\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef610cf0-f6b5-4267-ae0c-f4482fdaf962",
   "metadata": {},
   "source": [
    "This is a moderately sized dataset used for this analysis.  \n",
    "Keep in mind you are only using one dataset so you have to consider that the comparison may change with scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd08a8-225f-4768-8600-2448495e11de",
   "metadata": {},
   "source": [
    "### Initialize models\n",
    "In this step you define the number of base estimators, or individual trees, to be used in each model, and then intialize models for Random Forest regression and XGBoost regression.  You'll just use the default parameters to make the performance comparisons. As a part of the performance comparison, we'll also measure the training times for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23149d9c-8ef7-43ee-a75a-295ab558b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "n_estimators=100\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=n_estimators, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44e7e89b-ea0c-4e80-a57d-47333005f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "# Measure training time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end_time_rf = time.time()\n",
    "rf_train_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure training time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "end_time_xgb = time.time()\n",
    "xgb_train_time = end_time_xgb - start_time_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08177d5-bcf0-4a94-a964-d1c617a52f2e",
   "metadata": {},
   "source": [
    "### Exercise 2. Use the fitted models to make predictions on the test set. \n",
    "Also, measure the time it takes for each model to make its predictions using the time.time() function to measure the times before and after each model prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd1d0a45-6334-459d-94c2-7fb1a9757c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "\n",
    "# Measure prediction time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediction time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb -start_time_xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c8ede-dd24-42e0-8636-6bd7d4704db4",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "# Measure prediction time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediciton time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8588655f-db35-4f36-8d92-e691cad4fa6a",
   "metadata": {},
   "source": [
    "### Exercise 3:  Calulate the MSE and R^2 values for both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5e5bb22-6b76-4ff6-866e-1012af58f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfef139-0c76-46cb-8857-d5f4720a33e9",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a72d8-04c9-4577-abaa-af01618258f4",
   "metadata": {},
   "source": [
    "### Exercise 4:  Print the MSE and R^2 values for both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c13cca-e2a8-490e-8800-571198911d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  MSE = 0.2226, R^2 = 0.8050\n",
      "      XGBoost:  MSE = 0.2226, R^2 = 0.8301\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "\n",
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9985011-2612-40d8-ae37-9414993c97cc",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f22ed-99e4-4714-8dbb-bf8c7331d46d",
   "metadata": {},
   "source": [
    "You can see from the MSE and R^2 values that XGBoost is better than Random Forest, but the differences aren't overwhelming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a2e272-dc7e-400f-8da0-a5fb6da47255",
   "metadata": {},
   "source": [
    "### Exercise 5:  Print the timings for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7308be1e-85cd-4cb0-9294-ecf897c63189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  Training Time = 16.922 seconds, Testing time = 0.177 seconds\n",
      "      XGBoost:  Training Time = 0.244 seconds, Testing time = 0.007 seconds\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "\n",
    "print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df84f6-9e46-4300-879d-9f08d82fb459",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd6da9-b932-43b3-8504-f5dc99683379",
   "metadata": {},
   "source": [
    "What is very impressive is the difference in computation time between XGBoost and Random Forest for both training and testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c936b65-f97e-4a75-9021-8186a6db13aa",
   "metadata": {},
   "source": [
    "Next, you want to generate scatter plots between the predicted and actual values for both models so you can visually evaluate how well each model performs.\n",
    "We'll also plot lines one standard deviation of the test data above and below the ideal line, that is, the line that represents the perfect regressor, where the predictions are all correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e7ffc-7a4a-4588-9bca-42b15e00118c",
   "metadata": {},
   "source": [
    "### Exercise 6. Calculate the standard deviation of the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9241a6-ea6e-43ca-8a8c-4b41d6ed4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "std_y = np.std(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1666c-d094-4e9f-876a-7b29f4e9c399",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "``` python\n",
    "# Standard deviation of y_test\n",
    "std_y = np.std(y_test)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e9168-439d-4cc3-829b-875cbc6e35f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediciton time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}')\n",
    "print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')\n",
    "std_y = np.std(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8eda91-3ce7-47e3-a18d-a465925d3a49",
   "metadata": {},
   "source": [
    "### Visualize the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c5ba3-89ff-4eee-b42f-b17fca4f5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Random Forest plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, color=\"blue\",ec='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2,label=\"perfect model\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() + std_y, y_test.max() + std_y], 'r--', lw=1, label=\"+/-1 Std Dev\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() - std_y, y_test.max() - std_y], 'r--', lw=1, )\n",
    "plt.ylim(0,6)\n",
    "plt.title(\"Random Forest Predictions vs Actual\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# XGBoost plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_xgb, alpha=0.5, color=\"orange\",ec='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2,label=\"perfect model\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() + std_y, y_test.max() + std_y], 'r--', lw=1, label=\"+/-1 Std Dev\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() - std_y, y_test.max() - std_y], 'r--', lw=1, )\n",
    "plt.ylim(0,6)\n",
    "plt.title(\"XGBoost Predictions vs Actual\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08a144-a85f-4a3f-a9c3-ec2651fc948d",
   "metadata": {},
   "source": [
    "Both models performed very well. Most of their predictions fall within a standard deviation of the target. Interestingly, random forest \"respects\" the upper bound (the maximum value) present in the target by staying within its limits, while XGBoost \"overshoots\", or exceeds this limit. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9fcdfc-a700-4c8c-b8b4-444ab9d934c8",
   "metadata": {},
   "source": [
    "### Congratulations! You're ready to move on to your next lesson.\n",
    "\n",
    "## Author\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/jpgrossman/\" target=\"_blank\">Jeff Grossman</a>\n",
    "\n",
    "### Other Contributors\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/abhishek-gagneja-23051987/\" target=\"_blank\">Abhishek Gagneja</a>\n",
    "\n",
    "<!-- ## Changelog\n",
    "\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|:------------|:------|:------------------|:---------------------------------------|\n",
    "| 2024-11-05 | 1.0  | Jeff Grossman    | Create content | -->\n",
    "\n",
    "\n",
    "\n",
    "## <h3 align=\"center\"> Â© IBM Corporation. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd92092-b96f-4e34-8658-a29766f1f177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "prev_pub_hash": "c0340e3960777afa61ba00feb3a189a8a1e26c7e0f9f9482c7c5c54268b84f9c"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
